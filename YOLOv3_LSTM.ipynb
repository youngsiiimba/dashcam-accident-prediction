{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "Akbab63eYeA8",
        "NDWtEPtgYi73",
        "ajVNaOVXeC61"
      ],
      "authorship_tag": "ABX9TyPkqGg4xgWUhpPpAaS06bmT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youngsiiimba/dashcam-accident-prediction/blob/main/YOLOv3_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dGgCMuwhQIck"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.layers import Conv2D, Input, BatchNormalization, LeakyReLU, ZeroPadding2D, UpSampling2D\n",
        "from keras.layers import add, concatenate\n",
        "from keras.models import Model\n",
        "import struct\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -P weights https://pjreddie.com/media/files/yolov3.weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9u8aDhZBab3z",
        "outputId": "7ecbac30-49e5-410d-d0a0-1af784fef125"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-15 12:02:40--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: ‘weights/yolov3.weights’\n",
            "\n",
            "yolov3.weights      100%[===================>] 236.52M   102MB/s    in 2.3s    \n",
            "\n",
            "2023-06-15 12:02:43 (102 MB/s) - ‘weights/yolov3.weights’ saved [248007048/248007048]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define YOLOv3 model"
      ],
      "metadata": {
        "id": "Akbab63eYeA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _conv_block(inp, convs, skip=True):\n",
        "    x = inp\n",
        "    count = 0\n",
        "\n",
        "    for conv in convs:\n",
        "        if count == (len(convs) - 2) and skip:\n",
        "            skip_connection = x\n",
        "        count += 1\n",
        "\n",
        "        if conv['stride'] > 1: x = ZeroPadding2D(((1,0),(1,0)))(x) # peculiar padding as darknet prefer left and top\n",
        "        x = Conv2D(conv['filter'],\n",
        "                   conv['kernel'],\n",
        "                   strides=conv['stride'],\n",
        "                   padding='valid' if conv['stride'] > 1 else 'same', # peculiar padding as darknet prefer left and top\n",
        "                   name='conv_' + str(conv['layer_idx']),\n",
        "                   use_bias=False if conv['bnorm'] else True)(x)\n",
        "        if conv['bnorm']: x = BatchNormalization(epsilon=0.001, name='bnorm_' + str(conv['layer_idx']))(x)\n",
        "        if conv['leaky']: x = LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(x)\n",
        "\n",
        "    return add([skip_connection, x]) if skip else x"
      ],
      "metadata": {
        "id": "i0i9v_hdZPca"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_yolov3_model():\n",
        "    input_image = Input(shape=(None, None, 3))\n",
        "\n",
        "    # Layer  0 => 4\n",
        "    x = _conv_block(input_image, [{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 0},\n",
        "                                  {'filter': 64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 1},\n",
        "                                  {'filter': 32, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 2},\n",
        "                                  {'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 3}])\n",
        "\n",
        "    # Layer  5 => 8\n",
        "    x = _conv_block(x, [{'filter': 128, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 5},\n",
        "                        {'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 6},\n",
        "                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 7}])\n",
        "\n",
        "    # Layer  9 => 11\n",
        "    x = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 9},\n",
        "                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 10}])\n",
        "\n",
        "    # Layer 12 => 15\n",
        "    x = _conv_block(x, [{'filter': 256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 12},\n",
        "                        {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 13},\n",
        "                        {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 14}])\n",
        "\n",
        "    # Layer 16 => 36\n",
        "    for i in range(7):\n",
        "        x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 16+i*3},\n",
        "                            {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 17+i*3}])\n",
        "\n",
        "    skip_36 = x\n",
        "\n",
        "    # Layer 37 => 40\n",
        "    x = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 37},\n",
        "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 38},\n",
        "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 39}])\n",
        "\n",
        "    # Layer 41 => 61\n",
        "    for i in range(7):\n",
        "        x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 41+i*3},\n",
        "                            {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 42+i*3}])\n",
        "\n",
        "    skip_61 = x\n",
        "\n",
        "    # Layer 62 => 65\n",
        "    x = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 62},\n",
        "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 63},\n",
        "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 64}])\n",
        "\n",
        "    # Layer 66 => 74\n",
        "    for i in range(3):\n",
        "        x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 66+i*3},\n",
        "                            {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 67+i*3}])\n",
        "\n",
        "    # Layer 75 => 79\n",
        "    x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 75},\n",
        "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 76},\n",
        "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 77},\n",
        "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 78},\n",
        "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 79}], skip=False)\n",
        "\n",
        "    # Layer 80 => 82\n",
        "    yolo_82 = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 80},\n",
        "                              {'filter':  255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 81}], skip=False)\n",
        "\n",
        "    # Layer 83 => 86\n",
        "    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 84}], skip=False)\n",
        "    x = UpSampling2D(2)(x)\n",
        "    x = concatenate([x, skip_61])\n",
        "\n",
        "    # Layer 87 => 91\n",
        "    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 87},\n",
        "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 88},\n",
        "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 89},\n",
        "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 90},\n",
        "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 91}], skip=False)\n",
        "\n",
        "    # Layer 92 => 94\n",
        "    yolo_94 = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 92},\n",
        "                              {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 93}], skip=False)\n",
        "\n",
        "    # Layer 95 => 98\n",
        "    x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True,   'layer_idx': 96}], skip=False)\n",
        "    x = UpSampling2D(2)(x)\n",
        "    x = concatenate([x, skip_36])\n",
        "\n",
        "    # Layer 99 => 106\n",
        "    yolo_106 = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 99},\n",
        "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 100},\n",
        "                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 101},\n",
        "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 102},\n",
        "                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 103},\n",
        "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 104},\n",
        "                               {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 105}], skip=False)\n",
        "\n",
        "    model = Model(input_image, [yolo_82, yolo_94, yolo_106])\n",
        "    return model"
      ],
      "metadata": {
        "id": "CFZOODN3WwWE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Weight reader"
      ],
      "metadata": {
        "id": "-iw2ouI5bW3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WeightReader:\n",
        "    def __init__(self, weight_file):\n",
        "        with open(weight_file, 'rb') as w_f:\n",
        "            major,    = struct.unpack('i', w_f.read(4))\n",
        "            minor,    = struct.unpack('i', w_f.read(4))\n",
        "            revision, = struct.unpack('i', w_f.read(4))\n",
        "\n",
        "            if (major*10 + minor) >= 2 and major < 1000 and minor < 1000:\n",
        "                w_f.read(8)\n",
        "            else:\n",
        "                w_f.read(4)\n",
        "\n",
        "            transpose = (major > 1000) or (minor > 1000)\n",
        "\n",
        "            binary = w_f.read()\n",
        "\n",
        "        self.offset = 0\n",
        "        self.all_weights = np.frombuffer(binary, dtype='float32')\n",
        "\n",
        "    def read_bytes(self, size):\n",
        "        self.offset = self.offset + size\n",
        "        return self.all_weights[self.offset-size:self.offset]\n",
        "\n",
        "    def load_weights(self, model):\n",
        "        for i in range(106):\n",
        "            try:\n",
        "                conv_layer = model.get_layer('conv_' + str(i))\n",
        "                print(\"loading weights of convolution #\" + str(i))\n",
        "\n",
        "                if i not in [81, 93, 105]:\n",
        "                    norm_layer = model.get_layer('bnorm_' + str(i))\n",
        "\n",
        "                    size = np.prod(norm_layer.get_weights()[0].shape)\n",
        "\n",
        "                    beta  = self.read_bytes(size) # bias\n",
        "                    gamma = self.read_bytes(size) # scale\n",
        "                    mean  = self.read_bytes(size) # mean\n",
        "                    var   = self.read_bytes(size) # variance\n",
        "\n",
        "                    weights = norm_layer.set_weights([gamma, beta, mean, var])\n",
        "\n",
        "                if len(conv_layer.get_weights()) > 1:\n",
        "                    bias   = self.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n",
        "                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
        "\n",
        "                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
        "                    kernel = kernel.transpose([2,3,1,0])\n",
        "                    conv_layer.set_weights([kernel, bias])\n",
        "                else:\n",
        "                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
        "                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
        "                    kernel = kernel.transpose([2,3,1,0])\n",
        "                    conv_layer.set_weights([kernel])\n",
        "            except ValueError:\n",
        "                print(\"no convolution #\" + str(i))"
      ],
      "metadata": {
        "id": "1LDZUY8qbadB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make YOLOv3 model"
      ],
      "metadata": {
        "id": "NDWtEPtgYi73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yolov3_model = make_yolov3_model()"
      ],
      "metadata": {
        "id": "w18RumlGWv9h"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the model weights\n",
        "weight_reader = WeightReader('weights/yolov3.weights')"
      ],
      "metadata": {
        "id": "jirTkKQCbD4O"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set the model weights into the model\n",
        "weight_reader.load_weights(yolov3_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CN_2r74ib2tx",
        "outputId": "865a389c-62f0-4c9e-8e53-7c54f30db391"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading weights of convolution #0\n",
            "loading weights of convolution #1\n",
            "loading weights of convolution #2\n",
            "loading weights of convolution #3\n",
            "no convolution #4\n",
            "loading weights of convolution #5\n",
            "loading weights of convolution #6\n",
            "loading weights of convolution #7\n",
            "no convolution #8\n",
            "loading weights of convolution #9\n",
            "loading weights of convolution #10\n",
            "no convolution #11\n",
            "loading weights of convolution #12\n",
            "loading weights of convolution #13\n",
            "loading weights of convolution #14\n",
            "no convolution #15\n",
            "loading weights of convolution #16\n",
            "loading weights of convolution #17\n",
            "no convolution #18\n",
            "loading weights of convolution #19\n",
            "loading weights of convolution #20\n",
            "no convolution #21\n",
            "loading weights of convolution #22\n",
            "loading weights of convolution #23\n",
            "no convolution #24\n",
            "loading weights of convolution #25\n",
            "loading weights of convolution #26\n",
            "no convolution #27\n",
            "loading weights of convolution #28\n",
            "loading weights of convolution #29\n",
            "no convolution #30\n",
            "loading weights of convolution #31\n",
            "loading weights of convolution #32\n",
            "no convolution #33\n",
            "loading weights of convolution #34\n",
            "loading weights of convolution #35\n",
            "no convolution #36\n",
            "loading weights of convolution #37\n",
            "loading weights of convolution #38\n",
            "loading weights of convolution #39\n",
            "no convolution #40\n",
            "loading weights of convolution #41\n",
            "loading weights of convolution #42\n",
            "no convolution #43\n",
            "loading weights of convolution #44\n",
            "loading weights of convolution #45\n",
            "no convolution #46\n",
            "loading weights of convolution #47\n",
            "loading weights of convolution #48\n",
            "no convolution #49\n",
            "loading weights of convolution #50\n",
            "loading weights of convolution #51\n",
            "no convolution #52\n",
            "loading weights of convolution #53\n",
            "loading weights of convolution #54\n",
            "no convolution #55\n",
            "loading weights of convolution #56\n",
            "loading weights of convolution #57\n",
            "no convolution #58\n",
            "loading weights of convolution #59\n",
            "loading weights of convolution #60\n",
            "no convolution #61\n",
            "loading weights of convolution #62\n",
            "loading weights of convolution #63\n",
            "loading weights of convolution #64\n",
            "no convolution #65\n",
            "loading weights of convolution #66\n",
            "loading weights of convolution #67\n",
            "no convolution #68\n",
            "loading weights of convolution #69\n",
            "loading weights of convolution #70\n",
            "no convolution #71\n",
            "loading weights of convolution #72\n",
            "loading weights of convolution #73\n",
            "no convolution #74\n",
            "loading weights of convolution #75\n",
            "loading weights of convolution #76\n",
            "loading weights of convolution #77\n",
            "loading weights of convolution #78\n",
            "loading weights of convolution #79\n",
            "loading weights of convolution #80\n",
            "loading weights of convolution #81\n",
            "no convolution #82\n",
            "no convolution #83\n",
            "loading weights of convolution #84\n",
            "no convolution #85\n",
            "no convolution #86\n",
            "loading weights of convolution #87\n",
            "loading weights of convolution #88\n",
            "loading weights of convolution #89\n",
            "loading weights of convolution #90\n",
            "loading weights of convolution #91\n",
            "loading weights of convolution #92\n",
            "loading weights of convolution #93\n",
            "no convolution #94\n",
            "no convolution #95\n",
            "loading weights of convolution #96\n",
            "no convolution #97\n",
            "no convolution #98\n",
            "loading weights of convolution #99\n",
            "loading weights of convolution #100\n",
            "loading weights of convolution #101\n",
            "loading weights of convolution #102\n",
            "loading weights of convolution #103\n",
            "loading weights of convolution #104\n",
            "loading weights of convolution #105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save the model to a Keras compatible .h5 model file ready for later use.\n",
        "yolov3_model.save('yolov3-model.h5')\n",
        "\n",
        "\n",
        "\n",
        "# load yolov3 model\n",
        "#model = load_model('model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iw_fYGLUcGqz",
        "outputId": "70db72f0-09f9-4246-e831-1150e9a052bc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper functions for making predictions"
      ],
      "metadata": {
        "id": "ajVNaOVXeC61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# based on https://github.com/experiencor/keras-yolo3\n",
        "import numpy as np\n",
        "from numpy import expand_dims\n",
        "from keras.models import load_model\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "from matplotlib import pyplot\n",
        "from matplotlib.patches import Rectangle"
      ],
      "metadata": {
        "id": "nk5UlcI0euzw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BoundBox:\n",
        "    def __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
        "        self.xmin = xmin\n",
        "        self.ymin = ymin\n",
        "        self.xmax = xmax\n",
        "        self.ymax = ymax\n",
        "\n",
        "        self.objness = objness\n",
        "        self.classes = classes\n",
        "\n",
        "        self.label = -1\n",
        "        self.score = -1\n",
        "\n",
        "    def get_label(self):\n",
        "        if self.label == -1:\n",
        "            self.label = np.argmax(self.classes)\n",
        "\n",
        "        return self.label\n",
        "\n",
        "    def get_score(self):\n",
        "        if self.score == -1:\n",
        "            self.score = self.classes[self.get_label()]\n",
        "\n",
        "        return self.score"
      ],
      "metadata": {
        "id": "ccMWXODRfPIF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _sigmoid(x):\n",
        "    return 1. / (1. + np.exp(-x))"
      ],
      "metadata": {
        "id": "r-CJuRMvgP9T"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_netout(netout, anchors, obj_thresh, nms_thresh, net_h, net_w):\n",
        "    grid_h, grid_w = netout.shape[:2]\n",
        "    nb_box = 3\n",
        "    netout = netout.reshape((grid_h, grid_w, nb_box, -1))\n",
        "    nb_class = netout.shape[-1] - 5\n",
        "\n",
        "    boxes = []\n",
        "\n",
        "    netout[..., :2]  = _sigmoid(netout[..., :2])\n",
        "    netout[..., 4:]  = _sigmoid(netout[..., 4:])\n",
        "    netout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
        "    netout[..., 5:] *= netout[..., 5:] > obj_thresh\n",
        "\n",
        "    for i in range(grid_h*grid_w):\n",
        "        row = i / grid_w\n",
        "        col = i % grid_w\n",
        "\n",
        "        for b in range(nb_box):\n",
        "            # 4th element is objectness score\n",
        "            objectness = netout[int(row)][int(col)][b][4]\n",
        "            #objectness = netout[..., :4]\n",
        "\n",
        "            if(objectness.all() <= obj_thresh): continue\n",
        "\n",
        "            # first 4 elements are x, y, w, and h\n",
        "            x, y, w, h = netout[int(row)][int(col)][b][:4]\n",
        "\n",
        "            x = (col + x) / grid_w # center position, unit: image width\n",
        "            y = (row + y) / grid_h # center position, unit: image height\n",
        "            w = anchors[2 * b + 0] * np.exp(w) / net_w # unit: image width\n",
        "            h = anchors[2 * b + 1] * np.exp(h) / net_h # unit: image height\n",
        "\n",
        "            # last elements are class probabilities\n",
        "            classes = netout[int(row)][col][b][5:]\n",
        "\n",
        "            box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
        "            #box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, None, classes)\n",
        "\n",
        "            boxes.append(box)\n",
        "\n",
        "    return boxes"
      ],
      "metadata": {
        "id": "wzPGED7ZhLM3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n",
        "    if (float(net_w)/image_w) < (float(net_h)/image_h):\n",
        "        new_w = net_w\n",
        "        new_h = (image_h*net_w)/image_w\n",
        "    else:\n",
        "        new_h = net_w\n",
        "        new_w = (image_w*net_h)/image_h\n",
        "\n",
        "    for i in range(len(boxes)):\n",
        "        x_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
        "        y_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
        "\n",
        "        boxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
        "        boxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
        "        boxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
        "        boxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\n"
      ],
      "metadata": {
        "id": "1m51HYCxhhkx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _interval_overlap(interval_a, interval_b):\n",
        "    x1, x2 = interval_a\n",
        "    x3, x4 = interval_b\n",
        "\n",
        "    if x3 < x1:\n",
        "        if x4 < x1:\n",
        "            return 0\n",
        "        else:\n",
        "            return min(x2,x4) - x1\n",
        "    else:\n",
        "        if x2 < x3:\n",
        "             return 0\n",
        "        else:\n",
        "            return min(x2,x4) - x3"
      ],
      "metadata": {
        "id": "6v6rz4a_h0MF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bbox_iou(box1, box2):\n",
        "    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
        "    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
        "\n",
        "    intersect = intersect_w * intersect_h\n",
        "\n",
        "    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
        "    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
        "\n",
        "    union = w1*h1 + w2*h2 - intersect\n",
        "\n",
        "    return float(intersect) / union"
      ],
      "metadata": {
        "id": "Q3DYJW9gh-fY"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def do_nms(boxes, nms_thresh):\n",
        "    if len(boxes) > 0:\n",
        "        nb_class = len(boxes[0].classes)\n",
        "    else:\n",
        "        return\n",
        "\n",
        "    for c in range(nb_class):\n",
        "        sorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
        "\n",
        "        for i in range(len(sorted_indices)):\n",
        "            index_i = sorted_indices[i]\n",
        "\n",
        "            if boxes[index_i].classes[c] == 0: continue\n",
        "\n",
        "            for j in range(i+1, len(sorted_indices)):\n",
        "                index_j = sorted_indices[j]\n",
        "\n",
        "                if bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
        "                    boxes[index_j].classes[c] = 0"
      ],
      "metadata": {
        "id": "OpeHoB5DiGxK"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load and prepare an image\n",
        "def load_image_pixels(filename, shape):\n",
        "    # load the image to get its shape\n",
        "    image = load_img(filename)\n",
        "    width, height = image.size\n",
        "    # load the image with the required size\n",
        "    image = load_img(filename, target_size=shape)\n",
        "    # convert to numpy array\n",
        "    image = img_to_array(image)\n",
        "    # scale pixel values to [0, 1]\n",
        "    image = image.astype('float32')\n",
        "    image /= 255.0\n",
        "    # add a dimension so that we have one sample\n",
        "    image = expand_dims(image, 0)\n",
        "    return image, width, height"
      ],
      "metadata": {
        "id": "Ou81IYbZiccG"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get all of the results above a threshold\n",
        "def get_boxes(boxes, labels, thresh):\n",
        "    v_boxes, v_labels, v_scores = list(), list(), list()\n",
        "    # enumerate all boxes\n",
        "    for box in boxes:\n",
        "      # enumerate all possible labels\n",
        "      for i in range(len(labels)):\n",
        "        # check if the threshold for this label is high enough\n",
        "        if box.classes[i] > thresh:\n",
        "          v_boxes.append(box)\n",
        "          v_labels.append(labels[i])\n",
        "          v_scores.append(box.classes[i]*100)\n",
        "          # don't break, many labels may trigger for one box\n",
        "    return v_boxes, v_labels, v_scores"
      ],
      "metadata": {
        "id": "gUKjhooVi5Ee"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# draw all results\n",
        "def draw_boxes(filename, v_boxes, v_labels, v_scores):\n",
        "    # load the image\n",
        "    data = pyplot.imread(filename)\n",
        "    # plot the image\n",
        "    pyplot.imshow(data)\n",
        "    # get the context for drawing boxes\n",
        "    ax = pyplot.gca()\n",
        "    # plot each box\n",
        "    for i in range(len(v_boxes)):\n",
        "        box = v_boxes[i]\n",
        "        # get coordinates\n",
        "        y1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n",
        "        # calculate width and height of the box\n",
        "        width, height = x2 - x1, y2 - y1\n",
        "        # create the shape\n",
        "        rect = Rectangle((x1, y1), width, height, fill=False, color='white')\n",
        "        # draw the box\n",
        "        ax.add_patch(rect)\n",
        "        # draw text and score in top left corner\n",
        "        label = \"%s (%.3f)\" % (v_labels[i], v_scores[i])\n",
        "        pyplot.text(x1, y1, label, color='white')\n",
        "      # show the plot\n",
        "    pyplot.show()\n"
      ],
      "metadata": {
        "id": "UtPx02_DjMrI"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make predictions"
      ],
      "metadata": {
        "id": "BLZFpXzUmZAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/heartkilla/yolo-v3.git"
      ],
      "metadata": {
        "id": "aP6VgLJhkTC8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6a67da3-88a1-492a-861e-704a2a65e744"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolo-v3'...\n",
            "remote: Enumerating objects: 139, done.\u001b[K\n",
            "remote: Total 139 (delta 0), reused 0 (delta 0), pack-reused 139\u001b[K\n",
            "Receiving objects: 100% (139/139), 65.73 MiB | 19.32 MiB/s, done.\n",
            "Resolving deltas: 100% (48/48), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image1 = '/content/yolo-v3/data/images/dog.jpg'\n",
        "image2 = '/content/yolo-v3/data/images/office.jpg'"
      ],
      "metadata": {
        "id": "K6T_ROipmRwM"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the expected input shape for the model\n",
        "input_w, input_h = 416, 416\n",
        "# define our new photo\n",
        "photo_filename = '/content/yolo-v3/data/images/dog.jpg'\n",
        "# load and prepare image\n",
        "image, image_w, image_h = load_image_pixels(photo_filename, (input_w, input_h))"
      ],
      "metadata": {
        "id": "OERx567fmcPn"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image.size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8G4dNTg0pFd",
        "outputId": "cebb4476-1680-4057-b29a-28ba9f43df55"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "519168"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output of the model is, in fact, encoded candidate bounding boxes from three different grid sizes, and the boxes are defined the context of anchor boxes, carefully chosen based on an analysis of the size of objects in the MSCOCO dataset."
      ],
      "metadata": {
        "id": "yti-2Ozqugnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# make prediction\n",
        "yhat = yolov3_model.predict(image)\n",
        "print(len(yhat))\n",
        "#arr_yhat = np.array(yhat.copy)\n",
        "# summarize the shape of the list of arrays\n",
        "print([a.shape for a in yhat])"
      ],
      "metadata": {
        "id": "_KaVHxXNm73A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4678f143-9946-4c64-df66-9a6ba85866e9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 9s 9s/step\n",
            "3\n",
            "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "yhat[0].flatten()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkOOHuWpAS6m",
        "outputId": "333f4889-fb57-4c00-b0b4-bb048f958dce"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.16541481,  0.3153256 ,  0.32475203, ..., -3.9620342 ,\n",
              "       -4.1403227 , -3.6877267 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make data for YOLO-LSTM"
      ],
      "metadata": {
        "id": "kZhvgm_lvM3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###access google drive folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYOGEfOGwqbG",
        "outputId": "08579dd4-51df-410e-9bff-4c173034c938"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -u -q /content/drive/MyDrive/Dachcam_dataset.zip"
      ],
      "metadata": {
        "id": "UQ094hWzxUWZ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"/content/videos/training\"\n",
        "test_dir = \"/content/videos/testing\""
      ],
      "metadata": {
        "id": "DqLCIWrDxXXF"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import expand_dims\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "# load and prepare an image\n",
        "def load_image_pixels(filename, shape):\n",
        "    # load the image to get its shape\n",
        "    image = load_img(filename)\n",
        "    width, height = image.size\n",
        "    # load the image with the required size\n",
        "    image = load_img(filename, target_size=shape)\n",
        "    # convert to numpy array\n",
        "    image = img_to_array(image)\n",
        "    # scale pixel values to [0, 1]\n",
        "    image = image.astype('float32')\n",
        "    image /= 255.0\n",
        "    # add a dimension so that we have one sample\n",
        "    image = expand_dims(image, 0)\n",
        "    return image, width, height"
      ],
      "metadata": {
        "id": "EqS25xmY1FZJ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from numpy import expand_dims\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "def coordinates_extraction(video_path):\n",
        "    coordinates_list = []\n",
        "    vidObj = cv2.VideoCapture(video_path)\n",
        "    # Used as counter variable\n",
        "    count = 1\n",
        "    while count <= seq_len:\n",
        "        success, image = vidObj.read()\n",
        "        if success:\n",
        "            # #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            #image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "            image = cv2.resize(image, (vid_height, vid_width))\n",
        "            # convert to numpy array\n",
        "            image = img_to_array(image)\n",
        "            # scale pixel values to [0, 1]\n",
        "            image = image.astype('float32')\n",
        "            image /= 255.0\n",
        "            # add a dimension so that we have one sample\n",
        "            image = expand_dims(image, 0)\n",
        "            predictions = yolov3_model.predict(image)\n",
        "            coordinates_list.append(predictions[0].flatten())\n",
        "            count += 1\n",
        "        else:\n",
        "            print(\"Defected frame\")\n",
        "            break\n",
        "    #return only the first 50 frames, so model makes predict for the next 50 frames\n",
        "    return coordinates_list"
      ],
      "metadata": {
        "id": "ulpYxLR1xj4O"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def create_data(input_dir, seq_len, classes):\n",
        "    X = []\n",
        "    Y = []\n",
        "\n",
        "    classes_list = os.listdir(input_dir)\n",
        "\n",
        "    for c in classes_list:\n",
        "        print(c)\n",
        "        files_list = os.listdir(os.path.join(input_dir, c))\n",
        "        for f in files_list:\n",
        "          coordinates = coordinates_extraction(os.path.join(os.path.join(input_dir, c), f))\n",
        "          if len(coordinates) == seq_len:\n",
        "                X.append(coordinates)\n",
        "                y = [0]*len(classes)\n",
        "                y[classes.index(c)] = 1\n",
        "                Y.append(y)\n",
        "          else:\n",
        "            print(\"len(coordinates) != seq_len\")\n",
        "            break\n",
        "\n",
        "    X = np.asarray(X)\n",
        "    Y = np.asarray(Y)\n",
        "    return X, Y"
      ],
      "metadata": {
        "id": "2HoaHMUZxneT"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the expected input shape for the model\n",
        "vid_height , vid_width = 416, 416\n",
        "seq_len = 50\n",
        "classes = [\"negative\", \"positive\"]\n",
        "\n",
        "#Need to thread this or use multiprocessing to make this faster\n",
        "import time\n",
        "start = time.perf_counter()\n",
        "X_train, y_train = create_data(train_dir, seq_len, classes)\n",
        "X_test, y_test =  create_data(test_dir, seq_len, classes)\n",
        "finish = time.perf_counter()\n",
        "print(f\"Finished in {round(finish-start,2)} seconds.\")"
      ],
      "metadata": {
        "id": "QMIvflUaxumd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4b071620-d1a3-41b1-fba6-5f8bb8b98cf8"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "negative\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 108ms/step\n",
            "1/1 [==============================] - 0s 94ms/step\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "1/1 [==============================] - 0s 96ms/step\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "1/1 [==============================] - 0s 109ms/step\n",
            "1/1 [==============================] - 0s 111ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "1/1 [==============================] - 0s 99ms/step\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "1/1 [==============================] - 0s 128ms/step\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 86ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribution_strategy_context.py\u001b[0m in \u001b[0;36m_get_per_thread_mode\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution_strategy_stack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-22c5e12ddc4d>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mcreate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mfinish\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-ee6ae509a19c>\u001b[0m in \u001b[0;36mcreate_data\u001b[0;34m(input_dir, seq_len, classes)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mfiles_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m           \u001b[0mcoordinates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoordinates_extraction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoordinates\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoordinates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-e7025cf3720a>\u001b[0m in \u001b[0;36mcoordinates_extraction\u001b[0;34m(video_path)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0;31m# add a dimension so that we have one sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myolov3_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mcoordinates_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   2376\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2377\u001b[0m             \u001b[0mbatch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2378\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Single epoch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2379\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2380\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1302\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1305\u001b[0m             \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_truncate_execution_to_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1325\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inferred_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m         )\n\u001b[0;32m-> 1327\u001b[0;31m         \u001b[0moriginal_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_truncate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    645\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m     raise NotImplementedError(\n\u001b[1;32m    649\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mread_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    772\u001b[0m     \"\"\"\n\u001b[1;32m    773\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Read\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m       \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_variable_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m     \u001b[0;31m# Return an identity so it can get placed on whatever device the context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;31m# specifies instead of the device where the variable is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_read_variable_op\u001b[0;34m(self, no_copy)\u001b[0m\n\u001b[1;32m    736\u001b[0m       \u001b[0mThe\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m     \"\"\"\n\u001b[0;32m--> 738\u001b[0;31m     \u001b[0mvariable_accessed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_copy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36mvariable_accessed\u001b[0;34m(variable)\u001b[0m\n\u001b[1;32m    331\u001b[0m     \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m     \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_accessed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/tape.py\u001b[0m in \u001b[0;36mvariable_accessed\u001b[0;34m(variable)\u001b[0m\n\u001b[1;32m    109\u001b[0m   \"\"\"\n\u001b[1;32m    110\u001b[0m   strategy, context = (\n\u001b[0;32m--> 111\u001b[0;31m       distribution_strategy_context.get_strategy_and_replica_context())\n\u001b[0m\u001b[1;32m    112\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_container\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvariable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribution_strategy_context.py\u001b[0m in \u001b[0;36mget_strategy_and_replica_context\u001b[0;34m()\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_strategy_and_replica_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 270\u001b[0;31m   \u001b[0mper_thread_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_per_thread_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    271\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mper_thread_mode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mper_thread_mode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplica_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribution_strategy_context.py\u001b[0m in \u001b[0;36m_get_per_thread_mode\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_per_thread_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution_strategy_stack\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_get_default_replica_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir test"
      ],
      "metadata": {
        "id": "uLMYf3TO71vk"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir negative\n",
        "!mkdir positive\n"
      ],
      "metadata": {
        "id": "LN2AvDJq8DjI"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv positive/ test/positive"
      ],
      "metadata": {
        "id": "5O_nnlt49AHM"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv negative test/negative"
      ],
      "metadata": {
        "id": "CvFe4Tpm9TOP"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We keep running out run while trying to create the data so we'll use 4 videos to tinker\n",
        "!cp \"/content/videos/testing/negative/000830.mp4\" test/negative/000830.mp4\n",
        "!cp \"/content/videos/testing/negative/000831.mp4\" test/negative/000831.mp4\n",
        "\n",
        "!cp \"/content/videos/testing/positive/000456.mp4\" test/positive/000456.mp4\n",
        "!cp \"/content/videos/testing/positive/000457.mp4\" test/positive/000457.mp4"
      ],
      "metadata": {
        "id": "YXaIDsEX9LqM"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tinker_dir = \"test\"\n",
        "X, Y = create_data(tinker_dir, seq_len, classes)"
      ],
      "metadata": {
        "id": "g3UlwHoJ-SZ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "313828e0-d713-46ea-8c5d-fcb4d81e9b35"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "negative\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "positive\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "id": "wuTarx5eL1ND",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cc60b7f-2769-4af5-c4bd-eee1df9c18bb"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 50, 43095)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyEbUQTfB7Q7",
        "outputId": "e68344bd-686c-44ae-ef72-1a7bca9f392d"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make LSTM model"
      ],
      "metadata": {
        "id": "HOXwN4esFpJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = X.shape[0]\n",
        "sequence_length = X.shape[1]\n",
        "nb_features = X.shape[2]\n",
        "nb_out = 2\n",
        "#print(input_shape.shape)\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM, Activation\n",
        "from sklearn.metrics import fbeta_score\n",
        "# build the LSTM network\n",
        "# Feature weights\n",
        "# LSTM model\n",
        "LSTM_model = Sequential()\n",
        "\n",
        "# The first layer\n",
        "LSTM_model.add(LSTM(\n",
        "         input_shape=(sequence_length, nb_features),\n",
        "         units=100,\n",
        "         return_sequences=True))\n",
        "\n",
        "# Plus a 20% dropout rate\n",
        "#LSTM_model.add(Dropout(0.2))\n",
        "\n",
        "# The second layer\n",
        "LSTM_model.add(LSTM(\n",
        "          units=50,\n",
        "          return_sequences=False))\n",
        "\n",
        "# Plus a 20% dropout rate\n",
        "#LSTM_model.add(Dropout(0.2))\n",
        "\n",
        "# # Dense sigmoid layer\n",
        "LSTM_model.add(Dense(units=nb_out, activation='sigmoid'))\n",
        "# Dense softmax layer\n",
        "#LSTM_model.add(Dense(units=nb_out, activation='softmax'))\n",
        "\n",
        "# # With adam optimizer and a binary crossentropy loss. We will opimize for model accuracy.\n",
        "LSTM_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "\n",
        "\n",
        "\n",
        "#LSTM_model.compile(optimizer=keras.optimizers.Adam(0.001), loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "# Verify the architecture\n",
        "print(LSTM_model.summary())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##Note: I seem to be getting better results with activation set to 'sigmoid' as opposed to 'softmax' and loss set to 'binary_crossentropy' as opposed to 'categorical_crossentropy'\n",
        "\n"
      ],
      "metadata": {
        "id": "K5korYWNN-LD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "621f2b94-590f-4dff-df35-a833196efc14"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_6 (LSTM)               (None, 50, 100)           17278400  \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               (None, 50)                30200     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 102       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,308,702\n",
            "Trainable params: 17,308,702\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train model"
      ],
      "metadata": {
        "id": "tQZBrJMqF-FT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import time\n",
        "\n",
        "\n",
        "t0 = time.time()\n",
        "# fit the network\n",
        "LSTM_history = LSTM_model.fit(X, # Training features\n",
        "          Y, # Training labels\n",
        "          epochs=1000,   # We'll stop after 10 epochs\n",
        "          batch_size=200, #\n",
        "          validation_split=0.10, # Use 10% of data to evaluate the loss. (val_loss)\n",
        "          verbose=1, #\n",
        "          )\n",
        "\n",
        "print(\"Training took \"+str(time.time() - t0)+\" seconds\")"
      ],
      "metadata": {
        "id": "g97yHQMfR6tH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9b428f8-9029-4138-f75f-1b2be8cd0fa1"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "1/1 [==============================] - 5s 5s/step - loss: 0.7052 - acc: 0.3333 - val_loss: 0.9519 - val_acc: 0.0000e+00\n",
            "Epoch 2/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.6638 - acc: 0.6667 - val_loss: 1.0574 - val_acc: 0.0000e+00\n",
            "Epoch 3/1000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.6312 - acc: 0.6667 - val_loss: 1.1037 - val_acc: 0.0000e+00\n",
            "Epoch 4/1000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.6342 - acc: 0.6667 - val_loss: 1.1462 - val_acc: 0.0000e+00\n",
            "Epoch 5/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.6299 - acc: 0.6667 - val_loss: 1.1836 - val_acc: 0.0000e+00\n",
            "Epoch 6/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.6243 - acc: 0.6667 - val_loss: 1.2124 - val_acc: 0.0000e+00\n",
            "Epoch 7/1000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.6179 - acc: 0.6667 - val_loss: 1.2310 - val_acc: 0.0000e+00\n",
            "Epoch 8/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.6109 - acc: 0.6667 - val_loss: 1.2392 - val_acc: 0.0000e+00\n",
            "Epoch 9/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.6032 - acc: 0.6667 - val_loss: 1.2366 - val_acc: 0.0000e+00\n",
            "Epoch 10/1000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.5947 - acc: 0.6667 - val_loss: 1.2220 - val_acc: 0.0000e+00\n",
            "Epoch 11/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.5856 - acc: 0.6667 - val_loss: 1.1964 - val_acc: 0.0000e+00\n",
            "Epoch 12/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.5760 - acc: 0.6667 - val_loss: 1.1130 - val_acc: 0.0000e+00\n",
            "Epoch 13/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.5643 - acc: 0.6667 - val_loss: 1.1593 - val_acc: 0.0000e+00\n",
            "Epoch 14/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.5535 - acc: 0.6667 - val_loss: 1.2798 - val_acc: 0.0000e+00\n",
            "Epoch 15/1000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.5708 - acc: 0.6667 - val_loss: 1.2656 - val_acc: 0.0000e+00\n",
            "Epoch 16/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.5543 - acc: 0.6667 - val_loss: 1.3499 - val_acc: 0.0000e+00\n",
            "Epoch 17/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.5543 - acc: 0.6667 - val_loss: 1.1368 - val_acc: 0.0000e+00\n",
            "Epoch 18/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.5052 - acc: 0.6667 - val_loss: 1.0679 - val_acc: 0.0000e+00\n",
            "Epoch 19/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.4940 - acc: 1.0000 - val_loss: 1.1527 - val_acc: 0.0000e+00\n",
            "Epoch 20/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.4573 - acc: 1.0000 - val_loss: 1.3276 - val_acc: 0.0000e+00\n",
            "Epoch 21/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.4163 - acc: 1.0000 - val_loss: 1.4777 - val_acc: 0.0000e+00\n",
            "Epoch 22/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.3938 - acc: 1.0000 - val_loss: 1.5956 - val_acc: 0.0000e+00\n",
            "Epoch 23/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.3604 - acc: 1.0000 - val_loss: 1.7160 - val_acc: 0.0000e+00\n",
            "Epoch 24/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.3147 - acc: 1.0000 - val_loss: 1.8220 - val_acc: 0.0000e+00\n",
            "Epoch 25/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.2803 - acc: 1.0000 - val_loss: 1.9248 - val_acc: 0.0000e+00\n",
            "Epoch 26/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.2542 - acc: 1.0000 - val_loss: 2.0583 - val_acc: 0.0000e+00\n",
            "Epoch 27/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.2570 - acc: 1.0000 - val_loss: 2.0290 - val_acc: 0.0000e+00\n",
            "Epoch 28/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.2199 - acc: 1.0000 - val_loss: 2.2491 - val_acc: 0.0000e+00\n",
            "Epoch 29/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.1916 - acc: 1.0000 - val_loss: 2.3502 - val_acc: 0.0000e+00\n",
            "Epoch 30/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.1755 - acc: 1.0000 - val_loss: 2.4374 - val_acc: 0.0000e+00\n",
            "Epoch 31/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.1613 - acc: 1.0000 - val_loss: 2.5256 - val_acc: 0.0000e+00\n",
            "Epoch 32/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.1551 - acc: 1.0000 - val_loss: 2.5962 - val_acc: 0.0000e+00\n",
            "Epoch 33/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.1364 - acc: 1.0000 - val_loss: 2.6725 - val_acc: 0.0000e+00\n",
            "Epoch 34/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.1254 - acc: 1.0000 - val_loss: 2.7073 - val_acc: 0.0000e+00\n",
            "Epoch 35/1000\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.2176 - acc: 1.0000 - val_loss: 2.7819 - val_acc: 0.0000e+00\n",
            "Epoch 36/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.1332 - acc: 1.0000 - val_loss: 2.8533 - val_acc: 0.0000e+00\n",
            "Epoch 37/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.1037 - acc: 1.0000 - val_loss: 2.9108 - val_acc: 0.0000e+00\n",
            "Epoch 38/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0964 - acc: 1.0000 - val_loss: 0.5698 - val_acc: 1.0000\n",
            "Epoch 39/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.6227 - acc: 0.3333 - val_loss: 3.0437 - val_acc: 0.0000e+00\n",
            "Epoch 40/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0865 - acc: 1.0000 - val_loss: 3.0926 - val_acc: 0.0000e+00\n",
            "Epoch 41/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0840 - acc: 1.0000 - val_loss: 3.1344 - val_acc: 0.0000e+00\n",
            "Epoch 42/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0820 - acc: 1.0000 - val_loss: 3.1740 - val_acc: 0.0000e+00\n",
            "Epoch 43/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0812 - acc: 1.0000 - val_loss: 3.2127 - val_acc: 0.0000e+00\n",
            "Epoch 44/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.9946 - acc: 0.6667 - val_loss: 3.2103 - val_acc: 0.0000e+00\n",
            "Epoch 45/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.9631 - acc: 0.6667 - val_loss: 2.1069 - val_acc: 0.0000e+00\n",
            "Epoch 46/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.1803 - acc: 1.0000 - val_loss: 2.6233 - val_acc: 0.0000e+00\n",
            "Epoch 47/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0977 - acc: 1.0000 - val_loss: 2.5918 - val_acc: 0.0000e+00\n",
            "Epoch 48/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0986 - acc: 1.0000 - val_loss: 2.5757 - val_acc: 0.0000e+00\n",
            "Epoch 49/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0986 - acc: 1.0000 - val_loss: 2.5707 - val_acc: 0.0000e+00\n",
            "Epoch 50/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0981 - acc: 1.0000 - val_loss: 2.5744 - val_acc: 0.0000e+00\n",
            "Epoch 51/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0970 - acc: 1.0000 - val_loss: 2.5853 - val_acc: 0.0000e+00\n",
            "Epoch 52/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0955 - acc: 1.0000 - val_loss: 2.6023 - val_acc: 0.0000e+00\n",
            "Epoch 53/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0936 - acc: 1.0000 - val_loss: 2.6244 - val_acc: 0.0000e+00\n",
            "Epoch 54/1000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0915 - acc: 1.0000 - val_loss: 2.6509 - val_acc: 0.0000e+00\n",
            "Epoch 55/1000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0891 - acc: 1.0000 - val_loss: 2.6810 - val_acc: 0.0000e+00\n",
            "Epoch 56/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0866 - acc: 1.0000 - val_loss: 2.7142 - val_acc: 0.0000e+00\n",
            "Epoch 57/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0839 - acc: 1.0000 - val_loss: 2.7499 - val_acc: 0.0000e+00\n",
            "Epoch 58/1000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.0811 - acc: 1.0000 - val_loss: 2.7875 - val_acc: 0.0000e+00\n",
            "Epoch 59/1000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.0783 - acc: 1.0000 - val_loss: 2.8266 - val_acc: 0.0000e+00\n",
            "Epoch 60/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0755 - acc: 1.0000 - val_loss: 2.8669 - val_acc: 0.0000e+00\n",
            "Epoch 61/1000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.0727 - acc: 1.0000 - val_loss: 2.9080 - val_acc: 0.0000e+00\n",
            "Epoch 62/1000\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 0.0699 - acc: 1.0000 - val_loss: 2.9498 - val_acc: 0.0000e+00\n",
            "Epoch 63/1000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.0673 - acc: 1.0000 - val_loss: 2.9920 - val_acc: 0.0000e+00\n",
            "Epoch 64/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0647 - acc: 1.0000 - val_loss: 3.0345 - val_acc: 0.0000e+00\n",
            "Epoch 65/1000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0623 - acc: 1.0000 - val_loss: 3.0771 - val_acc: 0.0000e+00\n",
            "Epoch 66/1000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.0599 - acc: 1.0000 - val_loss: 3.1198 - val_acc: 0.0000e+00\n",
            "Epoch 67/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0577 - acc: 1.0000 - val_loss: 3.1625 - val_acc: 0.0000e+00\n",
            "Epoch 68/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0555 - acc: 1.0000 - val_loss: 3.2051 - val_acc: 0.0000e+00\n",
            "Epoch 69/1000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.0535 - acc: 1.0000 - val_loss: 3.2475 - val_acc: 0.0000e+00\n",
            "Epoch 70/1000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.0515 - acc: 1.0000 - val_loss: 3.2896 - val_acc: 0.0000e+00\n",
            "Epoch 71/1000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.0496 - acc: 1.0000 - val_loss: 3.3314 - val_acc: 0.0000e+00\n",
            "Epoch 72/1000\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 0.0479 - acc: 1.0000 - val_loss: 3.3729 - val_acc: 0.0000e+00\n",
            "Epoch 73/1000\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.0462 - acc: 1.0000 - val_loss: 3.4139 - val_acc: 0.0000e+00\n",
            "Epoch 74/1000\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 0.0446 - acc: 1.0000 - val_loss: 3.4546 - val_acc: 0.0000e+00\n",
            "Epoch 75/1000\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.0430 - acc: 1.0000 - val_loss: 3.4948 - val_acc: 0.0000e+00\n",
            "Epoch 76/1000\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.0416 - acc: 1.0000 - val_loss: 3.5346 - val_acc: 0.0000e+00\n",
            "Epoch 77/1000\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.0402 - acc: 1.0000 - val_loss: 3.5741 - val_acc: 0.0000e+00\n",
            "Epoch 78/1000\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 0.0389 - acc: 1.0000 - val_loss: 3.6131 - val_acc: 0.0000e+00\n",
            "Epoch 79/1000\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.0376 - acc: 1.0000 - val_loss: 3.6519 - val_acc: 0.0000e+00\n",
            "Epoch 80/1000\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.0364 - acc: 1.0000 - val_loss: 3.6903 - val_acc: 0.0000e+00\n",
            "Epoch 81/1000\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.0353 - acc: 1.0000 - val_loss: 3.7286 - val_acc: 0.0000e+00\n",
            "Epoch 82/1000\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 0.0342 - acc: 1.0000 - val_loss: 3.7665 - val_acc: 0.0000e+00\n",
            "Epoch 83/1000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0332 - acc: 1.0000 - val_loss: 3.8043 - val_acc: 0.0000e+00\n",
            "Epoch 84/1000\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 0.0322 - acc: 1.0000 - val_loss: 3.8418 - val_acc: 0.0000e+00\n",
            "Epoch 85/1000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0312 - acc: 1.0000 - val_loss: 3.8790 - val_acc: 0.0000e+00\n",
            "Epoch 86/1000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0303 - acc: 1.0000 - val_loss: 3.9156 - val_acc: 0.0000e+00\n",
            "Epoch 87/1000\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.0294 - acc: 1.0000 - val_loss: 3.9514 - val_acc: 0.0000e+00\n",
            "Epoch 88/1000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.0286 - acc: 1.0000 - val_loss: 3.9863 - val_acc: 0.0000e+00\n",
            "Epoch 89/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0278 - acc: 1.0000 - val_loss: 4.0201 - val_acc: 0.0000e+00\n",
            "Epoch 90/1000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0271 - acc: 1.0000 - val_loss: 4.0527 - val_acc: 0.0000e+00\n",
            "Epoch 91/1000\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.0264 - acc: 1.0000 - val_loss: 4.0838 - val_acc: 0.0000e+00\n",
            "Epoch 92/1000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0257 - acc: 1.0000 - val_loss: 4.1137 - val_acc: 0.0000e+00\n",
            "Epoch 93/1000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0251 - acc: 1.0000 - val_loss: 4.1422 - val_acc: 0.0000e+00\n",
            "Epoch 94/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0245 - acc: 1.0000 - val_loss: 4.1695 - val_acc: 0.0000e+00\n",
            "Epoch 95/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0239 - acc: 1.0000 - val_loss: 4.1957 - val_acc: 0.0000e+00\n",
            "Epoch 96/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0234 - acc: 1.0000 - val_loss: 4.2208 - val_acc: 0.0000e+00\n",
            "Epoch 97/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0229 - acc: 1.0000 - val_loss: 4.2450 - val_acc: 0.0000e+00\n",
            "Epoch 98/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0224 - acc: 1.0000 - val_loss: 4.2683 - val_acc: 0.0000e+00\n",
            "Epoch 99/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0219 - acc: 1.0000 - val_loss: 4.2909 - val_acc: 0.0000e+00\n",
            "Epoch 100/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.0215 - acc: 1.0000 - val_loss: 4.3128 - val_acc: 0.0000e+00\n",
            "Epoch 101/1000\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.0211 - acc: 1.0000 - val_loss: 4.3340 - val_acc: 0.0000e+00\n",
            "Epoch 102/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0207 - acc: 1.0000 - val_loss: 4.3546 - val_acc: 0.0000e+00\n",
            "Epoch 103/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0203 - acc: 1.0000 - val_loss: 4.3747 - val_acc: 0.0000e+00\n",
            "Epoch 104/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0199 - acc: 1.0000 - val_loss: 4.3943 - val_acc: 0.0000e+00\n",
            "Epoch 105/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0195 - acc: 1.0000 - val_loss: 4.4134 - val_acc: 0.0000e+00\n",
            "Epoch 106/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0192 - acc: 1.0000 - val_loss: 4.4321 - val_acc: 0.0000e+00\n",
            "Epoch 107/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0189 - acc: 1.0000 - val_loss: 4.4504 - val_acc: 0.0000e+00\n",
            "Epoch 108/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0185 - acc: 1.0000 - val_loss: 4.4683 - val_acc: 0.0000e+00\n",
            "Epoch 109/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0182 - acc: 1.0000 - val_loss: 4.4859 - val_acc: 0.0000e+00\n",
            "Epoch 110/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0179 - acc: 1.0000 - val_loss: 4.5031 - val_acc: 0.0000e+00\n",
            "Epoch 111/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.0176 - acc: 1.0000 - val_loss: 4.5200 - val_acc: 0.0000e+00\n",
            "Epoch 112/1000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0173 - acc: 1.0000 - val_loss: 4.5367 - val_acc: 0.0000e+00\n",
            "Epoch 113/1000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0171 - acc: 1.0000 - val_loss: 4.5530 - val_acc: 0.0000e+00\n",
            "Epoch 114/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0168 - acc: 1.0000 - val_loss: 4.5691 - val_acc: 0.0000e+00\n",
            "Epoch 115/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0165 - acc: 1.0000 - val_loss: 4.5849 - val_acc: 0.0000e+00\n",
            "Epoch 116/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0163 - acc: 1.0000 - val_loss: 4.6005 - val_acc: 0.0000e+00\n",
            "Epoch 117/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0160 - acc: 1.0000 - val_loss: 4.6159 - val_acc: 0.0000e+00\n",
            "Epoch 118/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0158 - acc: 1.0000 - val_loss: 4.6310 - val_acc: 0.0000e+00\n",
            "Epoch 119/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0156 - acc: 1.0000 - val_loss: 4.6459 - val_acc: 0.0000e+00\n",
            "Epoch 120/1000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0153 - acc: 1.0000 - val_loss: 4.6606 - val_acc: 0.0000e+00\n",
            "Epoch 121/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0151 - acc: 1.0000 - val_loss: 4.6752 - val_acc: 0.0000e+00\n",
            "Epoch 122/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0149 - acc: 1.0000 - val_loss: 4.6895 - val_acc: 0.0000e+00\n",
            "Epoch 123/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0147 - acc: 1.0000 - val_loss: 4.7037 - val_acc: 0.0000e+00\n",
            "Epoch 124/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0145 - acc: 1.0000 - val_loss: 4.7176 - val_acc: 0.0000e+00\n",
            "Epoch 125/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0143 - acc: 1.0000 - val_loss: 4.7315 - val_acc: 0.0000e+00\n",
            "Epoch 126/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0141 - acc: 1.0000 - val_loss: 4.7451 - val_acc: 0.0000e+00\n",
            "Epoch 127/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0139 - acc: 1.0000 - val_loss: 4.7586 - val_acc: 0.0000e+00\n",
            "Epoch 128/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0137 - acc: 1.0000 - val_loss: 4.7720 - val_acc: 0.0000e+00\n",
            "Epoch 129/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0135 - acc: 1.0000 - val_loss: 4.7852 - val_acc: 0.0000e+00\n",
            "Epoch 130/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0133 - acc: 1.0000 - val_loss: 4.7982 - val_acc: 0.0000e+00\n",
            "Epoch 131/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0132 - acc: 1.0000 - val_loss: 4.8112 - val_acc: 0.0000e+00\n",
            "Epoch 132/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0130 - acc: 1.0000 - val_loss: 4.8240 - val_acc: 0.0000e+00\n",
            "Epoch 133/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0128 - acc: 1.0000 - val_loss: 4.8366 - val_acc: 0.0000e+00\n",
            "Epoch 134/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0127 - acc: 1.0000 - val_loss: 4.8492 - val_acc: 0.0000e+00\n",
            "Epoch 135/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.0125 - acc: 1.0000 - val_loss: 4.8616 - val_acc: 0.0000e+00\n",
            "Epoch 136/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0124 - acc: 1.0000 - val_loss: 4.8739 - val_acc: 0.0000e+00\n",
            "Epoch 137/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0122 - acc: 1.0000 - val_loss: 4.8861 - val_acc: 0.0000e+00\n",
            "Epoch 138/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0121 - acc: 1.0000 - val_loss: 4.8982 - val_acc: 0.0000e+00\n",
            "Epoch 139/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.0119 - acc: 1.0000 - val_loss: 4.9101 - val_acc: 0.0000e+00\n",
            "Epoch 140/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0118 - acc: 1.0000 - val_loss: 4.9220 - val_acc: 0.0000e+00\n",
            "Epoch 141/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0116 - acc: 1.0000 - val_loss: 4.9338 - val_acc: 0.0000e+00\n",
            "Epoch 142/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0115 - acc: 1.0000 - val_loss: 4.9454 - val_acc: 0.0000e+00\n",
            "Epoch 143/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0113 - acc: 1.0000 - val_loss: 4.9570 - val_acc: 0.0000e+00\n",
            "Epoch 144/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0112 - acc: 1.0000 - val_loss: 4.9685 - val_acc: 0.0000e+00\n",
            "Epoch 145/1000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0111 - acc: 1.0000 - val_loss: 4.9798 - val_acc: 0.0000e+00\n",
            "Epoch 146/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0110 - acc: 1.0000 - val_loss: 4.9911 - val_acc: 0.0000e+00\n",
            "Epoch 147/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0108 - acc: 1.0000 - val_loss: 5.0023 - val_acc: 0.0000e+00\n",
            "Epoch 148/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0107 - acc: 1.0000 - val_loss: 5.0134 - val_acc: 0.0000e+00\n",
            "Epoch 149/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0106 - acc: 1.0000 - val_loss: 5.0245 - val_acc: 0.0000e+00\n",
            "Epoch 150/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.0105 - acc: 1.0000 - val_loss: 5.0354 - val_acc: 0.0000e+00\n",
            "Epoch 151/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0104 - acc: 1.0000 - val_loss: 5.0463 - val_acc: 0.0000e+00\n",
            "Epoch 152/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0102 - acc: 1.0000 - val_loss: 5.0571 - val_acc: 0.0000e+00\n",
            "Epoch 153/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0101 - acc: 1.0000 - val_loss: 5.0678 - val_acc: 0.0000e+00\n",
            "Epoch 154/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0100 - acc: 1.0000 - val_loss: 5.0784 - val_acc: 0.0000e+00\n",
            "Epoch 155/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0099 - acc: 1.0000 - val_loss: 5.0890 - val_acc: 0.0000e+00\n",
            "Epoch 156/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0098 - acc: 1.0000 - val_loss: 5.0995 - val_acc: 0.0000e+00\n",
            "Epoch 157/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0097 - acc: 1.0000 - val_loss: 5.1099 - val_acc: 0.0000e+00\n",
            "Epoch 158/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0096 - acc: 1.0000 - val_loss: 5.1202 - val_acc: 0.0000e+00\n",
            "Epoch 159/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0095 - acc: 1.0000 - val_loss: 5.1305 - val_acc: 0.0000e+00\n",
            "Epoch 160/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0094 - acc: 1.0000 - val_loss: 5.1407 - val_acc: 0.0000e+00\n",
            "Epoch 161/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0093 - acc: 1.0000 - val_loss: 5.1509 - val_acc: 0.0000e+00\n",
            "Epoch 162/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0092 - acc: 1.0000 - val_loss: 5.1610 - val_acc: 0.0000e+00\n",
            "Epoch 163/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0091 - acc: 1.0000 - val_loss: 5.1710 - val_acc: 0.0000e+00\n",
            "Epoch 164/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0090 - acc: 1.0000 - val_loss: 5.1810 - val_acc: 0.0000e+00\n",
            "Epoch 165/1000\n",
            "1/1 [==============================] - 0s 77ms/step - loss: 0.0089 - acc: 1.0000 - val_loss: 5.1909 - val_acc: 0.0000e+00\n",
            "Epoch 166/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.0088 - acc: 1.0000 - val_loss: 5.2008 - val_acc: 0.0000e+00\n",
            "Epoch 167/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0087 - acc: 1.0000 - val_loss: 5.2106 - val_acc: 0.0000e+00\n",
            "Epoch 168/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0087 - acc: 1.0000 - val_loss: 5.2203 - val_acc: 0.0000e+00\n",
            "Epoch 169/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0086 - acc: 1.0000 - val_loss: 5.2300 - val_acc: 0.0000e+00\n",
            "Epoch 170/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0085 - acc: 1.0000 - val_loss: 5.2397 - val_acc: 0.0000e+00\n",
            "Epoch 171/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.0084 - acc: 1.0000 - val_loss: 5.2493 - val_acc: 0.0000e+00\n",
            "Epoch 172/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0083 - acc: 1.0000 - val_loss: 5.2588 - val_acc: 0.0000e+00\n",
            "Epoch 173/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0082 - acc: 1.0000 - val_loss: 5.2683 - val_acc: 0.0000e+00\n",
            "Epoch 174/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0082 - acc: 1.0000 - val_loss: 5.2778 - val_acc: 0.0000e+00\n",
            "Epoch 175/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0081 - acc: 1.0000 - val_loss: 5.2872 - val_acc: 0.0000e+00\n",
            "Epoch 176/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0080 - acc: 1.0000 - val_loss: 5.2965 - val_acc: 0.0000e+00\n",
            "Epoch 177/1000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.0079 - acc: 1.0000 - val_loss: 5.3058 - val_acc: 0.0000e+00\n",
            "Epoch 178/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0079 - acc: 1.0000 - val_loss: 5.3151 - val_acc: 0.0000e+00\n",
            "Epoch 179/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0078 - acc: 1.0000 - val_loss: 5.3243 - val_acc: 0.0000e+00\n",
            "Epoch 180/1000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0077 - acc: 1.0000 - val_loss: 5.3335 - val_acc: 0.0000e+00\n",
            "Epoch 181/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0076 - acc: 1.0000 - val_loss: 5.3426 - val_acc: 0.0000e+00\n",
            "Epoch 182/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0076 - acc: 1.0000 - val_loss: 5.3517 - val_acc: 0.0000e+00\n",
            "Epoch 183/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0075 - acc: 1.0000 - val_loss: 5.3608 - val_acc: 0.0000e+00\n",
            "Epoch 184/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 5.3698 - val_acc: 0.0000e+00\n",
            "Epoch 185/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0074 - acc: 1.0000 - val_loss: 5.3787 - val_acc: 0.0000e+00\n",
            "Epoch 186/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0073 - acc: 1.0000 - val_loss: 5.3877 - val_acc: 0.0000e+00\n",
            "Epoch 187/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0072 - acc: 1.0000 - val_loss: 5.3966 - val_acc: 0.0000e+00\n",
            "Epoch 188/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0072 - acc: 1.0000 - val_loss: 5.4054 - val_acc: 0.0000e+00\n",
            "Epoch 189/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0071 - acc: 1.0000 - val_loss: 5.4142 - val_acc: 0.0000e+00\n",
            "Epoch 190/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0071 - acc: 1.0000 - val_loss: 5.4230 - val_acc: 0.0000e+00\n",
            "Epoch 191/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 5.4317 - val_acc: 0.0000e+00\n",
            "Epoch 192/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0069 - acc: 1.0000 - val_loss: 5.4405 - val_acc: 0.0000e+00\n",
            "Epoch 193/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0069 - acc: 1.0000 - val_loss: 5.4491 - val_acc: 0.0000e+00\n",
            "Epoch 194/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 5.4577 - val_acc: 0.0000e+00\n",
            "Epoch 195/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0068 - acc: 1.0000 - val_loss: 5.4663 - val_acc: 0.0000e+00\n",
            "Epoch 196/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0067 - acc: 1.0000 - val_loss: 5.4749 - val_acc: 0.0000e+00\n",
            "Epoch 197/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 5.4834 - val_acc: 0.0000e+00\n",
            "Epoch 198/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0066 - acc: 1.0000 - val_loss: 5.4919 - val_acc: 0.0000e+00\n",
            "Epoch 199/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 5.5003 - val_acc: 0.0000e+00\n",
            "Epoch 200/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0065 - acc: 1.0000 - val_loss: 5.5087 - val_acc: 0.0000e+00\n",
            "Epoch 201/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0064 - acc: 1.0000 - val_loss: 5.5171 - val_acc: 0.0000e+00\n",
            "Epoch 202/1000\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 0.0064 - acc: 1.0000 - val_loss: 5.5254 - val_acc: 0.0000e+00\n",
            "Epoch 203/1000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 5.5337 - val_acc: 0.0000e+00\n",
            "Epoch 204/1000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 5.5419 - val_acc: 0.0000e+00\n",
            "Epoch 205/1000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 5.5502 - val_acc: 0.0000e+00\n",
            "Epoch 206/1000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0062 - acc: 1.0000 - val_loss: 5.5583 - val_acc: 0.0000e+00\n",
            "Epoch 207/1000\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 5.5665 - val_acc: 0.0000e+00\n",
            "Epoch 208/1000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 5.5746 - val_acc: 0.0000e+00\n",
            "Epoch 209/1000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 5.5826 - val_acc: 0.0000e+00\n",
            "Epoch 210/1000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.0060 - acc: 1.0000 - val_loss: 5.5906 - val_acc: 0.0000e+00\n",
            "Epoch 211/1000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 5.5986 - val_acc: 0.0000e+00\n",
            "Epoch 212/1000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0059 - acc: 1.0000 - val_loss: 5.6065 - val_acc: 0.0000e+00\n",
            "Epoch 213/1000\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 5.6144 - val_acc: 0.0000e+00\n",
            "Epoch 214/1000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 5.6223 - val_acc: 0.0000e+00\n",
            "Epoch 215/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0058 - acc: 1.0000 - val_loss: 5.6301 - val_acc: 0.0000e+00\n",
            "Epoch 216/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 5.6379 - val_acc: 0.0000e+00\n",
            "Epoch 217/1000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.0057 - acc: 1.0000 - val_loss: 5.6456 - val_acc: 0.0000e+00\n",
            "Epoch 218/1000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 5.6533 - val_acc: 0.0000e+00\n",
            "Epoch 219/1000\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.0056 - acc: 1.0000 - val_loss: 5.6610 - val_acc: 0.0000e+00\n",
            "Epoch 220/1000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 5.6686 - val_acc: 0.0000e+00\n",
            "Epoch 221/1000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 5.6761 - val_acc: 0.0000e+00\n",
            "Epoch 222/1000\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 0.0055 - acc: 1.0000 - val_loss: 5.6837 - val_acc: 0.0000e+00\n",
            "Epoch 223/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 5.6912 - val_acc: 0.0000e+00\n",
            "Epoch 224/1000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.0054 - acc: 1.0000 - val_loss: 5.6986 - val_acc: 0.0000e+00\n",
            "Epoch 225/1000\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 5.7060 - val_acc: 0.0000e+00\n",
            "Epoch 226/1000\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 5.7134 - val_acc: 0.0000e+00\n",
            "Epoch 227/1000\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 5.7208 - val_acc: 0.0000e+00\n",
            "Epoch 228/1000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 5.7281 - val_acc: 0.0000e+00\n",
            "Epoch 229/1000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 5.7353 - val_acc: 0.0000e+00\n",
            "Epoch 230/1000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0052 - acc: 1.0000 - val_loss: 5.7426 - val_acc: 0.0000e+00\n",
            "Epoch 231/1000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 5.7498 - val_acc: 0.0000e+00\n",
            "Epoch 232/1000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 5.7569 - val_acc: 0.0000e+00\n",
            "Epoch 233/1000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.0051 - acc: 1.0000 - val_loss: 5.7640 - val_acc: 0.0000e+00\n",
            "Epoch 234/1000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 5.7711 - val_acc: 0.0000e+00\n",
            "Epoch 235/1000\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 5.7782 - val_acc: 0.0000e+00\n",
            "Epoch 236/1000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.0050 - acc: 1.0000 - val_loss: 5.7852 - val_acc: 0.0000e+00\n",
            "Epoch 237/1000\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 5.7921 - val_acc: 0.0000e+00\n",
            "Epoch 238/1000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 5.7991 - val_acc: 0.0000e+00\n",
            "Epoch 239/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0049 - acc: 1.0000 - val_loss: 5.8060 - val_acc: 0.0000e+00\n",
            "Epoch 240/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 5.8129 - val_acc: 0.0000e+00\n",
            "Epoch 241/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 5.8197 - val_acc: 0.0000e+00\n",
            "Epoch 242/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 5.8265 - val_acc: 0.0000e+00\n",
            "Epoch 243/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 5.8333 - val_acc: 0.0000e+00\n",
            "Epoch 244/1000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 5.8400 - val_acc: 0.0000e+00\n",
            "Epoch 245/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 5.8467 - val_acc: 0.0000e+00\n",
            "Epoch 246/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 5.8534 - val_acc: 0.0000e+00\n",
            "Epoch 247/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 5.8600 - val_acc: 0.0000e+00\n",
            "Epoch 248/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0046 - acc: 1.0000 - val_loss: 5.8667 - val_acc: 0.0000e+00\n",
            "Epoch 249/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 5.8732 - val_acc: 0.0000e+00\n",
            "Epoch 250/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 5.8798 - val_acc: 0.0000e+00\n",
            "Epoch 251/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 5.8863 - val_acc: 0.0000e+00\n",
            "Epoch 252/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0045 - acc: 1.0000 - val_loss: 5.8928 - val_acc: 0.0000e+00\n",
            "Epoch 253/1000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 5.8993 - val_acc: 0.0000e+00\n",
            "Epoch 254/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 5.9057 - val_acc: 0.0000e+00\n",
            "Epoch 255/1000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 5.9121 - val_acc: 0.0000e+00\n",
            "Epoch 256/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 5.9185 - val_acc: 0.0000e+00\n",
            "Epoch 257/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 5.9248 - val_acc: 0.0000e+00\n",
            "Epoch 258/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 5.9312 - val_acc: 0.0000e+00\n",
            "Epoch 259/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 5.9375 - val_acc: 0.0000e+00\n",
            "Epoch 260/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 5.9437 - val_acc: 0.0000e+00\n",
            "Epoch 261/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 5.9500 - val_acc: 0.0000e+00\n",
            "Epoch 262/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 5.9562 - val_acc: 0.0000e+00\n",
            "Epoch 263/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 5.9624 - val_acc: 0.0000e+00\n",
            "Epoch 264/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 5.9685 - val_acc: 0.0000e+00\n",
            "Epoch 265/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 5.9747 - val_acc: 0.0000e+00\n",
            "Epoch 266/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 5.9808 - val_acc: 0.0000e+00\n",
            "Epoch 267/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 5.9869 - val_acc: 0.0000e+00\n",
            "Epoch 268/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 5.9929 - val_acc: 0.0000e+00\n",
            "Epoch 269/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 5.9989 - val_acc: 0.0000e+00\n",
            "Epoch 270/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 6.0050 - val_acc: 0.0000e+00\n",
            "Epoch 271/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0040 - acc: 1.0000 - val_loss: 6.0109 - val_acc: 0.0000e+00\n",
            "Epoch 272/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 6.0169 - val_acc: 0.0000e+00\n",
            "Epoch 273/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 6.0228 - val_acc: 0.0000e+00\n",
            "Epoch 274/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 6.0288 - val_acc: 0.0000e+00\n",
            "Epoch 275/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 6.0346 - val_acc: 0.0000e+00\n",
            "Epoch 276/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 6.0405 - val_acc: 0.0000e+00\n",
            "Epoch 277/1000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 6.0463 - val_acc: 0.0000e+00\n",
            "Epoch 278/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 6.0522 - val_acc: 0.0000e+00\n",
            "Epoch 279/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 6.0580 - val_acc: 0.0000e+00\n",
            "Epoch 280/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0038 - acc: 1.0000 - val_loss: 6.0637 - val_acc: 0.0000e+00\n",
            "Epoch 281/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 6.0695 - val_acc: 0.0000e+00\n",
            "Epoch 282/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 6.0752 - val_acc: 0.0000e+00\n",
            "Epoch 283/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 6.0809 - val_acc: 0.0000e+00\n",
            "Epoch 284/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 6.0866 - val_acc: 0.0000e+00\n",
            "Epoch 285/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0037 - acc: 1.0000 - val_loss: 6.0922 - val_acc: 0.0000e+00\n",
            "Epoch 286/1000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 6.0979 - val_acc: 0.0000e+00\n",
            "Epoch 287/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 6.1035 - val_acc: 0.0000e+00\n",
            "Epoch 288/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 6.1091 - val_acc: 0.0000e+00\n",
            "Epoch 289/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 6.1147 - val_acc: 0.0000e+00\n",
            "Epoch 290/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0036 - acc: 1.0000 - val_loss: 6.1202 - val_acc: 0.0000e+00\n",
            "Epoch 291/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 6.1257 - val_acc: 0.0000e+00\n",
            "Epoch 292/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 6.1312 - val_acc: 0.0000e+00\n",
            "Epoch 293/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 6.1367 - val_acc: 0.0000e+00\n",
            "Epoch 294/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 6.1422 - val_acc: 0.0000e+00\n",
            "Epoch 295/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 6.1476 - val_acc: 0.0000e+00\n",
            "Epoch 296/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 6.1530 - val_acc: 0.0000e+00\n",
            "Epoch 297/1000\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 6.1584 - val_acc: 0.0000e+00\n",
            "Epoch 298/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 6.1638 - val_acc: 0.0000e+00\n",
            "Epoch 299/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 6.1692 - val_acc: 0.0000e+00\n",
            "Epoch 300/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 6.1745 - val_acc: 0.0000e+00\n",
            "Epoch 301/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0034 - acc: 1.0000 - val_loss: 6.1798 - val_acc: 0.0000e+00\n",
            "Epoch 302/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 6.1851 - val_acc: 0.0000e+00\n",
            "Epoch 303/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 6.1904 - val_acc: 0.0000e+00\n",
            "Epoch 304/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 6.1956 - val_acc: 0.0000e+00\n",
            "Epoch 305/1000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 6.2009 - val_acc: 0.0000e+00\n",
            "Epoch 306/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 6.2061 - val_acc: 0.0000e+00\n",
            "Epoch 307/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 6.2113 - val_acc: 0.0000e+00\n",
            "Epoch 308/1000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 6.2164 - val_acc: 0.0000e+00\n",
            "Epoch 309/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 6.2216 - val_acc: 0.0000e+00\n",
            "Epoch 310/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 6.2267 - val_acc: 0.0000e+00\n",
            "Epoch 311/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 6.2318 - val_acc: 0.0000e+00\n",
            "Epoch 312/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 6.2369 - val_acc: 0.0000e+00\n",
            "Epoch 313/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 6.2420 - val_acc: 0.0000e+00\n",
            "Epoch 314/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 6.2471 - val_acc: 0.0000e+00\n",
            "Epoch 315/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 6.2521 - val_acc: 0.0000e+00\n",
            "Epoch 316/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 6.2571 - val_acc: 0.0000e+00\n",
            "Epoch 317/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 6.2621 - val_acc: 0.0000e+00\n",
            "Epoch 318/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 6.2671 - val_acc: 0.0000e+00\n",
            "Epoch 319/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0031 - acc: 1.0000 - val_loss: 6.2720 - val_acc: 0.0000e+00\n",
            "Epoch 320/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 6.2770 - val_acc: 0.0000e+00\n",
            "Epoch 321/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 6.2819 - val_acc: 0.0000e+00\n",
            "Epoch 322/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 6.2868 - val_acc: 0.0000e+00\n",
            "Epoch 323/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 6.2917 - val_acc: 0.0000e+00\n",
            "Epoch 324/1000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 6.2966 - val_acc: 0.0000e+00\n",
            "Epoch 325/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 6.3014 - val_acc: 0.0000e+00\n",
            "Epoch 326/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 6.3063 - val_acc: 0.0000e+00\n",
            "Epoch 327/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 6.3111 - val_acc: 0.0000e+00\n",
            "Epoch 328/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 6.3159 - val_acc: 0.0000e+00\n",
            "Epoch 329/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 6.3207 - val_acc: 0.0000e+00\n",
            "Epoch 330/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 6.3254 - val_acc: 0.0000e+00\n",
            "Epoch 331/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 6.3302 - val_acc: 0.0000e+00\n",
            "Epoch 332/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 6.3349 - val_acc: 0.0000e+00\n",
            "Epoch 333/1000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 6.3396 - val_acc: 0.0000e+00\n",
            "Epoch 334/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 6.3443 - val_acc: 0.0000e+00\n",
            "Epoch 335/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 6.3490 - val_acc: 0.0000e+00\n",
            "Epoch 336/1000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 6.3537 - val_acc: 0.0000e+00\n",
            "Epoch 337/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 6.3583 - val_acc: 0.0000e+00\n",
            "Epoch 338/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 6.3629 - val_acc: 0.0000e+00\n",
            "Epoch 339/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 6.3676 - val_acc: 0.0000e+00\n",
            "Epoch 340/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 6.3722 - val_acc: 0.0000e+00\n",
            "Epoch 341/1000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0028 - acc: 1.0000 - val_loss: 6.3767 - val_acc: 0.0000e+00\n",
            "Epoch 342/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 6.3813 - val_acc: 0.0000e+00\n",
            "Epoch 343/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 6.3859 - val_acc: 0.0000e+00\n",
            "Epoch 344/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 6.3904 - val_acc: 0.0000e+00\n",
            "Epoch 345/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 6.3949 - val_acc: 0.0000e+00\n",
            "Epoch 346/1000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 6.3995 - val_acc: 0.0000e+00\n",
            "Epoch 347/1000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 6.4039 - val_acc: 0.0000e+00\n",
            "Epoch 348/1000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 6.4084 - val_acc: 0.0000e+00\n",
            "Epoch 349/1000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 6.4129 - val_acc: 0.0000e+00\n",
            "Epoch 350/1000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 6.4174 - val_acc: 0.0000e+00\n",
            "Epoch 351/1000\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 6.4218 - val_acc: 0.0000e+00\n",
            "Epoch 352/1000\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 6.4262 - val_acc: 0.0000e+00\n",
            "Epoch 353/1000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 6.4306 - val_acc: 0.0000e+00\n",
            "Epoch 354/1000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 6.4350 - val_acc: 0.0000e+00\n",
            "Epoch 355/1000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 6.4394 - val_acc: 0.0000e+00\n",
            "Epoch 356/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 6.4438 - val_acc: 0.0000e+00\n",
            "Epoch 357/1000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 6.4481 - val_acc: 0.0000e+00\n",
            "Epoch 358/1000\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 6.4525 - val_acc: 0.0000e+00\n",
            "Epoch 359/1000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 6.4568 - val_acc: 0.0000e+00\n",
            "Epoch 360/1000\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 6.4611 - val_acc: 0.0000e+00\n",
            "Epoch 361/1000\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 6.4654 - val_acc: 0.0000e+00\n",
            "Epoch 362/1000\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 6.4697 - val_acc: 0.0000e+00\n",
            "Epoch 363/1000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 6.4740 - val_acc: 0.0000e+00\n",
            "Epoch 364/1000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 6.4783 - val_acc: 0.0000e+00\n",
            "Epoch 365/1000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 6.4825 - val_acc: 0.0000e+00\n",
            "Epoch 366/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 6.4868 - val_acc: 0.0000e+00\n",
            "Epoch 367/1000\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 6.4910 - val_acc: 0.0000e+00\n",
            "Epoch 368/1000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 6.4952 - val_acc: 0.0000e+00\n",
            "Epoch 369/1000\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 6.4994 - val_acc: 0.0000e+00\n",
            "Epoch 370/1000\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 6.5036 - val_acc: 0.0000e+00\n",
            "Epoch 371/1000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 6.5078 - val_acc: 0.0000e+00\n",
            "Epoch 372/1000\n",
            "1/1 [==============================] - 0s 154ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 6.5120 - val_acc: 0.0000e+00\n",
            "Epoch 373/1000\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 6.5161 - val_acc: 0.0000e+00\n",
            "Epoch 374/1000\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 6.5203 - val_acc: 0.0000e+00\n",
            "Epoch 375/1000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 6.5244 - val_acc: 0.0000e+00\n",
            "Epoch 376/1000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 6.5285 - val_acc: 0.0000e+00\n",
            "Epoch 377/1000\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 6.5327 - val_acc: 0.0000e+00\n",
            "Epoch 378/1000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 6.5368 - val_acc: 0.0000e+00\n",
            "Epoch 379/1000\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 6.5409 - val_acc: 0.0000e+00\n",
            "Epoch 380/1000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 6.5449 - val_acc: 0.0000e+00\n",
            "Epoch 381/1000\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 6.5490 - val_acc: 0.0000e+00\n",
            "Epoch 382/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 6.5531 - val_acc: 0.0000e+00\n",
            "Epoch 383/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 6.5571 - val_acc: 0.0000e+00\n",
            "Epoch 384/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 6.5612 - val_acc: 0.0000e+00\n",
            "Epoch 385/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 6.5652 - val_acc: 0.0000e+00\n",
            "Epoch 386/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 6.5692 - val_acc: 0.0000e+00\n",
            "Epoch 387/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 6.5732 - val_acc: 0.0000e+00\n",
            "Epoch 388/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0023 - acc: 1.0000 - val_loss: 6.5772 - val_acc: 0.0000e+00\n",
            "Epoch 389/1000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 6.5812 - val_acc: 0.0000e+00\n",
            "Epoch 390/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 6.5852 - val_acc: 0.0000e+00\n",
            "Epoch 391/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 6.5891 - val_acc: 0.0000e+00\n",
            "Epoch 392/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 6.5931 - val_acc: 0.0000e+00\n",
            "Epoch 393/1000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 6.5970 - val_acc: 0.0000e+00\n",
            "Epoch 394/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 6.6010 - val_acc: 0.0000e+00\n",
            "Epoch 395/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 6.6049 - val_acc: 0.0000e+00\n",
            "Epoch 396/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 6.6088 - val_acc: 0.0000e+00\n",
            "Epoch 397/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 6.6127 - val_acc: 0.0000e+00\n",
            "Epoch 398/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 6.6166 - val_acc: 0.0000e+00\n",
            "Epoch 399/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0022 - acc: 1.0000 - val_loss: 6.6205 - val_acc: 0.0000e+00\n",
            "Epoch 400/1000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 6.6244 - val_acc: 0.0000e+00\n",
            "Epoch 401/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 6.6283 - val_acc: 0.0000e+00\n",
            "Epoch 402/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 6.6321 - val_acc: 0.0000e+00\n",
            "Epoch 403/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 6.6360 - val_acc: 0.0000e+00\n",
            "Epoch 404/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 6.6398 - val_acc: 0.0000e+00\n",
            "Epoch 405/1000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 6.6436 - val_acc: 0.0000e+00\n",
            "Epoch 406/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 6.6475 - val_acc: 0.0000e+00\n",
            "Epoch 407/1000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 6.6513 - val_acc: 0.0000e+00\n",
            "Epoch 408/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 6.6551 - val_acc: 0.0000e+00\n",
            "Epoch 409/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 6.6589 - val_acc: 0.0000e+00\n",
            "Epoch 410/1000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 6.6627 - val_acc: 0.0000e+00\n",
            "Epoch 411/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0021 - acc: 1.0000 - val_loss: 6.6665 - val_acc: 0.0000e+00\n",
            "Epoch 412/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 6.6702 - val_acc: 0.0000e+00\n",
            "Epoch 413/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 6.6740 - val_acc: 0.0000e+00\n",
            "Epoch 414/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 6.6777 - val_acc: 0.0000e+00\n",
            "Epoch 415/1000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 6.6815 - val_acc: 0.0000e+00\n",
            "Epoch 416/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 6.6852 - val_acc: 0.0000e+00\n",
            "Epoch 417/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 6.6889 - val_acc: 0.0000e+00\n",
            "Epoch 418/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 6.6927 - val_acc: 0.0000e+00\n",
            "Epoch 419/1000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 6.6964 - val_acc: 0.0000e+00\n",
            "Epoch 420/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 6.7001 - val_acc: 0.0000e+00\n",
            "Epoch 421/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 6.7038 - val_acc: 0.0000e+00\n",
            "Epoch 422/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 6.7075 - val_acc: 0.0000e+00\n",
            "Epoch 423/1000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 6.7111 - val_acc: 0.0000e+00\n",
            "Epoch 424/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0020 - acc: 1.0000 - val_loss: 6.7148 - val_acc: 0.0000e+00\n",
            "Epoch 425/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 6.7185 - val_acc: 0.0000e+00\n",
            "Epoch 426/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 6.7221 - val_acc: 0.0000e+00\n",
            "Epoch 427/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 6.7258 - val_acc: 0.0000e+00\n",
            "Epoch 428/1000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 6.7294 - val_acc: 0.0000e+00\n",
            "Epoch 429/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 6.7330 - val_acc: 0.0000e+00\n",
            "Epoch 430/1000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 6.7367 - val_acc: 0.0000e+00\n",
            "Epoch 431/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 6.7403 - val_acc: 0.0000e+00\n",
            "Epoch 432/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 6.7439 - val_acc: 0.0000e+00\n",
            "Epoch 433/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 6.7475 - val_acc: 0.0000e+00\n",
            "Epoch 434/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 6.7511 - val_acc: 0.0000e+00\n",
            "Epoch 435/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 6.7546 - val_acc: 0.0000e+00\n",
            "Epoch 436/1000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 6.7582 - val_acc: 0.0000e+00\n",
            "Epoch 437/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 6.7618 - val_acc: 0.0000e+00\n",
            "Epoch 438/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 6.7653 - val_acc: 0.0000e+00\n",
            "Epoch 439/1000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 6.7689 - val_acc: 0.0000e+00\n",
            "Epoch 440/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 6.7724 - val_acc: 0.0000e+00\n",
            "Epoch 441/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 6.7760 - val_acc: 0.0000e+00\n",
            "Epoch 442/1000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 6.7795 - val_acc: 0.0000e+00\n",
            "Epoch 443/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 6.7830 - val_acc: 0.0000e+00\n",
            "Epoch 444/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 6.7865 - val_acc: 0.0000e+00\n",
            "Epoch 445/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 6.7901 - val_acc: 0.0000e+00\n",
            "Epoch 446/1000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 6.7936 - val_acc: 0.0000e+00\n",
            "Epoch 447/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 6.7971 - val_acc: 0.0000e+00\n",
            "Epoch 448/1000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 6.8005 - val_acc: 0.0000e+00\n",
            "Epoch 449/1000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 6.8040 - val_acc: 0.0000e+00\n",
            "Epoch 450/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 6.8075 - val_acc: 0.0000e+00\n",
            "Epoch 451/1000\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 6.8110 - val_acc: 0.0000e+00\n",
            "Epoch 452/1000\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 6.8144 - val_acc: 0.0000e+00\n",
            "Epoch 453/1000\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 6.8179 - val_acc: 0.0000e+00\n",
            "Epoch 454/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 6.8213 - val_acc: 0.0000e+00\n",
            "Epoch 455/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 6.8247 - val_acc: 0.0000e+00\n",
            "Epoch 456/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 6.8282 - val_acc: 0.0000e+00\n",
            "Epoch 457/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 6.8316 - val_acc: 0.0000e+00\n",
            "Epoch 458/1000\n",
            "1/1 [==============================] - 0s 245ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 6.8350 - val_acc: 0.0000e+00\n",
            "Epoch 459/1000\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 6.8384 - val_acc: 0.0000e+00\n",
            "Epoch 460/1000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 6.8418 - val_acc: 0.0000e+00\n",
            "Epoch 461/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 6.8452 - val_acc: 0.0000e+00\n",
            "Epoch 462/1000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 6.8486 - val_acc: 0.0000e+00\n",
            "Epoch 463/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 6.8520 - val_acc: 0.0000e+00\n",
            "Epoch 464/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 6.8554 - val_acc: 0.0000e+00\n",
            "Epoch 465/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 6.8587 - val_acc: 0.0000e+00\n",
            "Epoch 466/1000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 6.8621 - val_acc: 0.0000e+00\n",
            "Epoch 467/1000\n",
            "1/1 [==============================] - 0s 228ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 6.8655 - val_acc: 0.0000e+00\n",
            "Epoch 468/1000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 6.8688 - val_acc: 0.0000e+00\n",
            "Epoch 469/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 6.8722 - val_acc: 0.0000e+00\n",
            "Epoch 470/1000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 6.8755 - val_acc: 0.0000e+00\n",
            "Epoch 471/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0017 - acc: 1.0000 - val_loss: 6.8788 - val_acc: 0.0000e+00\n",
            "Epoch 472/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 6.8821 - val_acc: 0.0000e+00\n",
            "Epoch 473/1000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 6.8855 - val_acc: 0.0000e+00\n",
            "Epoch 474/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 6.8888 - val_acc: 0.0000e+00\n",
            "Epoch 475/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 6.8921 - val_acc: 0.0000e+00\n",
            "Epoch 476/1000\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 6.8954 - val_acc: 0.0000e+00\n",
            "Epoch 477/1000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 6.8987 - val_acc: 0.0000e+00\n",
            "Epoch 478/1000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 6.9020 - val_acc: 0.0000e+00\n",
            "Epoch 479/1000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 6.9052 - val_acc: 0.0000e+00\n",
            "Epoch 480/1000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 6.9085 - val_acc: 0.0000e+00\n",
            "Epoch 481/1000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 6.9118 - val_acc: 0.0000e+00\n",
            "Epoch 482/1000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 6.9150 - val_acc: 0.0000e+00\n",
            "Epoch 483/1000\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 6.9183 - val_acc: 0.0000e+00\n",
            "Epoch 484/1000\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 6.9215 - val_acc: 0.0000e+00\n",
            "Epoch 485/1000\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 6.9248 - val_acc: 0.0000e+00\n",
            "Epoch 486/1000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 6.9280 - val_acc: 0.0000e+00\n",
            "Epoch 487/1000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 6.9313 - val_acc: 0.0000e+00\n",
            "Epoch 488/1000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 6.9345 - val_acc: 0.0000e+00\n",
            "Epoch 489/1000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 6.9377 - val_acc: 0.0000e+00\n",
            "Epoch 490/1000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 6.9409 - val_acc: 0.0000e+00\n",
            "Epoch 491/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 6.9441 - val_acc: 0.0000e+00\n",
            "Epoch 492/1000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 6.9473 - val_acc: 0.0000e+00\n",
            "Epoch 493/1000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 6.9505 - val_acc: 0.0000e+00\n",
            "Epoch 494/1000\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 6.9537 - val_acc: 0.0000e+00\n",
            "Epoch 495/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 6.9569 - val_acc: 0.0000e+00\n",
            "Epoch 496/1000\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 6.9601 - val_acc: 0.0000e+00\n",
            "Epoch 497/1000\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 6.9632 - val_acc: 0.0000e+00\n",
            "Epoch 498/1000\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 6.9664 - val_acc: 0.0000e+00\n",
            "Epoch 499/1000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 6.9696 - val_acc: 0.0000e+00\n",
            "Epoch 500/1000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 6.9727 - val_acc: 0.0000e+00\n",
            "Epoch 501/1000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 6.9759 - val_acc: 0.0000e+00\n",
            "Epoch 502/1000\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 6.9790 - val_acc: 0.0000e+00\n",
            "Epoch 503/1000\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 6.9822 - val_acc: 0.0000e+00\n",
            "Epoch 504/1000\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 6.9853 - val_acc: 0.0000e+00\n",
            "Epoch 505/1000\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 6.9884 - val_acc: 0.0000e+00\n",
            "Epoch 506/1000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 6.9915 - val_acc: 0.0000e+00\n",
            "Epoch 507/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 6.9946 - val_acc: 0.0000e+00\n",
            "Epoch 508/1000\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 6.9978 - val_acc: 0.0000e+00\n",
            "Epoch 509/1000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 7.0009 - val_acc: 0.0000e+00\n",
            "Epoch 510/1000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 7.0040 - val_acc: 0.0000e+00\n",
            "Epoch 511/1000\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 7.0071 - val_acc: 0.0000e+00\n",
            "Epoch 512/1000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 7.0101 - val_acc: 0.0000e+00\n",
            "Epoch 513/1000\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 7.0132 - val_acc: 0.0000e+00\n",
            "Epoch 514/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 7.0163 - val_acc: 0.0000e+00\n",
            "Epoch 515/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 7.0194 - val_acc: 0.0000e+00\n",
            "Epoch 516/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 7.0224 - val_acc: 0.0000e+00\n",
            "Epoch 517/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 7.0255 - val_acc: 0.0000e+00\n",
            "Epoch 518/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 7.0286 - val_acc: 0.0000e+00\n",
            "Epoch 519/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 7.0316 - val_acc: 0.0000e+00\n",
            "Epoch 520/1000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 7.0347 - val_acc: 0.0000e+00\n",
            "Epoch 521/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 7.0377 - val_acc: 0.0000e+00\n",
            "Epoch 522/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 7.0407 - val_acc: 0.0000e+00\n",
            "Epoch 523/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 7.0438 - val_acc: 0.0000e+00\n",
            "Epoch 524/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 7.0468 - val_acc: 0.0000e+00\n",
            "Epoch 525/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 7.0498 - val_acc: 0.0000e+00\n",
            "Epoch 526/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 7.0528 - val_acc: 0.0000e+00\n",
            "Epoch 527/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 7.0558 - val_acc: 0.0000e+00\n",
            "Epoch 528/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 7.0588 - val_acc: 0.0000e+00\n",
            "Epoch 529/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 7.0618 - val_acc: 0.0000e+00\n",
            "Epoch 530/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 7.0648 - val_acc: 0.0000e+00\n",
            "Epoch 531/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 7.0678 - val_acc: 0.0000e+00\n",
            "Epoch 532/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 7.0708 - val_acc: 0.0000e+00\n",
            "Epoch 533/1000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 7.0738 - val_acc: 0.0000e+00\n",
            "Epoch 534/1000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 7.0768 - val_acc: 0.0000e+00\n",
            "Epoch 535/1000\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 7.0797 - val_acc: 0.0000e+00\n",
            "Epoch 536/1000\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 7.0827 - val_acc: 0.0000e+00\n",
            "Epoch 537/1000\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 7.0857 - val_acc: 0.0000e+00\n",
            "Epoch 538/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 7.0886 - val_acc: 0.0000e+00\n",
            "Epoch 539/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 7.0916 - val_acc: 0.0000e+00\n",
            "Epoch 540/1000\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 7.0945 - val_acc: 0.0000e+00\n",
            "Epoch 541/1000\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 7.0974 - val_acc: 0.0000e+00\n",
            "Epoch 542/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 7.1004 - val_acc: 0.0000e+00\n",
            "Epoch 543/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 7.1033 - val_acc: 0.0000e+00\n",
            "Epoch 544/1000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 7.1062 - val_acc: 0.0000e+00\n",
            "Epoch 545/1000\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 7.1091 - val_acc: 0.0000e+00\n",
            "Epoch 546/1000\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 7.1121 - val_acc: 0.0000e+00\n",
            "Epoch 547/1000\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 7.1150 - val_acc: 0.0000e+00\n",
            "Epoch 548/1000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 7.1179 - val_acc: 0.0000e+00\n",
            "Epoch 549/1000\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 7.1208 - val_acc: 0.0000e+00\n",
            "Epoch 550/1000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 7.1237 - val_acc: 0.0000e+00\n",
            "Epoch 551/1000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 7.1266 - val_acc: 0.0000e+00\n",
            "Epoch 552/1000\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 7.1295 - val_acc: 0.0000e+00\n",
            "Epoch 553/1000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 7.1323 - val_acc: 0.0000e+00\n",
            "Epoch 554/1000\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 7.1352 - val_acc: 0.0000e+00\n",
            "Epoch 555/1000\n",
            "1/1 [==============================] - 0s 174ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 7.1381 - val_acc: 0.0000e+00\n",
            "Epoch 556/1000\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 7.1410 - val_acc: 0.0000e+00\n",
            "Epoch 557/1000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 7.1438 - val_acc: 0.0000e+00\n",
            "Epoch 558/1000\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 7.1467 - val_acc: 0.0000e+00\n",
            "Epoch 559/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 7.1495 - val_acc: 0.0000e+00\n",
            "Epoch 560/1000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 7.1524 - val_acc: 0.0000e+00\n",
            "Epoch 561/1000\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 7.1552 - val_acc: 0.0000e+00\n",
            "Epoch 562/1000\n",
            "1/1 [==============================] - 0s 198ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 7.1581 - val_acc: 0.0000e+00\n",
            "Epoch 563/1000\n",
            "1/1 [==============================] - 0s 245ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 7.1609 - val_acc: 0.0000e+00\n",
            "Epoch 564/1000\n",
            "1/1 [==============================] - 0s 245ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 7.1637 - val_acc: 0.0000e+00\n",
            "Epoch 565/1000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 7.1666 - val_acc: 0.0000e+00\n",
            "Epoch 566/1000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 7.1694 - val_acc: 0.0000e+00\n",
            "Epoch 567/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 7.1722 - val_acc: 0.0000e+00\n",
            "Epoch 568/1000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 7.1750 - val_acc: 0.0000e+00\n",
            "Epoch 569/1000\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 7.1778 - val_acc: 0.0000e+00\n",
            "Epoch 570/1000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 7.1807 - val_acc: 0.0000e+00\n",
            "Epoch 571/1000\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 7.1835 - val_acc: 0.0000e+00\n",
            "Epoch 572/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 7.1863 - val_acc: 0.0000e+00\n",
            "Epoch 573/1000\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 7.1890 - val_acc: 0.0000e+00\n",
            "Epoch 574/1000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 7.1918 - val_acc: 0.0000e+00\n",
            "Epoch 575/1000\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 7.1946 - val_acc: 0.0000e+00\n",
            "Epoch 576/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 7.1974 - val_acc: 0.0000e+00\n",
            "Epoch 577/1000\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 7.2002 - val_acc: 0.0000e+00\n",
            "Epoch 578/1000\n",
            "1/1 [==============================] - 0s 177ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 7.2029 - val_acc: 0.0000e+00\n",
            "Epoch 579/1000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 7.2057 - val_acc: 0.0000e+00\n",
            "Epoch 580/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 7.2085 - val_acc: 0.0000e+00\n",
            "Epoch 581/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 7.2112 - val_acc: 0.0000e+00\n",
            "Epoch 582/1000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 7.2140 - val_acc: 0.0000e+00\n",
            "Epoch 583/1000\n",
            "1/1 [==============================] - 0s 222ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 7.2167 - val_acc: 0.0000e+00\n",
            "Epoch 584/1000\n",
            "1/1 [==============================] - 0s 255ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 7.2195 - val_acc: 0.0000e+00\n",
            "Epoch 585/1000\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 7.2222 - val_acc: 0.0000e+00\n",
            "Epoch 586/1000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 7.2250 - val_acc: 0.0000e+00\n",
            "Epoch 587/1000\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 7.2277 - val_acc: 0.0000e+00\n",
            "Epoch 588/1000\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 7.2304 - val_acc: 0.0000e+00\n",
            "Epoch 589/1000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 7.2332 - val_acc: 0.0000e+00\n",
            "Epoch 590/1000\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 7.2359 - val_acc: 0.0000e+00\n",
            "Epoch 591/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 7.2386 - val_acc: 0.0000e+00\n",
            "Epoch 592/1000\n",
            "1/1 [==============================] - 0s 202ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 7.2413 - val_acc: 0.0000e+00\n",
            "Epoch 593/1000\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 7.2440 - val_acc: 0.0000e+00\n",
            "Epoch 594/1000\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 7.2467 - val_acc: 0.0000e+00\n",
            "Epoch 595/1000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 7.2494 - val_acc: 0.0000e+00\n",
            "Epoch 596/1000\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 7.2521 - val_acc: 0.0000e+00\n",
            "Epoch 597/1000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 7.2548 - val_acc: 0.0000e+00\n",
            "Epoch 598/1000\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 7.2575 - val_acc: 0.0000e+00\n",
            "Epoch 599/1000\n",
            "1/1 [==============================] - 0s 188ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 7.2602 - val_acc: 0.0000e+00\n",
            "Epoch 600/1000\n",
            "1/1 [==============================] - 0s 169ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 7.2629 - val_acc: 0.0000e+00\n",
            "Epoch 601/1000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 7.2655 - val_acc: 0.0000e+00\n",
            "Epoch 602/1000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 7.2682 - val_acc: 0.0000e+00\n",
            "Epoch 603/1000\n",
            "1/1 [==============================] - 0s 214ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 7.2709 - val_acc: 0.0000e+00\n",
            "Epoch 604/1000\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 7.2736 - val_acc: 0.0000e+00\n",
            "Epoch 605/1000\n",
            "1/1 [==============================] - 0s 178ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 7.2762 - val_acc: 0.0000e+00\n",
            "Epoch 606/1000\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 7.2789 - val_acc: 0.0000e+00\n",
            "Epoch 607/1000\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 7.2815 - val_acc: 0.0000e+00\n",
            "Epoch 608/1000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 7.2842 - val_acc: 0.0000e+00\n",
            "Epoch 609/1000\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 7.2868 - val_acc: 0.0000e+00\n",
            "Epoch 610/1000\n",
            "1/1 [==============================] - 0s 286ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 7.2895 - val_acc: 0.0000e+00\n",
            "Epoch 611/1000\n",
            "1/1 [==============================] - 0s 163ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 7.2921 - val_acc: 0.0000e+00\n",
            "Epoch 612/1000\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 7.2947 - val_acc: 0.0000e+00\n",
            "Epoch 613/1000\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 7.2974 - val_acc: 0.0000e+00\n",
            "Epoch 614/1000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 7.3000 - val_acc: 0.0000e+00\n",
            "Epoch 615/1000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 7.3026 - val_acc: 0.0000e+00\n",
            "Epoch 616/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 7.3052 - val_acc: 0.0000e+00\n",
            "Epoch 617/1000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 7.3079 - val_acc: 0.0000e+00\n",
            "Epoch 618/1000\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 7.3105 - val_acc: 0.0000e+00\n",
            "Epoch 619/1000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 7.3131 - val_acc: 0.0000e+00\n",
            "Epoch 620/1000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 7.3157 - val_acc: 0.0000e+00\n",
            "Epoch 621/1000\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 7.3183 - val_acc: 0.0000e+00\n",
            "Epoch 622/1000\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 7.3209 - val_acc: 0.0000e+00\n",
            "Epoch 623/1000\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 7.3235 - val_acc: 0.0000e+00\n",
            "Epoch 624/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 7.3261 - val_acc: 0.0000e+00\n",
            "Epoch 625/1000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 7.3287 - val_acc: 0.0000e+00\n",
            "Epoch 626/1000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 7.3312 - val_acc: 0.0000e+00\n",
            "Epoch 627/1000\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 7.3338 - val_acc: 0.0000e+00\n",
            "Epoch 628/1000\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 7.3364 - val_acc: 0.0000e+00\n",
            "Epoch 629/1000\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 7.3390 - val_acc: 0.0000e+00\n",
            "Epoch 630/1000\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 7.3415 - val_acc: 0.0000e+00\n",
            "Epoch 631/1000\n",
            "1/1 [==============================] - 0s 157ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 7.3441 - val_acc: 0.0000e+00\n",
            "Epoch 632/1000\n",
            "1/1 [==============================] - 0s 142ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 7.3467 - val_acc: 0.0000e+00\n",
            "Epoch 633/1000\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 7.3492 - val_acc: 0.0000e+00\n",
            "Epoch 634/1000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 7.3518 - val_acc: 0.0000e+00\n",
            "Epoch 635/1000\n",
            "1/1 [==============================] - 0s 185ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 7.3543 - val_acc: 0.0000e+00\n",
            "Epoch 636/1000\n",
            "1/1 [==============================] - 0s 153ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 7.3569 - val_acc: 0.0000e+00\n",
            "Epoch 637/1000\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 7.3594 - val_acc: 0.0000e+00\n",
            "Epoch 638/1000\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 7.3620 - val_acc: 0.0000e+00\n",
            "Epoch 639/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 7.3645 - val_acc: 0.0000e+00\n",
            "Epoch 640/1000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 9.9893e-04 - acc: 1.0000 - val_loss: 7.3670 - val_acc: 0.0000e+00\n",
            "Epoch 641/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 9.9632e-04 - acc: 1.0000 - val_loss: 7.3696 - val_acc: 0.0000e+00\n",
            "Epoch 642/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 9.9372e-04 - acc: 1.0000 - val_loss: 7.3721 - val_acc: 0.0000e+00\n",
            "Epoch 643/1000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 9.9113e-04 - acc: 1.0000 - val_loss: 7.3746 - val_acc: 0.0000e+00\n",
            "Epoch 644/1000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 9.8855e-04 - acc: 1.0000 - val_loss: 7.3771 - val_acc: 0.0000e+00\n",
            "Epoch 645/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 9.8598e-04 - acc: 1.0000 - val_loss: 7.3796 - val_acc: 0.0000e+00\n",
            "Epoch 646/1000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 9.8342e-04 - acc: 1.0000 - val_loss: 7.3822 - val_acc: 0.0000e+00\n",
            "Epoch 647/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 9.8087e-04 - acc: 1.0000 - val_loss: 7.3847 - val_acc: 0.0000e+00\n",
            "Epoch 648/1000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 9.7833e-04 - acc: 1.0000 - val_loss: 7.3872 - val_acc: 0.0000e+00\n",
            "Epoch 649/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 9.7580e-04 - acc: 1.0000 - val_loss: 7.3897 - val_acc: 0.0000e+00\n",
            "Epoch 650/1000\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 9.7328e-04 - acc: 1.0000 - val_loss: 7.3922 - val_acc: 0.0000e+00\n",
            "Epoch 651/1000\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 9.7077e-04 - acc: 1.0000 - val_loss: 7.3947 - val_acc: 0.0000e+00\n",
            "Epoch 652/1000\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 9.6827e-04 - acc: 1.0000 - val_loss: 7.3972 - val_acc: 0.0000e+00\n",
            "Epoch 653/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 9.6578e-04 - acc: 1.0000 - val_loss: 7.3996 - val_acc: 0.0000e+00\n",
            "Epoch 654/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 9.6330e-04 - acc: 1.0000 - val_loss: 7.4021 - val_acc: 0.0000e+00\n",
            "Epoch 655/1000\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 9.6083e-04 - acc: 1.0000 - val_loss: 7.4046 - val_acc: 0.0000e+00\n",
            "Epoch 656/1000\n",
            "1/1 [==============================] - 0s 152ms/step - loss: 9.5837e-04 - acc: 1.0000 - val_loss: 7.4071 - val_acc: 0.0000e+00\n",
            "Epoch 657/1000\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 9.5592e-04 - acc: 1.0000 - val_loss: 7.4096 - val_acc: 0.0000e+00\n",
            "Epoch 658/1000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 9.5348e-04 - acc: 1.0000 - val_loss: 7.4120 - val_acc: 0.0000e+00\n",
            "Epoch 659/1000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 9.5104e-04 - acc: 1.0000 - val_loss: 7.4145 - val_acc: 0.0000e+00\n",
            "Epoch 660/1000\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 9.4862e-04 - acc: 1.0000 - val_loss: 7.4170 - val_acc: 0.0000e+00\n",
            "Epoch 661/1000\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 9.4621e-04 - acc: 1.0000 - val_loss: 7.4194 - val_acc: 0.0000e+00\n",
            "Epoch 662/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 9.4380e-04 - acc: 1.0000 - val_loss: 7.4219 - val_acc: 0.0000e+00\n",
            "Epoch 663/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 9.4141e-04 - acc: 1.0000 - val_loss: 7.4244 - val_acc: 0.0000e+00\n",
            "Epoch 664/1000\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 9.3902e-04 - acc: 1.0000 - val_loss: 7.4268 - val_acc: 0.0000e+00\n",
            "Epoch 665/1000\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 9.3664e-04 - acc: 1.0000 - val_loss: 7.4293 - val_acc: 0.0000e+00\n",
            "Epoch 666/1000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 9.3428e-04 - acc: 1.0000 - val_loss: 7.4317 - val_acc: 0.0000e+00\n",
            "Epoch 667/1000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 9.3192e-04 - acc: 1.0000 - val_loss: 7.4341 - val_acc: 0.0000e+00\n",
            "Epoch 668/1000\n",
            "1/1 [==============================] - 0s 82ms/step - loss: 9.2957e-04 - acc: 1.0000 - val_loss: 7.4366 - val_acc: 0.0000e+00\n",
            "Epoch 669/1000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 9.2723e-04 - acc: 1.0000 - val_loss: 7.4390 - val_acc: 0.0000e+00\n",
            "Epoch 670/1000\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 9.2490e-04 - acc: 1.0000 - val_loss: 7.4415 - val_acc: 0.0000e+00\n",
            "Epoch 671/1000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 9.2257e-04 - acc: 1.0000 - val_loss: 7.4439 - val_acc: 0.0000e+00\n",
            "Epoch 672/1000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 9.2026e-04 - acc: 1.0000 - val_loss: 7.4463 - val_acc: 0.0000e+00\n",
            "Epoch 673/1000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 9.1795e-04 - acc: 1.0000 - val_loss: 7.4487 - val_acc: 0.0000e+00\n",
            "Epoch 674/1000\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 9.1566e-04 - acc: 1.0000 - val_loss: 7.4512 - val_acc: 0.0000e+00\n",
            "Epoch 675/1000\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 9.1337e-04 - acc: 1.0000 - val_loss: 7.4536 - val_acc: 0.0000e+00\n",
            "Epoch 676/1000\n",
            "1/1 [==============================] - 0s 259ms/step - loss: 9.1109e-04 - acc: 1.0000 - val_loss: 7.4560 - val_acc: 0.0000e+00\n",
            "Epoch 677/1000\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 9.0882e-04 - acc: 1.0000 - val_loss: 7.4584 - val_acc: 0.0000e+00\n",
            "Epoch 678/1000\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 9.0655e-04 - acc: 1.0000 - val_loss: 7.4608 - val_acc: 0.0000e+00\n",
            "Epoch 679/1000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 9.0430e-04 - acc: 1.0000 - val_loss: 7.4632 - val_acc: 0.0000e+00\n",
            "Epoch 680/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 9.0206e-04 - acc: 1.0000 - val_loss: 7.4656 - val_acc: 0.0000e+00\n",
            "Epoch 681/1000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 8.9982e-04 - acc: 1.0000 - val_loss: 7.4680 - val_acc: 0.0000e+00\n",
            "Epoch 682/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 8.9759e-04 - acc: 1.0000 - val_loss: 7.4704 - val_acc: 0.0000e+00\n",
            "Epoch 683/1000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 8.9537e-04 - acc: 1.0000 - val_loss: 7.4728 - val_acc: 0.0000e+00\n",
            "Epoch 684/1000\n",
            "1/1 [==============================] - 0s 151ms/step - loss: 8.9316e-04 - acc: 1.0000 - val_loss: 7.4752 - val_acc: 0.0000e+00\n",
            "Epoch 685/1000\n",
            "1/1 [==============================] - 0s 307ms/step - loss: 8.9095e-04 - acc: 1.0000 - val_loss: 7.4776 - val_acc: 0.0000e+00\n",
            "Epoch 686/1000\n",
            "1/1 [==============================] - 0s 250ms/step - loss: 8.8876e-04 - acc: 1.0000 - val_loss: 7.4800 - val_acc: 0.0000e+00\n",
            "Epoch 687/1000\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 8.8657e-04 - acc: 1.0000 - val_loss: 7.4823 - val_acc: 0.0000e+00\n",
            "Epoch 688/1000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 8.8439e-04 - acc: 1.0000 - val_loss: 7.4847 - val_acc: 0.0000e+00\n",
            "Epoch 689/1000\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 8.8222e-04 - acc: 1.0000 - val_loss: 7.4871 - val_acc: 0.0000e+00\n",
            "Epoch 690/1000\n",
            "1/1 [==============================] - 0s 205ms/step - loss: 8.8006e-04 - acc: 1.0000 - val_loss: 7.4895 - val_acc: 0.0000e+00\n",
            "Epoch 691/1000\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 8.7790e-04 - acc: 1.0000 - val_loss: 7.4918 - val_acc: 0.0000e+00\n",
            "Epoch 692/1000\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 8.7576e-04 - acc: 1.0000 - val_loss: 7.4942 - val_acc: 0.0000e+00\n",
            "Epoch 693/1000\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 8.7362e-04 - acc: 1.0000 - val_loss: 7.4966 - val_acc: 0.0000e+00\n",
            "Epoch 694/1000\n",
            "1/1 [==============================] - 0s 282ms/step - loss: 8.7149e-04 - acc: 1.0000 - val_loss: 7.4989 - val_acc: 0.0000e+00\n",
            "Epoch 695/1000\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 8.6936e-04 - acc: 1.0000 - val_loss: 7.5013 - val_acc: 0.0000e+00\n",
            "Epoch 696/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 8.6725e-04 - acc: 1.0000 - val_loss: 7.5036 - val_acc: 0.0000e+00\n",
            "Epoch 697/1000\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 8.6514e-04 - acc: 1.0000 - val_loss: 7.5060 - val_acc: 0.0000e+00\n",
            "Epoch 698/1000\n",
            "1/1 [==============================] - 0s 245ms/step - loss: 8.6304e-04 - acc: 1.0000 - val_loss: 7.5083 - val_acc: 0.0000e+00\n",
            "Epoch 699/1000\n",
            "1/1 [==============================] - 0s 240ms/step - loss: 8.6095e-04 - acc: 1.0000 - val_loss: 7.5107 - val_acc: 0.0000e+00\n",
            "Epoch 700/1000\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 8.5886e-04 - acc: 1.0000 - val_loss: 7.5130 - val_acc: 0.0000e+00\n",
            "Epoch 701/1000\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 8.5679e-04 - acc: 1.0000 - val_loss: 7.5154 - val_acc: 0.0000e+00\n",
            "Epoch 702/1000\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 8.5472e-04 - acc: 1.0000 - val_loss: 7.5177 - val_acc: 0.0000e+00\n",
            "Epoch 703/1000\n",
            "1/1 [==============================] - 0s 176ms/step - loss: 8.5265e-04 - acc: 1.0000 - val_loss: 7.5200 - val_acc: 0.0000e+00\n",
            "Epoch 704/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 8.5060e-04 - acc: 1.0000 - val_loss: 7.5224 - val_acc: 0.0000e+00\n",
            "Epoch 705/1000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 8.4855e-04 - acc: 1.0000 - val_loss: 7.5247 - val_acc: 0.0000e+00\n",
            "Epoch 706/1000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 8.4651e-04 - acc: 1.0000 - val_loss: 7.5270 - val_acc: 0.0000e+00\n",
            "Epoch 707/1000\n",
            "1/1 [==============================] - 0s 290ms/step - loss: 8.4448e-04 - acc: 1.0000 - val_loss: 7.5293 - val_acc: 0.0000e+00\n",
            "Epoch 708/1000\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 8.4246e-04 - acc: 1.0000 - val_loss: 7.5317 - val_acc: 0.0000e+00\n",
            "Epoch 709/1000\n",
            "1/1 [==============================] - 0s 197ms/step - loss: 8.4044e-04 - acc: 1.0000 - val_loss: 7.5340 - val_acc: 0.0000e+00\n",
            "Epoch 710/1000\n",
            "1/1 [==============================] - 0s 155ms/step - loss: 8.3843e-04 - acc: 1.0000 - val_loss: 7.5363 - val_acc: 0.0000e+00\n",
            "Epoch 711/1000\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 8.3643e-04 - acc: 1.0000 - val_loss: 7.5386 - val_acc: 0.0000e+00\n",
            "Epoch 712/1000\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 8.3443e-04 - acc: 1.0000 - val_loss: 7.5409 - val_acc: 0.0000e+00\n",
            "Epoch 713/1000\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 8.3244e-04 - acc: 1.0000 - val_loss: 7.5432 - val_acc: 0.0000e+00\n",
            "Epoch 714/1000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 8.3046e-04 - acc: 1.0000 - val_loss: 7.5455 - val_acc: 0.0000e+00\n",
            "Epoch 715/1000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 8.2849e-04 - acc: 1.0000 - val_loss: 7.5478 - val_acc: 0.0000e+00\n",
            "Epoch 716/1000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 8.2652e-04 - acc: 1.0000 - val_loss: 7.5501 - val_acc: 0.0000e+00\n",
            "Epoch 717/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 8.2456e-04 - acc: 1.0000 - val_loss: 7.5524 - val_acc: 0.0000e+00\n",
            "Epoch 718/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 8.2261e-04 - acc: 1.0000 - val_loss: 7.5547 - val_acc: 0.0000e+00\n",
            "Epoch 719/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 8.2066e-04 - acc: 1.0000 - val_loss: 7.5570 - val_acc: 0.0000e+00\n",
            "Epoch 720/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 8.1872e-04 - acc: 1.0000 - val_loss: 7.5593 - val_acc: 0.0000e+00\n",
            "Epoch 721/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 8.1679e-04 - acc: 1.0000 - val_loss: 7.5616 - val_acc: 0.0000e+00\n",
            "Epoch 722/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 8.1486e-04 - acc: 1.0000 - val_loss: 7.5638 - val_acc: 0.0000e+00\n",
            "Epoch 723/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 8.1295e-04 - acc: 1.0000 - val_loss: 7.5661 - val_acc: 0.0000e+00\n",
            "Epoch 724/1000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 8.1103e-04 - acc: 1.0000 - val_loss: 7.5684 - val_acc: 0.0000e+00\n",
            "Epoch 725/1000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 8.0913e-04 - acc: 1.0000 - val_loss: 7.5707 - val_acc: 0.0000e+00\n",
            "Epoch 726/1000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 8.0723e-04 - acc: 1.0000 - val_loss: 7.5729 - val_acc: 0.0000e+00\n",
            "Epoch 727/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 8.0534e-04 - acc: 1.0000 - val_loss: 7.5752 - val_acc: 0.0000e+00\n",
            "Epoch 728/1000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 8.0345e-04 - acc: 1.0000 - val_loss: 7.5775 - val_acc: 0.0000e+00\n",
            "Epoch 729/1000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 8.0158e-04 - acc: 1.0000 - val_loss: 7.5797 - val_acc: 0.0000e+00\n",
            "Epoch 730/1000\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 7.9970e-04 - acc: 1.0000 - val_loss: 7.5820 - val_acc: 0.0000e+00\n",
            "Epoch 731/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 7.9784e-04 - acc: 1.0000 - val_loss: 7.5842 - val_acc: 0.0000e+00\n",
            "Epoch 732/1000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 7.9598e-04 - acc: 1.0000 - val_loss: 7.5865 - val_acc: 0.0000e+00\n",
            "Epoch 733/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 7.9413e-04 - acc: 1.0000 - val_loss: 7.5887 - val_acc: 0.0000e+00\n",
            "Epoch 734/1000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 7.9228e-04 - acc: 1.0000 - val_loss: 7.5910 - val_acc: 0.0000e+00\n",
            "Epoch 735/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 7.9044e-04 - acc: 1.0000 - val_loss: 7.5932 - val_acc: 0.0000e+00\n",
            "Epoch 736/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 7.8861e-04 - acc: 1.0000 - val_loss: 7.5955 - val_acc: 0.0000e+00\n",
            "Epoch 737/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 7.8679e-04 - acc: 1.0000 - val_loss: 7.5977 - val_acc: 0.0000e+00\n",
            "Epoch 738/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 7.8497e-04 - acc: 1.0000 - val_loss: 7.6000 - val_acc: 0.0000e+00\n",
            "Epoch 739/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 7.8315e-04 - acc: 1.0000 - val_loss: 7.6022 - val_acc: 0.0000e+00\n",
            "Epoch 740/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 7.8135e-04 - acc: 1.0000 - val_loss: 7.6044 - val_acc: 0.0000e+00\n",
            "Epoch 741/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 7.7955e-04 - acc: 1.0000 - val_loss: 7.6066 - val_acc: 0.0000e+00\n",
            "Epoch 742/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 7.7775e-04 - acc: 1.0000 - val_loss: 7.6089 - val_acc: 0.0000e+00\n",
            "Epoch 743/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 7.7596e-04 - acc: 1.0000 - val_loss: 7.6111 - val_acc: 0.0000e+00\n",
            "Epoch 744/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 7.7418e-04 - acc: 1.0000 - val_loss: 7.6133 - val_acc: 0.0000e+00\n",
            "Epoch 745/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 7.7240e-04 - acc: 1.0000 - val_loss: 7.6155 - val_acc: 0.0000e+00\n",
            "Epoch 746/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 7.7063e-04 - acc: 1.0000 - val_loss: 7.6178 - val_acc: 0.0000e+00\n",
            "Epoch 747/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 7.6887e-04 - acc: 1.0000 - val_loss: 7.6200 - val_acc: 0.0000e+00\n",
            "Epoch 748/1000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 7.6711e-04 - acc: 1.0000 - val_loss: 7.6222 - val_acc: 0.0000e+00\n",
            "Epoch 749/1000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 7.6536e-04 - acc: 1.0000 - val_loss: 7.6244 - val_acc: 0.0000e+00\n",
            "Epoch 750/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 7.6362e-04 - acc: 1.0000 - val_loss: 7.6266 - val_acc: 0.0000e+00\n",
            "Epoch 751/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 7.6188e-04 - acc: 1.0000 - val_loss: 7.6288 - val_acc: 0.0000e+00\n",
            "Epoch 752/1000\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 7.6014e-04 - acc: 1.0000 - val_loss: 7.6310 - val_acc: 0.0000e+00\n",
            "Epoch 753/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 7.5841e-04 - acc: 1.0000 - val_loss: 7.6332 - val_acc: 0.0000e+00\n",
            "Epoch 754/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 7.5669e-04 - acc: 1.0000 - val_loss: 7.6354 - val_acc: 0.0000e+00\n",
            "Epoch 755/1000\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 7.5498e-04 - acc: 1.0000 - val_loss: 7.6376 - val_acc: 0.0000e+00\n",
            "Epoch 756/1000\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 7.5327e-04 - acc: 1.0000 - val_loss: 7.6398 - val_acc: 0.0000e+00\n",
            "Epoch 757/1000\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 7.5156e-04 - acc: 1.0000 - val_loss: 7.6420 - val_acc: 0.0000e+00\n",
            "Epoch 758/1000\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 7.4986e-04 - acc: 1.0000 - val_loss: 7.6442 - val_acc: 0.0000e+00\n",
            "Epoch 759/1000\n",
            "1/1 [==============================] - 0s 161ms/step - loss: 7.4817e-04 - acc: 1.0000 - val_loss: 7.6463 - val_acc: 0.0000e+00\n",
            "Epoch 760/1000\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 7.4648e-04 - acc: 1.0000 - val_loss: 7.6485 - val_acc: 0.0000e+00\n",
            "Epoch 761/1000\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 7.4480e-04 - acc: 1.0000 - val_loss: 7.6507 - val_acc: 0.0000e+00\n",
            "Epoch 762/1000\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 7.4313e-04 - acc: 1.0000 - val_loss: 7.6529 - val_acc: 0.0000e+00\n",
            "Epoch 763/1000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 7.4146e-04 - acc: 1.0000 - val_loss: 7.6550 - val_acc: 0.0000e+00\n",
            "Epoch 764/1000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 7.3979e-04 - acc: 1.0000 - val_loss: 7.6572 - val_acc: 0.0000e+00\n",
            "Epoch 765/1000\n",
            "1/1 [==============================] - 0s 181ms/step - loss: 7.3813e-04 - acc: 1.0000 - val_loss: 7.6594 - val_acc: 0.0000e+00\n",
            "Epoch 766/1000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 7.3648e-04 - acc: 1.0000 - val_loss: 7.6616 - val_acc: 0.0000e+00\n",
            "Epoch 767/1000\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 7.3483e-04 - acc: 1.0000 - val_loss: 7.6637 - val_acc: 0.0000e+00\n",
            "Epoch 768/1000\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 7.3319e-04 - acc: 1.0000 - val_loss: 7.6659 - val_acc: 0.0000e+00\n",
            "Epoch 769/1000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 7.3156e-04 - acc: 1.0000 - val_loss: 7.6680 - val_acc: 0.0000e+00\n",
            "Epoch 770/1000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 7.2993e-04 - acc: 1.0000 - val_loss: 7.6702 - val_acc: 0.0000e+00\n",
            "Epoch 771/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 7.2830e-04 - acc: 1.0000 - val_loss: 7.6724 - val_acc: 0.0000e+00\n",
            "Epoch 772/1000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 7.2668e-04 - acc: 1.0000 - val_loss: 7.6745 - val_acc: 0.0000e+00\n",
            "Epoch 773/1000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 7.2506e-04 - acc: 1.0000 - val_loss: 7.6767 - val_acc: 0.0000e+00\n",
            "Epoch 774/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 7.2346e-04 - acc: 1.0000 - val_loss: 7.6788 - val_acc: 0.0000e+00\n",
            "Epoch 775/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 7.2185e-04 - acc: 1.0000 - val_loss: 7.6809 - val_acc: 0.0000e+00\n",
            "Epoch 776/1000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 7.2025e-04 - acc: 1.0000 - val_loss: 7.6831 - val_acc: 0.0000e+00\n",
            "Epoch 777/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 7.1866e-04 - acc: 1.0000 - val_loss: 7.6852 - val_acc: 0.0000e+00\n",
            "Epoch 778/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 7.1707e-04 - acc: 1.0000 - val_loss: 7.6874 - val_acc: 0.0000e+00\n",
            "Epoch 779/1000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 7.1549e-04 - acc: 1.0000 - val_loss: 7.6895 - val_acc: 0.0000e+00\n",
            "Epoch 780/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 7.1391e-04 - acc: 1.0000 - val_loss: 7.6916 - val_acc: 0.0000e+00\n",
            "Epoch 781/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 7.1234e-04 - acc: 1.0000 - val_loss: 7.6938 - val_acc: 0.0000e+00\n",
            "Epoch 782/1000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 7.1077e-04 - acc: 1.0000 - val_loss: 7.6959 - val_acc: 0.0000e+00\n",
            "Epoch 783/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 7.0921e-04 - acc: 1.0000 - val_loss: 7.6980 - val_acc: 0.0000e+00\n",
            "Epoch 784/1000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 7.0765e-04 - acc: 1.0000 - val_loss: 7.7001 - val_acc: 0.0000e+00\n",
            "Epoch 785/1000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 7.0610e-04 - acc: 1.0000 - val_loss: 7.7023 - val_acc: 0.0000e+00\n",
            "Epoch 786/1000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 7.0456e-04 - acc: 1.0000 - val_loss: 7.7044 - val_acc: 0.0000e+00\n",
            "Epoch 787/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 7.0302e-04 - acc: 1.0000 - val_loss: 7.7065 - val_acc: 0.0000e+00\n",
            "Epoch 788/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 7.0148e-04 - acc: 1.0000 - val_loss: 7.7086 - val_acc: 0.0000e+00\n",
            "Epoch 789/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 6.9995e-04 - acc: 1.0000 - val_loss: 7.7107 - val_acc: 0.0000e+00\n",
            "Epoch 790/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 6.9842e-04 - acc: 1.0000 - val_loss: 7.7128 - val_acc: 0.0000e+00\n",
            "Epoch 791/1000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 6.9690e-04 - acc: 1.0000 - val_loss: 7.7149 - val_acc: 0.0000e+00\n",
            "Epoch 792/1000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 6.9538e-04 - acc: 1.0000 - val_loss: 7.7170 - val_acc: 0.0000e+00\n",
            "Epoch 793/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 6.9387e-04 - acc: 1.0000 - val_loss: 7.7192 - val_acc: 0.0000e+00\n",
            "Epoch 794/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 6.9237e-04 - acc: 1.0000 - val_loss: 7.7213 - val_acc: 0.0000e+00\n",
            "Epoch 795/1000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 6.9087e-04 - acc: 1.0000 - val_loss: 7.7234 - val_acc: 0.0000e+00\n",
            "Epoch 796/1000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 6.8937e-04 - acc: 1.0000 - val_loss: 7.7254 - val_acc: 0.0000e+00\n",
            "Epoch 797/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 6.8788e-04 - acc: 1.0000 - val_loss: 7.7275 - val_acc: 0.0000e+00\n",
            "Epoch 798/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 6.8639e-04 - acc: 1.0000 - val_loss: 7.7296 - val_acc: 0.0000e+00\n",
            "Epoch 799/1000\n",
            "1/1 [==============================] - 0s 81ms/step - loss: 6.8491e-04 - acc: 1.0000 - val_loss: 7.7317 - val_acc: 0.0000e+00\n",
            "Epoch 800/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 6.8343e-04 - acc: 1.0000 - val_loss: 7.7338 - val_acc: 0.0000e+00\n",
            "Epoch 801/1000\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 6.8196e-04 - acc: 1.0000 - val_loss: 7.7359 - val_acc: 0.0000e+00\n",
            "Epoch 802/1000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 6.8049e-04 - acc: 1.0000 - val_loss: 7.7380 - val_acc: 0.0000e+00\n",
            "Epoch 803/1000\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 6.7903e-04 - acc: 1.0000 - val_loss: 7.7401 - val_acc: 0.0000e+00\n",
            "Epoch 804/1000\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 6.7757e-04 - acc: 1.0000 - val_loss: 7.7421 - val_acc: 0.0000e+00\n",
            "Epoch 805/1000\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 6.7612e-04 - acc: 1.0000 - val_loss: 7.7442 - val_acc: 0.0000e+00\n",
            "Epoch 806/1000\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 6.7467e-04 - acc: 1.0000 - val_loss: 7.7463 - val_acc: 0.0000e+00\n",
            "Epoch 807/1000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 6.7322e-04 - acc: 1.0000 - val_loss: 7.7484 - val_acc: 0.0000e+00\n",
            "Epoch 808/1000\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 6.7178e-04 - acc: 1.0000 - val_loss: 7.7504 - val_acc: 0.0000e+00\n",
            "Epoch 809/1000\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 6.7035e-04 - acc: 1.0000 - val_loss: 7.7525 - val_acc: 0.0000e+00\n",
            "Epoch 810/1000\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 6.6892e-04 - acc: 1.0000 - val_loss: 7.7546 - val_acc: 0.0000e+00\n",
            "Epoch 811/1000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 6.6749e-04 - acc: 1.0000 - val_loss: 7.7566 - val_acc: 0.0000e+00\n",
            "Epoch 812/1000\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 6.6607e-04 - acc: 1.0000 - val_loss: 7.7587 - val_acc: 0.0000e+00\n",
            "Epoch 813/1000\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 6.6465e-04 - acc: 1.0000 - val_loss: 7.7607 - val_acc: 0.0000e+00\n",
            "Epoch 814/1000\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 6.6324e-04 - acc: 1.0000 - val_loss: 7.7628 - val_acc: 0.0000e+00\n",
            "Epoch 815/1000\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 6.6183e-04 - acc: 1.0000 - val_loss: 7.7649 - val_acc: 0.0000e+00\n",
            "Epoch 816/1000\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 6.6043e-04 - acc: 1.0000 - val_loss: 7.7669 - val_acc: 0.0000e+00\n",
            "Epoch 817/1000\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 6.5903e-04 - acc: 1.0000 - val_loss: 7.7690 - val_acc: 0.0000e+00\n",
            "Epoch 818/1000\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 6.5764e-04 - acc: 1.0000 - val_loss: 7.7710 - val_acc: 0.0000e+00\n",
            "Epoch 819/1000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 6.5625e-04 - acc: 1.0000 - val_loss: 7.7730 - val_acc: 0.0000e+00\n",
            "Epoch 820/1000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 6.5486e-04 - acc: 1.0000 - val_loss: 7.7751 - val_acc: 0.0000e+00\n",
            "Epoch 821/1000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 6.5348e-04 - acc: 1.0000 - val_loss: 7.7771 - val_acc: 0.0000e+00\n",
            "Epoch 822/1000\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 6.5210e-04 - acc: 1.0000 - val_loss: 7.7792 - val_acc: 0.0000e+00\n",
            "Epoch 823/1000\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 6.5073e-04 - acc: 1.0000 - val_loss: 7.7812 - val_acc: 0.0000e+00\n",
            "Epoch 824/1000\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 6.4936e-04 - acc: 1.0000 - val_loss: 7.7832 - val_acc: 0.0000e+00\n",
            "Epoch 825/1000\n",
            "1/1 [==============================] - 0s 141ms/step - loss: 6.4800e-04 - acc: 1.0000 - val_loss: 7.7853 - val_acc: 0.0000e+00\n",
            "Epoch 826/1000\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 6.4664e-04 - acc: 1.0000 - val_loss: 7.7873 - val_acc: 0.0000e+00\n",
            "Epoch 827/1000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 6.4529e-04 - acc: 1.0000 - val_loss: 7.7893 - val_acc: 0.0000e+00\n",
            "Epoch 828/1000\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 6.4393e-04 - acc: 1.0000 - val_loss: 7.7914 - val_acc: 0.0000e+00\n",
            "Epoch 829/1000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 6.4259e-04 - acc: 1.0000 - val_loss: 7.7934 - val_acc: 0.0000e+00\n",
            "Epoch 830/1000\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 6.4125e-04 - acc: 1.0000 - val_loss: 7.7954 - val_acc: 0.0000e+00\n",
            "Epoch 831/1000\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 6.3991e-04 - acc: 1.0000 - val_loss: 7.7974 - val_acc: 0.0000e+00\n",
            "Epoch 832/1000\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 6.3857e-04 - acc: 1.0000 - val_loss: 7.7994 - val_acc: 0.0000e+00\n",
            "Epoch 833/1000\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 6.3724e-04 - acc: 1.0000 - val_loss: 7.8015 - val_acc: 0.0000e+00\n",
            "Epoch 834/1000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 6.3592e-04 - acc: 1.0000 - val_loss: 7.8035 - val_acc: 0.0000e+00\n",
            "Epoch 835/1000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 6.3460e-04 - acc: 1.0000 - val_loss: 7.8055 - val_acc: 0.0000e+00\n",
            "Epoch 836/1000\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 6.3328e-04 - acc: 1.0000 - val_loss: 7.8075 - val_acc: 0.0000e+00\n",
            "Epoch 837/1000\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 6.3196e-04 - acc: 1.0000 - val_loss: 7.8095 - val_acc: 0.0000e+00\n",
            "Epoch 838/1000\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 6.3066e-04 - acc: 1.0000 - val_loss: 7.8115 - val_acc: 0.0000e+00\n",
            "Epoch 839/1000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 6.2935e-04 - acc: 1.0000 - val_loss: 7.8135 - val_acc: 0.0000e+00\n",
            "Epoch 840/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 6.2805e-04 - acc: 1.0000 - val_loss: 7.8155 - val_acc: 0.0000e+00\n",
            "Epoch 841/1000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 6.2675e-04 - acc: 1.0000 - val_loss: 7.8175 - val_acc: 0.0000e+00\n",
            "Epoch 842/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 6.2546e-04 - acc: 1.0000 - val_loss: 7.8195 - val_acc: 0.0000e+00\n",
            "Epoch 843/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 6.2417e-04 - acc: 1.0000 - val_loss: 7.8215 - val_acc: 0.0000e+00\n",
            "Epoch 844/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 6.2288e-04 - acc: 1.0000 - val_loss: 7.8235 - val_acc: 0.0000e+00\n",
            "Epoch 845/1000\n",
            "1/1 [==============================] - 0s 88ms/step - loss: 6.2160e-04 - acc: 1.0000 - val_loss: 7.8255 - val_acc: 0.0000e+00\n",
            "Epoch 846/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 6.2032e-04 - acc: 1.0000 - val_loss: 7.8275 - val_acc: 0.0000e+00\n",
            "Epoch 847/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 6.1905e-04 - acc: 1.0000 - val_loss: 7.8295 - val_acc: 0.0000e+00\n",
            "Epoch 848/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 6.1778e-04 - acc: 1.0000 - val_loss: 7.8315 - val_acc: 0.0000e+00\n",
            "Epoch 849/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 6.1652e-04 - acc: 1.0000 - val_loss: 7.8334 - val_acc: 0.0000e+00\n",
            "Epoch 850/1000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 6.1525e-04 - acc: 1.0000 - val_loss: 7.8354 - val_acc: 0.0000e+00\n",
            "Epoch 851/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 6.1400e-04 - acc: 1.0000 - val_loss: 7.8374 - val_acc: 0.0000e+00\n",
            "Epoch 852/1000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 6.1274e-04 - acc: 1.0000 - val_loss: 7.8394 - val_acc: 0.0000e+00\n",
            "Epoch 853/1000\n",
            "1/1 [==============================] - 0s 83ms/step - loss: 6.1149e-04 - acc: 1.0000 - val_loss: 7.8414 - val_acc: 0.0000e+00\n",
            "Epoch 854/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 6.1024e-04 - acc: 1.0000 - val_loss: 7.8433 - val_acc: 0.0000e+00\n",
            "Epoch 855/1000\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 6.0900e-04 - acc: 1.0000 - val_loss: 7.8453 - val_acc: 0.0000e+00\n",
            "Epoch 856/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 6.0776e-04 - acc: 1.0000 - val_loss: 7.8473 - val_acc: 0.0000e+00\n",
            "Epoch 857/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 6.0653e-04 - acc: 1.0000 - val_loss: 7.8492 - val_acc: 0.0000e+00\n",
            "Epoch 858/1000\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 6.0530e-04 - acc: 1.0000 - val_loss: 7.8512 - val_acc: 0.0000e+00\n",
            "Epoch 859/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 6.0407e-04 - acc: 1.0000 - val_loss: 7.8532 - val_acc: 0.0000e+00\n",
            "Epoch 860/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 6.0284e-04 - acc: 1.0000 - val_loss: 7.8551 - val_acc: 0.0000e+00\n",
            "Epoch 861/1000\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 6.0162e-04 - acc: 1.0000 - val_loss: 7.8571 - val_acc: 0.0000e+00\n",
            "Epoch 862/1000\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 6.0041e-04 - acc: 1.0000 - val_loss: 7.8590 - val_acc: 0.0000e+00\n",
            "Epoch 863/1000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 5.9919e-04 - acc: 1.0000 - val_loss: 7.8610 - val_acc: 0.0000e+00\n",
            "Epoch 864/1000\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 5.9799e-04 - acc: 1.0000 - val_loss: 7.8630 - val_acc: 0.0000e+00\n",
            "Epoch 865/1000\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 5.9678e-04 - acc: 1.0000 - val_loss: 7.8649 - val_acc: 0.0000e+00\n",
            "Epoch 866/1000\n",
            "1/1 [==============================] - 0s 120ms/step - loss: 5.9558e-04 - acc: 1.0000 - val_loss: 7.8669 - val_acc: 0.0000e+00\n",
            "Epoch 867/1000\n",
            "1/1 [==============================] - 0s 146ms/step - loss: 5.9438e-04 - acc: 1.0000 - val_loss: 7.8688 - val_acc: 0.0000e+00\n",
            "Epoch 868/1000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 5.9318e-04 - acc: 1.0000 - val_loss: 7.8708 - val_acc: 0.0000e+00\n",
            "Epoch 869/1000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 5.9199e-04 - acc: 1.0000 - val_loss: 7.8727 - val_acc: 0.0000e+00\n",
            "Epoch 870/1000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 5.9081e-04 - acc: 1.0000 - val_loss: 7.8746 - val_acc: 0.0000e+00\n",
            "Epoch 871/1000\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 5.8962e-04 - acc: 1.0000 - val_loss: 7.8766 - val_acc: 0.0000e+00\n",
            "Epoch 872/1000\n",
            "1/1 [==============================] - 0s 255ms/step - loss: 5.8844e-04 - acc: 1.0000 - val_loss: 7.8785 - val_acc: 0.0000e+00\n",
            "Epoch 873/1000\n",
            "1/1 [==============================] - 0s 283ms/step - loss: 5.8726e-04 - acc: 1.0000 - val_loss: 7.8805 - val_acc: 0.0000e+00\n",
            "Epoch 874/1000\n",
            "1/1 [==============================] - 0s 230ms/step - loss: 5.8609e-04 - acc: 1.0000 - val_loss: 7.8824 - val_acc: 0.0000e+00\n",
            "Epoch 875/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 5.8492e-04 - acc: 1.0000 - val_loss: 7.8843 - val_acc: 0.0000e+00\n",
            "Epoch 876/1000\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 5.8375e-04 - acc: 1.0000 - val_loss: 7.8863 - val_acc: 0.0000e+00\n",
            "Epoch 877/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 5.8259e-04 - acc: 1.0000 - val_loss: 7.8882 - val_acc: 0.0000e+00\n",
            "Epoch 878/1000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 5.8143e-04 - acc: 1.0000 - val_loss: 7.8901 - val_acc: 0.0000e+00\n",
            "Epoch 879/1000\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 5.8028e-04 - acc: 1.0000 - val_loss: 7.8920 - val_acc: 0.0000e+00\n",
            "Epoch 880/1000\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 5.7912e-04 - acc: 1.0000 - val_loss: 7.8940 - val_acc: 0.0000e+00\n",
            "Epoch 881/1000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 5.7797e-04 - acc: 1.0000 - val_loss: 7.8959 - val_acc: 0.0000e+00\n",
            "Epoch 882/1000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 5.7683e-04 - acc: 1.0000 - val_loss: 7.8978 - val_acc: 0.0000e+00\n",
            "Epoch 883/1000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 5.7569e-04 - acc: 1.0000 - val_loss: 7.8997 - val_acc: 0.0000e+00\n",
            "Epoch 884/1000\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 5.7455e-04 - acc: 1.0000 - val_loss: 7.9016 - val_acc: 0.0000e+00\n",
            "Epoch 885/1000\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 5.7341e-04 - acc: 1.0000 - val_loss: 7.9036 - val_acc: 0.0000e+00\n",
            "Epoch 886/1000\n",
            "1/1 [==============================] - 0s 105ms/step - loss: 5.7228e-04 - acc: 1.0000 - val_loss: 7.9055 - val_acc: 0.0000e+00\n",
            "Epoch 887/1000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 5.7115e-04 - acc: 1.0000 - val_loss: 7.9074 - val_acc: 0.0000e+00\n",
            "Epoch 888/1000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 5.7002e-04 - acc: 1.0000 - val_loss: 7.9093 - val_acc: 0.0000e+00\n",
            "Epoch 889/1000\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 5.6890e-04 - acc: 1.0000 - val_loss: 7.9112 - val_acc: 0.0000e+00\n",
            "Epoch 890/1000\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 5.6778e-04 - acc: 1.0000 - val_loss: 7.9131 - val_acc: 0.0000e+00\n",
            "Epoch 891/1000\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 5.6667e-04 - acc: 1.0000 - val_loss: 7.9150 - val_acc: 0.0000e+00\n",
            "Epoch 892/1000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 5.6555e-04 - acc: 1.0000 - val_loss: 7.9169 - val_acc: 0.0000e+00\n",
            "Epoch 893/1000\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 5.6444e-04 - acc: 1.0000 - val_loss: 7.9188 - val_acc: 0.0000e+00\n",
            "Epoch 894/1000\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 5.6334e-04 - acc: 1.0000 - val_loss: 7.9207 - val_acc: 0.0000e+00\n",
            "Epoch 895/1000\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 5.6224e-04 - acc: 1.0000 - val_loss: 7.9226 - val_acc: 0.0000e+00\n",
            "Epoch 896/1000\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 5.6114e-04 - acc: 1.0000 - val_loss: 7.9245 - val_acc: 0.0000e+00\n",
            "Epoch 897/1000\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 5.6004e-04 - acc: 1.0000 - val_loss: 7.9264 - val_acc: 0.0000e+00\n",
            "Epoch 898/1000\n",
            "1/1 [==============================] - 0s 173ms/step - loss: 5.5895e-04 - acc: 1.0000 - val_loss: 7.9283 - val_acc: 0.0000e+00\n",
            "Epoch 899/1000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 5.5786e-04 - acc: 1.0000 - val_loss: 7.9302 - val_acc: 0.0000e+00\n",
            "Epoch 900/1000\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 5.5677e-04 - acc: 1.0000 - val_loss: 7.9321 - val_acc: 0.0000e+00\n",
            "Epoch 901/1000\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 5.5568e-04 - acc: 1.0000 - val_loss: 7.9339 - val_acc: 0.0000e+00\n",
            "Epoch 902/1000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 5.5460e-04 - acc: 1.0000 - val_loss: 7.9358 - val_acc: 0.0000e+00\n",
            "Epoch 903/1000\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 5.5353e-04 - acc: 1.0000 - val_loss: 7.9377 - val_acc: 0.0000e+00\n",
            "Epoch 904/1000\n",
            "1/1 [==============================] - 0s 262ms/step - loss: 5.5245e-04 - acc: 1.0000 - val_loss: 7.9396 - val_acc: 0.0000e+00\n",
            "Epoch 905/1000\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 5.5138e-04 - acc: 1.0000 - val_loss: 7.9415 - val_acc: 0.0000e+00\n",
            "Epoch 906/1000\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 5.5031e-04 - acc: 1.0000 - val_loss: 7.9433 - val_acc: 0.0000e+00\n",
            "Epoch 907/1000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 5.4925e-04 - acc: 1.0000 - val_loss: 7.9452 - val_acc: 0.0000e+00\n",
            "Epoch 908/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 5.4819e-04 - acc: 1.0000 - val_loss: 7.9471 - val_acc: 0.0000e+00\n",
            "Epoch 909/1000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 5.4713e-04 - acc: 1.0000 - val_loss: 7.9490 - val_acc: 0.0000e+00\n",
            "Epoch 910/1000\n",
            "1/1 [==============================] - 0s 95ms/step - loss: 5.4607e-04 - acc: 1.0000 - val_loss: 7.9508 - val_acc: 0.0000e+00\n",
            "Epoch 911/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 5.4502e-04 - acc: 1.0000 - val_loss: 7.9527 - val_acc: 0.0000e+00\n",
            "Epoch 912/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 5.4397e-04 - acc: 1.0000 - val_loss: 7.9546 - val_acc: 0.0000e+00\n",
            "Epoch 913/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 5.4292e-04 - acc: 1.0000 - val_loss: 7.9564 - val_acc: 0.0000e+00\n",
            "Epoch 914/1000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 5.4188e-04 - acc: 1.0000 - val_loss: 7.9583 - val_acc: 0.0000e+00\n",
            "Epoch 915/1000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 5.4084e-04 - acc: 1.0000 - val_loss: 7.9602 - val_acc: 0.0000e+00\n",
            "Epoch 916/1000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 5.3980e-04 - acc: 1.0000 - val_loss: 7.9620 - val_acc: 0.0000e+00\n",
            "Epoch 917/1000\n",
            "1/1 [==============================] - 0s 233ms/step - loss: 5.3876e-04 - acc: 1.0000 - val_loss: 7.9639 - val_acc: 0.0000e+00\n",
            "Epoch 918/1000\n",
            "1/1 [==============================] - 0s 204ms/step - loss: 5.3773e-04 - acc: 1.0000 - val_loss: 7.9657 - val_acc: 0.0000e+00\n",
            "Epoch 919/1000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 5.3670e-04 - acc: 1.0000 - val_loss: 7.9676 - val_acc: 0.0000e+00\n",
            "Epoch 920/1000\n",
            "1/1 [==============================] - 0s 216ms/step - loss: 5.3568e-04 - acc: 1.0000 - val_loss: 7.9694 - val_acc: 0.0000e+00\n",
            "Epoch 921/1000\n",
            "1/1 [==============================] - 0s 232ms/step - loss: 5.3465e-04 - acc: 1.0000 - val_loss: 7.9713 - val_acc: 0.0000e+00\n",
            "Epoch 922/1000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 5.3363e-04 - acc: 1.0000 - val_loss: 7.9731 - val_acc: 0.0000e+00\n",
            "Epoch 923/1000\n",
            "1/1 [==============================] - 0s 200ms/step - loss: 5.3261e-04 - acc: 1.0000 - val_loss: 7.9750 - val_acc: 0.0000e+00\n",
            "Epoch 924/1000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 5.3160e-04 - acc: 1.0000 - val_loss: 7.9768 - val_acc: 0.0000e+00\n",
            "Epoch 925/1000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 5.3059e-04 - acc: 1.0000 - val_loss: 7.9787 - val_acc: 0.0000e+00\n",
            "Epoch 926/1000\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 5.2958e-04 - acc: 1.0000 - val_loss: 7.9805 - val_acc: 0.0000e+00\n",
            "Epoch 927/1000\n",
            "1/1 [==============================] - 0s 171ms/step - loss: 5.2857e-04 - acc: 1.0000 - val_loss: 7.9824 - val_acc: 0.0000e+00\n",
            "Epoch 928/1000\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 5.2757e-04 - acc: 1.0000 - val_loss: 7.9842 - val_acc: 0.0000e+00\n",
            "Epoch 929/1000\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 5.2657e-04 - acc: 1.0000 - val_loss: 7.9860 - val_acc: 0.0000e+00\n",
            "Epoch 930/1000\n",
            "1/1 [==============================] - 0s 246ms/step - loss: 5.2557e-04 - acc: 1.0000 - val_loss: 7.9879 - val_acc: 0.0000e+00\n",
            "Epoch 931/1000\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 5.2458e-04 - acc: 1.0000 - val_loss: 7.9897 - val_acc: 0.0000e+00\n",
            "Epoch 932/1000\n",
            "1/1 [==============================] - 0s 221ms/step - loss: 5.2359e-04 - acc: 1.0000 - val_loss: 7.9915 - val_acc: 0.0000e+00\n",
            "Epoch 933/1000\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 5.2260e-04 - acc: 1.0000 - val_loss: 7.9934 - val_acc: 0.0000e+00\n",
            "Epoch 934/1000\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 5.2161e-04 - acc: 1.0000 - val_loss: 7.9952 - val_acc: 0.0000e+00\n",
            "Epoch 935/1000\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 5.2063e-04 - acc: 1.0000 - val_loss: 7.9970 - val_acc: 0.0000e+00\n",
            "Epoch 936/1000\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 5.1965e-04 - acc: 1.0000 - val_loss: 7.9989 - val_acc: 0.0000e+00\n",
            "Epoch 937/1000\n",
            "1/1 [==============================] - 0s 168ms/step - loss: 5.1867e-04 - acc: 1.0000 - val_loss: 8.0007 - val_acc: 0.0000e+00\n",
            "Epoch 938/1000\n",
            "1/1 [==============================] - 0s 106ms/step - loss: 5.1769e-04 - acc: 1.0000 - val_loss: 8.0025 - val_acc: 0.0000e+00\n",
            "Epoch 939/1000\n",
            "1/1 [==============================] - 0s 119ms/step - loss: 5.1672e-04 - acc: 1.0000 - val_loss: 8.0043 - val_acc: 0.0000e+00\n",
            "Epoch 940/1000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 5.1575e-04 - acc: 1.0000 - val_loss: 8.0061 - val_acc: 0.0000e+00\n",
            "Epoch 941/1000\n",
            "1/1 [==============================] - 0s 159ms/step - loss: 5.1478e-04 - acc: 1.0000 - val_loss: 8.0080 - val_acc: 0.0000e+00\n",
            "Epoch 942/1000\n",
            "1/1 [==============================] - 0s 183ms/step - loss: 5.1382e-04 - acc: 1.0000 - val_loss: 8.0098 - val_acc: 0.0000e+00\n",
            "Epoch 943/1000\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 5.1286e-04 - acc: 1.0000 - val_loss: 8.0116 - val_acc: 0.0000e+00\n",
            "Epoch 944/1000\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 5.1190e-04 - acc: 1.0000 - val_loss: 8.0134 - val_acc: 0.0000e+00\n",
            "Epoch 945/1000\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 5.1094e-04 - acc: 1.0000 - val_loss: 8.0152 - val_acc: 0.0000e+00\n",
            "Epoch 946/1000\n",
            "1/1 [==============================] - 0s 207ms/step - loss: 5.0999e-04 - acc: 1.0000 - val_loss: 8.0170 - val_acc: 0.0000e+00\n",
            "Epoch 947/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 5.0904e-04 - acc: 1.0000 - val_loss: 8.0188 - val_acc: 0.0000e+00\n",
            "Epoch 948/1000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 5.0809e-04 - acc: 1.0000 - val_loss: 8.0206 - val_acc: 0.0000e+00\n",
            "Epoch 949/1000\n",
            "1/1 [==============================] - 0s 148ms/step - loss: 5.0714e-04 - acc: 1.0000 - val_loss: 8.0224 - val_acc: 0.0000e+00\n",
            "Epoch 950/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 5.0620e-04 - acc: 1.0000 - val_loss: 8.0242 - val_acc: 0.0000e+00\n",
            "Epoch 951/1000\n",
            "1/1 [==============================] - 0s 87ms/step - loss: 5.0526e-04 - acc: 1.0000 - val_loss: 8.0260 - val_acc: 0.0000e+00\n",
            "Epoch 952/1000\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 5.0432e-04 - acc: 1.0000 - val_loss: 8.0278 - val_acc: 0.0000e+00\n",
            "Epoch 953/1000\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 5.0338e-04 - acc: 1.0000 - val_loss: 8.0296 - val_acc: 0.0000e+00\n",
            "Epoch 954/1000\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 5.0245e-04 - acc: 1.0000 - val_loss: 8.0314 - val_acc: 0.0000e+00\n",
            "Epoch 955/1000\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 5.0152e-04 - acc: 1.0000 - val_loss: 8.0332 - val_acc: 0.0000e+00\n",
            "Epoch 956/1000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 5.0059e-04 - acc: 1.0000 - val_loss: 8.0350 - val_acc: 0.0000e+00\n",
            "Epoch 957/1000\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 4.9967e-04 - acc: 1.0000 - val_loss: 8.0368 - val_acc: 0.0000e+00\n",
            "Epoch 958/1000\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 4.9874e-04 - acc: 1.0000 - val_loss: 8.0386 - val_acc: 0.0000e+00\n",
            "Epoch 959/1000\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 4.9782e-04 - acc: 1.0000 - val_loss: 8.0404 - val_acc: 0.0000e+00\n",
            "Epoch 960/1000\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 4.9691e-04 - acc: 1.0000 - val_loss: 8.0422 - val_acc: 0.0000e+00\n",
            "Epoch 961/1000\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 4.9599e-04 - acc: 1.0000 - val_loss: 8.0440 - val_acc: 0.0000e+00\n",
            "Epoch 962/1000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 4.9508e-04 - acc: 1.0000 - val_loss: 8.0457 - val_acc: 0.0000e+00\n",
            "Epoch 963/1000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 4.9417e-04 - acc: 1.0000 - val_loss: 8.0475 - val_acc: 0.0000e+00\n",
            "Epoch 964/1000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 4.9326e-04 - acc: 1.0000 - val_loss: 8.0493 - val_acc: 0.0000e+00\n",
            "Epoch 965/1000\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 4.9236e-04 - acc: 1.0000 - val_loss: 8.0511 - val_acc: 0.0000e+00\n",
            "Epoch 966/1000\n",
            "1/1 [==============================] - 0s 140ms/step - loss: 4.9145e-04 - acc: 1.0000 - val_loss: 8.0529 - val_acc: 0.0000e+00\n",
            "Epoch 967/1000\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 4.9055e-04 - acc: 1.0000 - val_loss: 8.0546 - val_acc: 0.0000e+00\n",
            "Epoch 968/1000\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 4.8965e-04 - acc: 1.0000 - val_loss: 8.0564 - val_acc: 0.0000e+00\n",
            "Epoch 969/1000\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 4.8876e-04 - acc: 1.0000 - val_loss: 8.0582 - val_acc: 0.0000e+00\n",
            "Epoch 970/1000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 4.8787e-04 - acc: 1.0000 - val_loss: 8.0600 - val_acc: 0.0000e+00\n",
            "Epoch 971/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 4.8698e-04 - acc: 1.0000 - val_loss: 8.0617 - val_acc: 0.0000e+00\n",
            "Epoch 972/1000\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 4.8609e-04 - acc: 1.0000 - val_loss: 8.0635 - val_acc: 0.0000e+00\n",
            "Epoch 973/1000\n",
            "1/1 [==============================] - 0s 143ms/step - loss: 4.8520e-04 - acc: 1.0000 - val_loss: 8.0653 - val_acc: 0.0000e+00\n",
            "Epoch 974/1000\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 4.8432e-04 - acc: 1.0000 - val_loss: 8.0670 - val_acc: 0.0000e+00\n",
            "Epoch 975/1000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 4.8344e-04 - acc: 1.0000 - val_loss: 8.0688 - val_acc: 0.0000e+00\n",
            "Epoch 976/1000\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 4.8256e-04 - acc: 1.0000 - val_loss: 8.0706 - val_acc: 0.0000e+00\n",
            "Epoch 977/1000\n",
            "1/1 [==============================] - 0s 136ms/step - loss: 4.8168e-04 - acc: 1.0000 - val_loss: 8.0723 - val_acc: 0.0000e+00\n",
            "Epoch 978/1000\n",
            "1/1 [==============================] - 0s 113ms/step - loss: 4.8081e-04 - acc: 1.0000 - val_loss: 8.0741 - val_acc: 0.0000e+00\n",
            "Epoch 979/1000\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 4.7994e-04 - acc: 1.0000 - val_loss: 8.0758 - val_acc: 0.0000e+00\n",
            "Epoch 980/1000\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 4.7907e-04 - acc: 1.0000 - val_loss: 8.0776 - val_acc: 0.0000e+00\n",
            "Epoch 981/1000\n",
            "1/1 [==============================] - 0s 192ms/step - loss: 4.7820e-04 - acc: 1.0000 - val_loss: 8.0793 - val_acc: 0.0000e+00\n",
            "Epoch 982/1000\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 4.7734e-04 - acc: 1.0000 - val_loss: 8.0811 - val_acc: 0.0000e+00\n",
            "Epoch 983/1000\n",
            "1/1 [==============================] - 0s 166ms/step - loss: 4.7647e-04 - acc: 1.0000 - val_loss: 8.0828 - val_acc: 0.0000e+00\n",
            "Epoch 984/1000\n",
            "1/1 [==============================] - 0s 158ms/step - loss: 4.7561e-04 - acc: 1.0000 - val_loss: 8.0846 - val_acc: 0.0000e+00\n",
            "Epoch 985/1000\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 4.7476e-04 - acc: 1.0000 - val_loss: 8.0863 - val_acc: 0.0000e+00\n",
            "Epoch 986/1000\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 4.7390e-04 - acc: 1.0000 - val_loss: 8.0881 - val_acc: 0.0000e+00\n",
            "Epoch 987/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 4.7305e-04 - acc: 1.0000 - val_loss: 8.0898 - val_acc: 0.0000e+00\n",
            "Epoch 988/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 4.7220e-04 - acc: 1.0000 - val_loss: 8.0916 - val_acc: 0.0000e+00\n",
            "Epoch 989/1000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 4.7135e-04 - acc: 1.0000 - val_loss: 8.0933 - val_acc: 0.0000e+00\n",
            "Epoch 990/1000\n",
            "1/1 [==============================] - 0s 94ms/step - loss: 4.7050e-04 - acc: 1.0000 - val_loss: 8.0951 - val_acc: 0.0000e+00\n",
            "Epoch 991/1000\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 4.6966e-04 - acc: 1.0000 - val_loss: 8.0968 - val_acc: 0.0000e+00\n",
            "Epoch 992/1000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 4.6882e-04 - acc: 1.0000 - val_loss: 8.0985 - val_acc: 0.0000e+00\n",
            "Epoch 993/1000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 4.6798e-04 - acc: 1.0000 - val_loss: 8.1003 - val_acc: 0.0000e+00\n",
            "Epoch 994/1000\n",
            "1/1 [==============================] - 0s 98ms/step - loss: 4.6714e-04 - acc: 1.0000 - val_loss: 8.1020 - val_acc: 0.0000e+00\n",
            "Epoch 995/1000\n",
            "1/1 [==============================] - 0s 99ms/step - loss: 4.6630e-04 - acc: 1.0000 - val_loss: 8.1037 - val_acc: 0.0000e+00\n",
            "Epoch 996/1000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 4.6547e-04 - acc: 1.0000 - val_loss: 8.1055 - val_acc: 0.0000e+00\n",
            "Epoch 997/1000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 4.6464e-04 - acc: 1.0000 - val_loss: 8.1072 - val_acc: 0.0000e+00\n",
            "Epoch 998/1000\n",
            "1/1 [==============================] - 0s 86ms/step - loss: 4.6381e-04 - acc: 1.0000 - val_loss: 8.1089 - val_acc: 0.0000e+00\n",
            "Epoch 999/1000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 4.6298e-04 - acc: 1.0000 - val_loss: 8.1107 - val_acc: 0.0000e+00\n",
            "Epoch 1000/1000\n",
            "1/1 [==============================] - 0s 84ms/step - loss: 4.6216e-04 - acc: 1.0000 - val_loss: 8.1124 - val_acc: 0.0000e+00\n",
            "Training took 145.3326907157898 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate model"
      ],
      "metadata": {
        "id": "P02uLEMGGC_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "###Evaluate accuracy and loss of model\n",
        "###Sets for each training epoch\n",
        "acc = LSTM_history.history['acc']\n",
        "val_acc = LSTM_history.history['val_acc']\n",
        "\n",
        "loss = LSTM_history.history['loss']\n",
        "val_loss = LSTM_history.history['val_loss']\n",
        "\n",
        "###Get number of epochs\n",
        "epochs = range(len(acc))\n",
        "\n",
        "###Plot training and validation accuracy per epoch\n",
        "plt.plot(epochs, acc)\n",
        "plt.plot(epochs, val_acc)\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "###Plot training and Validation loss per epoch\n",
        "plt.plot(epochs, loss)\n",
        "plt.plot(epochs, val_loss)\n",
        "plt.title('Training and validation loss')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904
        },
        "id": "8ls2mBL2DfwU",
        "outputId": "4caf551b-1787-4210-b06c-0f92983f6fa6"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Training and validation loss')"
            ]
          },
          "metadata": {},
          "execution_count": 69
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}