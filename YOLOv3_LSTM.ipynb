{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youngsiiimba/dashcam-accident-prediction/blob/main/YOLOv3_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "dGgCMuwhQIck"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.layers import Conv2D, Input, BatchNormalization, LeakyReLU, ZeroPadding2D, UpSampling2D\n",
        "from keras.layers import add, concatenate\n",
        "from keras.models import Model\n",
        "import struct\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9u8aDhZBab3z",
        "outputId": "e03c0b79-ef2a-4428-aee3-4003170032e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-22 16:32:58--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: ‘weights/yolov3.weights.3’\n",
            "\n",
            "yolov3.weights.3    100%[===================>] 236.52M  18.2MB/s    in 14s     \n",
            "\n",
            "2023-07-22 16:33:13 (16.8 MB/s) - ‘weights/yolov3.weights.3’ saved [248007048/248007048]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget -P weights https://pjreddie.com/media/files/yolov3.weights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Akbab63eYeA8"
      },
      "source": [
        "# Define YOLOv3 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "i0i9v_hdZPca"
      },
      "outputs": [],
      "source": [
        "def _conv_block(inp, convs, skip=True):\n",
        "    x = inp\n",
        "    count = 0\n",
        "\n",
        "    for conv in convs:\n",
        "        if count == (len(convs) - 2) and skip:\n",
        "            skip_connection = x\n",
        "        count += 1\n",
        "\n",
        "        if conv['stride'] > 1: x = ZeroPadding2D(((1,0),(1,0)))(x) # peculiar padding as darknet prefer left and top\n",
        "        x = Conv2D(conv['filter'],\n",
        "                   conv['kernel'],\n",
        "                   strides=conv['stride'],\n",
        "                   padding='valid' if conv['stride'] > 1 else 'same', # peculiar padding as darknet prefer left and top\n",
        "                   name='conv_' + str(conv['layer_idx']),\n",
        "                   use_bias=False if conv['bnorm'] else True)(x)\n",
        "        if conv['bnorm']: x = BatchNormalization(epsilon=0.001, name='bnorm_' + str(conv['layer_idx']))(x)\n",
        "        if conv['leaky']: x = LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(x)\n",
        "\n",
        "    return add([skip_connection, x]) if skip else x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "CFZOODN3WwWE"
      },
      "outputs": [],
      "source": [
        "def make_yolov3_model():\n",
        "    input_image = Input(shape=(None, None, 3))\n",
        "\n",
        "    # Layer  0 => 4\n",
        "    x = _conv_block(input_image, [{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 0},\n",
        "                                  {'filter': 64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 1},\n",
        "                                  {'filter': 32, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 2},\n",
        "                                  {'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 3}])\n",
        "\n",
        "    # Layer  5 => 8\n",
        "    x = _conv_block(x, [{'filter': 128, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 5},\n",
        "                        {'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 6},\n",
        "                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 7}])\n",
        "\n",
        "    # Layer  9 => 11\n",
        "    x = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 9},\n",
        "                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 10}])\n",
        "\n",
        "    # Layer 12 => 15\n",
        "    x = _conv_block(x, [{'filter': 256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 12},\n",
        "                        {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 13},\n",
        "                        {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 14}])\n",
        "\n",
        "    # Layer 16 => 36\n",
        "    for i in range(7):\n",
        "        x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 16+i*3},\n",
        "                            {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 17+i*3}])\n",
        "\n",
        "    skip_36 = x\n",
        "\n",
        "    # Layer 37 => 40\n",
        "    x = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 37},\n",
        "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 38},\n",
        "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 39}])\n",
        "\n",
        "    # Layer 41 => 61\n",
        "    for i in range(7):\n",
        "        x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 41+i*3},\n",
        "                            {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 42+i*3}])\n",
        "\n",
        "    skip_61 = x\n",
        "\n",
        "    # Layer 62 => 65\n",
        "    x = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 62},\n",
        "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 63},\n",
        "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 64}])\n",
        "\n",
        "    # Layer 66 => 74\n",
        "    for i in range(3):\n",
        "        x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 66+i*3},\n",
        "                            {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 67+i*3}])\n",
        "\n",
        "    # Layer 75 => 79\n",
        "    x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 75},\n",
        "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 76},\n",
        "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 77},\n",
        "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 78},\n",
        "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 79}], skip=False)\n",
        "\n",
        "    # Layer 80 => 82\n",
        "    yolo_82 = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 80},\n",
        "                              {'filter':  255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 81}], skip=False)\n",
        "\n",
        "    # Layer 83 => 86\n",
        "    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 84}], skip=False)\n",
        "    x = UpSampling2D(2)(x)\n",
        "    x = concatenate([x, skip_61])\n",
        "\n",
        "    # Layer 87 => 91\n",
        "    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 87},\n",
        "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 88},\n",
        "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 89},\n",
        "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 90},\n",
        "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 91}], skip=False)\n",
        "\n",
        "    # Layer 92 => 94\n",
        "    yolo_94 = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 92},\n",
        "                              {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 93}], skip=False)\n",
        "\n",
        "    # Layer 95 => 98\n",
        "    x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True,   'layer_idx': 96}], skip=False)\n",
        "    x = UpSampling2D(2)(x)\n",
        "    x = concatenate([x, skip_36])\n",
        "\n",
        "    # Layer 99 => 106\n",
        "    yolo_106 = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 99},\n",
        "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 100},\n",
        "                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 101},\n",
        "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 102},\n",
        "                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 103},\n",
        "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 104},\n",
        "                               {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 105}], skip=False)\n",
        "\n",
        "    model = Model(input_image, [yolo_82, yolo_94, yolo_106])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iw2ouI5bW3f"
      },
      "source": [
        "### Weight reader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "1LDZUY8qbadB"
      },
      "outputs": [],
      "source": [
        "class WeightReader:\n",
        "    def __init__(self, weight_file):\n",
        "        with open(weight_file, 'rb') as w_f:\n",
        "            major,    = struct.unpack('i', w_f.read(4))\n",
        "            minor,    = struct.unpack('i', w_f.read(4))\n",
        "            revision, = struct.unpack('i', w_f.read(4))\n",
        "\n",
        "            if (major*10 + minor) >= 2 and major < 1000 and minor < 1000:\n",
        "                w_f.read(8)\n",
        "            else:\n",
        "                w_f.read(4)\n",
        "\n",
        "            transpose = (major > 1000) or (minor > 1000)\n",
        "\n",
        "            binary = w_f.read()\n",
        "\n",
        "        self.offset = 0\n",
        "        self.all_weights = np.frombuffer(binary, dtype='float32')\n",
        "\n",
        "    def read_bytes(self, size):\n",
        "        self.offset = self.offset + size\n",
        "        return self.all_weights[self.offset-size:self.offset]\n",
        "\n",
        "    def load_weights(self, model):\n",
        "        for i in range(106):\n",
        "            try:\n",
        "                conv_layer = model.get_layer('conv_' + str(i))\n",
        "                print(\"loading weights of convolution #\" + str(i))\n",
        "\n",
        "                if i not in [81, 93, 105]:\n",
        "                    norm_layer = model.get_layer('bnorm_' + str(i))\n",
        "\n",
        "                    size = np.prod(norm_layer.get_weights()[0].shape)\n",
        "\n",
        "                    beta  = self.read_bytes(size) # bias\n",
        "                    gamma = self.read_bytes(size) # scale\n",
        "                    mean  = self.read_bytes(size) # mean\n",
        "                    var   = self.read_bytes(size) # variance\n",
        "\n",
        "                    weights = norm_layer.set_weights([gamma, beta, mean, var])\n",
        "\n",
        "                if len(conv_layer.get_weights()) > 1:\n",
        "                    bias   = self.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n",
        "                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
        "\n",
        "                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
        "                    kernel = kernel.transpose([2,3,1,0])\n",
        "                    conv_layer.set_weights([kernel, bias])\n",
        "                else:\n",
        "                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
        "                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
        "                    kernel = kernel.transpose([2,3,1,0])\n",
        "                    conv_layer.set_weights([kernel])\n",
        "            except ValueError:\n",
        "                print(\"no convolution #\" + str(i))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDWtEPtgYi73"
      },
      "source": [
        "## Make YOLOv3 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "w18RumlGWv9h"
      },
      "outputs": [],
      "source": [
        "yolov3_model = make_yolov3_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "jirTkKQCbD4O"
      },
      "outputs": [],
      "source": [
        "# load the model weights\n",
        "weight_reader = WeightReader('weights/yolov3.weights')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CN_2r74ib2tx",
        "outputId": "366e5f6a-e05f-4be2-86de-c5039f7e43df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading weights of convolution #0\n",
            "loading weights of convolution #1\n",
            "loading weights of convolution #2\n",
            "loading weights of convolution #3\n",
            "no convolution #4\n",
            "loading weights of convolution #5\n",
            "loading weights of convolution #6\n",
            "loading weights of convolution #7\n",
            "no convolution #8\n",
            "loading weights of convolution #9\n",
            "loading weights of convolution #10\n",
            "no convolution #11\n",
            "loading weights of convolution #12\n",
            "loading weights of convolution #13\n",
            "loading weights of convolution #14\n",
            "no convolution #15\n",
            "loading weights of convolution #16\n",
            "loading weights of convolution #17\n",
            "no convolution #18\n",
            "loading weights of convolution #19\n",
            "loading weights of convolution #20\n",
            "no convolution #21\n",
            "loading weights of convolution #22\n",
            "loading weights of convolution #23\n",
            "no convolution #24\n",
            "loading weights of convolution #25\n",
            "loading weights of convolution #26\n",
            "no convolution #27\n",
            "loading weights of convolution #28\n",
            "loading weights of convolution #29\n",
            "no convolution #30\n",
            "loading weights of convolution #31\n",
            "loading weights of convolution #32\n",
            "no convolution #33\n",
            "loading weights of convolution #34\n",
            "loading weights of convolution #35\n",
            "no convolution #36\n",
            "loading weights of convolution #37\n",
            "loading weights of convolution #38\n",
            "loading weights of convolution #39\n",
            "no convolution #40\n",
            "loading weights of convolution #41\n",
            "loading weights of convolution #42\n",
            "no convolution #43\n",
            "loading weights of convolution #44\n",
            "loading weights of convolution #45\n",
            "no convolution #46\n",
            "loading weights of convolution #47\n",
            "loading weights of convolution #48\n",
            "no convolution #49\n",
            "loading weights of convolution #50\n",
            "loading weights of convolution #51\n",
            "no convolution #52\n",
            "loading weights of convolution #53\n",
            "loading weights of convolution #54\n",
            "no convolution #55\n",
            "loading weights of convolution #56\n",
            "loading weights of convolution #57\n",
            "no convolution #58\n",
            "loading weights of convolution #59\n",
            "loading weights of convolution #60\n",
            "no convolution #61\n",
            "loading weights of convolution #62\n",
            "loading weights of convolution #63\n",
            "loading weights of convolution #64\n",
            "no convolution #65\n",
            "loading weights of convolution #66\n",
            "loading weights of convolution #67\n",
            "no convolution #68\n",
            "loading weights of convolution #69\n",
            "loading weights of convolution #70\n",
            "no convolution #71\n",
            "loading weights of convolution #72\n",
            "loading weights of convolution #73\n",
            "no convolution #74\n",
            "loading weights of convolution #75\n",
            "loading weights of convolution #76\n",
            "loading weights of convolution #77\n",
            "loading weights of convolution #78\n",
            "loading weights of convolution #79\n",
            "loading weights of convolution #80\n",
            "loading weights of convolution #81\n",
            "no convolution #82\n",
            "no convolution #83\n",
            "loading weights of convolution #84\n",
            "no convolution #85\n",
            "no convolution #86\n",
            "loading weights of convolution #87\n",
            "loading weights of convolution #88\n",
            "loading weights of convolution #89\n",
            "loading weights of convolution #90\n",
            "loading weights of convolution #91\n",
            "loading weights of convolution #92\n",
            "loading weights of convolution #93\n",
            "no convolution #94\n",
            "no convolution #95\n",
            "loading weights of convolution #96\n",
            "no convolution #97\n",
            "no convolution #98\n",
            "loading weights of convolution #99\n",
            "loading weights of convolution #100\n",
            "loading weights of convolution #101\n",
            "loading weights of convolution #102\n",
            "loading weights of convolution #103\n",
            "loading weights of convolution #104\n",
            "loading weights of convolution #105\n"
          ]
        }
      ],
      "source": [
        "# set the model weights into the model\n",
        "weight_reader.load_weights(yolov3_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iw_fYGLUcGqz",
        "outputId": "08c961eb-3de7-4886-a5f8-a7287cdce177"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "# save the model to a Keras compatible .h5 model file ready for later use.\n",
        "yolov3_model.save('yolov3-model.h5')\n",
        "\n",
        "\n",
        "\n",
        "# load yolov3 model\n",
        "#model = load_model('model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajVNaOVXeC61"
      },
      "source": [
        "## Helper functions for making predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "nk5UlcI0euzw"
      },
      "outputs": [],
      "source": [
        "# based on https://github.com/experiencor/keras-yolo3\n",
        "import numpy as np\n",
        "from numpy import expand_dims\n",
        "from keras.models import load_model\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "from matplotlib import pyplot\n",
        "from matplotlib.patches import Rectangle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "ccMWXODRfPIF"
      },
      "outputs": [],
      "source": [
        "class BoundBox:\n",
        "    def __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
        "        self.xmin = xmin\n",
        "        self.ymin = ymin\n",
        "        self.xmax = xmax\n",
        "        self.ymax = ymax\n",
        "\n",
        "        self.objness = objness\n",
        "        self.classes = classes\n",
        "\n",
        "        self.label = -1\n",
        "        self.score = -1\n",
        "\n",
        "    def get_label(self):\n",
        "        if self.label == -1:\n",
        "            self.label = np.argmax(self.classes)\n",
        "\n",
        "        return self.label\n",
        "\n",
        "    def get_score(self):\n",
        "        if self.score == -1:\n",
        "            self.score = self.classes[self.get_label()]\n",
        "\n",
        "        return self.score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "r-CJuRMvgP9T"
      },
      "outputs": [],
      "source": [
        "def _sigmoid(x):\n",
        "    return 1. / (1. + np.exp(-x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "wzPGED7ZhLM3"
      },
      "outputs": [],
      "source": [
        "def decode_netout(netout, anchors, obj_thresh, nms_thresh, net_h, net_w):\n",
        "    grid_h, grid_w = netout.shape[:2]\n",
        "    nb_box = 3\n",
        "    netout = netout.reshape((grid_h, grid_w, nb_box, -1))\n",
        "    nb_class = netout.shape[-1] - 5\n",
        "\n",
        "    boxes = []\n",
        "\n",
        "    netout[..., :2]  = _sigmoid(netout[..., :2])\n",
        "    netout[..., 4:]  = _sigmoid(netout[..., 4:])\n",
        "    netout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
        "    netout[..., 5:] *= netout[..., 5:] > obj_thresh\n",
        "\n",
        "    for i in range(grid_h*grid_w):\n",
        "        row = i / grid_w\n",
        "        col = i % grid_w\n",
        "\n",
        "        for b in range(nb_box):\n",
        "            # 4th element is objectness score\n",
        "            objectness = netout[int(row)][int(col)][b][4]\n",
        "            #objectness = netout[..., :4]\n",
        "\n",
        "            if(objectness.all() <= obj_thresh): continue\n",
        "\n",
        "            # first 4 elements are x, y, w, and h\n",
        "            x, y, w, h = netout[int(row)][int(col)][b][:4]\n",
        "\n",
        "            x = (col + x) / grid_w # center position, unit: image width\n",
        "            y = (row + y) / grid_h # center position, unit: image height\n",
        "            w = anchors[2 * b + 0] * np.exp(w) / net_w # unit: image width\n",
        "            h = anchors[2 * b + 1] * np.exp(h) / net_h # unit: image height\n",
        "\n",
        "            # last elements are class probabilities\n",
        "            classes = netout[int(row)][col][b][5:]\n",
        "\n",
        "            box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
        "            #box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, None, classes)\n",
        "\n",
        "            boxes.append(box)\n",
        "\n",
        "    return boxes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "1m51HYCxhhkx"
      },
      "outputs": [],
      "source": [
        "def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n",
        "    if (float(net_w)/image_w) < (float(net_h)/image_h):\n",
        "        new_w = net_w\n",
        "        new_h = (image_h*net_w)/image_w\n",
        "    else:\n",
        "        new_h = net_w\n",
        "        new_w = (image_w*net_h)/image_h\n",
        "\n",
        "    for i in range(len(boxes)):\n",
        "        x_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
        "        y_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
        "\n",
        "        boxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
        "        boxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
        "        boxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
        "        boxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "6v6rz4a_h0MF"
      },
      "outputs": [],
      "source": [
        "def _interval_overlap(interval_a, interval_b):\n",
        "    x1, x2 = interval_a\n",
        "    x3, x4 = interval_b\n",
        "\n",
        "    if x3 < x1:\n",
        "        if x4 < x1:\n",
        "            return 0\n",
        "        else:\n",
        "            return min(x2,x4) - x1\n",
        "    else:\n",
        "        if x2 < x3:\n",
        "             return 0\n",
        "        else:\n",
        "            return min(x2,x4) - x3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "Q3DYJW9gh-fY"
      },
      "outputs": [],
      "source": [
        "def bbox_iou(box1, box2):\n",
        "    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
        "    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
        "\n",
        "    intersect = intersect_w * intersect_h\n",
        "\n",
        "    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
        "    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
        "\n",
        "    union = w1*h1 + w2*h2 - intersect\n",
        "\n",
        "    return float(intersect) / union"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "OpeHoB5DiGxK"
      },
      "outputs": [],
      "source": [
        "def do_nms(boxes, nms_thresh):\n",
        "    if len(boxes) > 0:\n",
        "        nb_class = len(boxes[0].classes)\n",
        "    else:\n",
        "        return\n",
        "\n",
        "    for c in range(nb_class):\n",
        "        sorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
        "\n",
        "        for i in range(len(sorted_indices)):\n",
        "            index_i = sorted_indices[i]\n",
        "\n",
        "            if boxes[index_i].classes[c] == 0: continue\n",
        "\n",
        "            for j in range(i+1, len(sorted_indices)):\n",
        "                index_j = sorted_indices[j]\n",
        "\n",
        "                if bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
        "                    boxes[index_j].classes[c] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "Ou81IYbZiccG"
      },
      "outputs": [],
      "source": [
        "# load and prepare an image\n",
        "def load_image_pixels(filename, shape):\n",
        "    # load the image to get its shape\n",
        "    image = load_img(filename)\n",
        "    width, height = image.size\n",
        "    # load the image with the required size\n",
        "    image = load_img(filename, target_size=shape)\n",
        "    # convert to numpy array\n",
        "    image = img_to_array(image)\n",
        "    # scale pixel values to [0, 1]\n",
        "    image = image.astype('float32')\n",
        "    image /= 255.0\n",
        "    # add a dimension so that we have one sample\n",
        "    image = expand_dims(image, 0)\n",
        "    return image, width, height"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "gUKjhooVi5Ee"
      },
      "outputs": [],
      "source": [
        "# get all of the results above a threshold\n",
        "def get_boxes(boxes, labels, thresh):\n",
        "    v_boxes, v_labels, v_scores = list(), list(), list()\n",
        "    # enumerate all boxes\n",
        "    for box in boxes:\n",
        "      # enumerate all possible labels\n",
        "      for i in range(len(labels)):\n",
        "        # check if the threshold for this label is high enough\n",
        "        if box.classes[i] > thresh:\n",
        "          v_boxes.append(box)\n",
        "          v_labels.append(labels[i])\n",
        "          v_scores.append(box.classes[i]*100)\n",
        "          # don't break, many labels may trigger for one box\n",
        "    return v_boxes, v_labels, v_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "UtPx02_DjMrI"
      },
      "outputs": [],
      "source": [
        "# draw all results\n",
        "def draw_boxes(filename, v_boxes, v_labels, v_scores):\n",
        "    # load the image\n",
        "    data = pyplot.imread(filename)\n",
        "    # plot the image\n",
        "    pyplot.imshow(data)\n",
        "    # get the context for drawing boxes\n",
        "    ax = pyplot.gca()\n",
        "    # plot each box\n",
        "    for i in range(len(v_boxes)):\n",
        "        box = v_boxes[i]\n",
        "        # get coordinates\n",
        "        y1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n",
        "        # calculate width and height of the box\n",
        "        width, height = x2 - x1, y2 - y1\n",
        "        # create the shape\n",
        "        rect = Rectangle((x1, y1), width, height, fill=False, color='white')\n",
        "        # draw the box\n",
        "        ax.add_patch(rect)\n",
        "        # draw text and score in top left corner\n",
        "        label = \"%s (%.3f)\" % (v_labels[i], v_scores[i])\n",
        "        pyplot.text(x1, y1, label, color='white')\n",
        "      # show the plot\n",
        "    pyplot.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLZFpXzUmZAt"
      },
      "source": [
        "## Make predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aP6VgLJhkTC8",
        "outputId": "3a149a92-3f3a-4b19-c3ee-f19138117b55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'yolo-v3' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/heartkilla/yolo-v3.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "K6T_ROipmRwM"
      },
      "outputs": [],
      "source": [
        "image1 = '/content/yolo-v3/data/images/dog.jpg'\n",
        "image2 = '/content/yolo-v3/data/images/office.jpg'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "OERx567fmcPn"
      },
      "outputs": [],
      "source": [
        "# define the expected input shape for the model\n",
        "input_w, input_h = 416, 416\n",
        "# define our new photo\n",
        "photo_filename = '/content/yolo-v3/data/images/dog.jpg'\n",
        "# load and prepare image\n",
        "image, image_w, image_h = load_image_pixels(photo_filename, (input_w, input_h))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8G4dNTg0pFd",
        "outputId": "8cca3bc6-1838-4d1a-ebfa-f37617c0f9b2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "519168"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "image.size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yti-2Ozqugnk"
      },
      "source": [
        "The output of the model is, in fact, encoded candidate bounding boxes from three different grid sizes, and the boxes are defined the context of anchor boxes, carefully chosen based on an analysis of the size of objects in the MSCOCO dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KaVHxXNm73A",
        "outputId": "02efb7ef-f1a7-4417-9df2-8fa71b376d04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "3\n",
            "[(1, 13, 13, 255), (1, 26, 26, 255), (1, 52, 52, 255)]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "# make prediction\n",
        "yhat = yolov3_model.predict(image)\n",
        "print(len(yhat))\n",
        "#arr_yhat = np.array(yhat.copy)\n",
        "# summarize the shape of the list of arrays\n",
        "print([a.shape for a in yhat])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkOOHuWpAS6m",
        "outputId": "cad6b9c0-1c5f-4830-8798-0125570a8ee8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.16541481,  0.3153256 ,  0.32475203, ..., -3.9620342 ,\n",
              "       -4.1403227 , -3.6877267 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "yhat[0].flatten()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZhvgm_lvM3n"
      },
      "source": [
        "# Make data for YOLO-LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYOGEfOGwqbG",
        "outputId": "4b0a4352-f4b7-4e10-f93c-19b29090769a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "###access google drive folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "UQ094hWzxUWZ"
      },
      "outputs": [],
      "source": [
        "!unzip -u -q /content/drive/MyDrive/Dachcam_dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "DqLCIWrDxXXF"
      },
      "outputs": [],
      "source": [
        "train_dir = \"/content/videos/training\"\n",
        "test_dir = \"/content/videos/testing\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "EqS25xmY1FZJ"
      },
      "outputs": [],
      "source": [
        "from numpy import expand_dims\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "# load and prepare an image\n",
        "def load_image_pixels(filename, shape):\n",
        "    # load the image to get its shape\n",
        "    image = load_img(filename)\n",
        "    width, height = image.size\n",
        "    # load the image with the required size\n",
        "    image = load_img(filename, target_size=shape)\n",
        "    # convert to numpy array\n",
        "    image = img_to_array(image)\n",
        "    # scale pixel values to [0, 1]\n",
        "    image = image.astype('float32')\n",
        "    image /= 255.0\n",
        "    # add a dimension so that we have one sample\n",
        "    image = expand_dims(image, 0)\n",
        "    return image, width, height"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "ulpYxLR1xj4O"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from numpy import expand_dims\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "def coordinates_extraction(video_path):\n",
        "    coordinates_list = []\n",
        "    vidObj = cv2.VideoCapture(video_path)\n",
        "    # Used as counter variable\n",
        "    count = 1\n",
        "    while count <= seq_len:\n",
        "        success, image = vidObj.read()\n",
        "        if success:\n",
        "            # #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            #image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "            image = cv2.resize(image, (vid_height, vid_width))\n",
        "            # convert to numpy array\n",
        "            image = img_to_array(image)\n",
        "            # scale pixel values to [0, 1]\n",
        "            image = image.astype('float32')\n",
        "            image /= 255.0\n",
        "            # add a dimension so that we have one sample\n",
        "            image = expand_dims(image, 0)\n",
        "            # make predictions using YOLOv3 model\n",
        "            predictions = yolov3_model.predict(image)\n",
        "            # Flatten the output before we append it to a list\n",
        "            coordinates_list.append(predictions[0].flatten())\n",
        "            count += 1\n",
        "        else:\n",
        "            print(\"Defected frame\")\n",
        "            break\n",
        "    #return only the first 50 frames, so model makes predict for the next 50 frames\n",
        "    return coordinates_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "2HoaHMUZxneT"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "def create_data(input_dir, seq_len, classes):\n",
        "    X = []\n",
        "    Y = []\n",
        "\n",
        "    classes_list = os.listdir(input_dir)\n",
        "\n",
        "    for c in classes_list:\n",
        "        print(c)\n",
        "        files_list = os.listdir(os.path.join(input_dir, c))\n",
        "        for f in files_list:\n",
        "          coordinates = coordinates_extraction(os.path.join(os.path.join(input_dir, c), f))\n",
        "          if len(coordinates) == seq_len:\n",
        "                X.append(coordinates)\n",
        "                y = [0]*len(classes)\n",
        "                y[classes.index(c)] = 1\n",
        "                Y.append(y)\n",
        "          else:\n",
        "            print(\"len(coordinates) != seq_len\")\n",
        "            break\n",
        "\n",
        "    X = np.asarray(X)\n",
        "    Y = np.asarray(Y)\n",
        "    # X = np.array(X, dtype='float32')\n",
        "    # Y = np.array(Y, dtype='float32')\n",
        "    # # We using memory memory in an attempt to save RAM by storing the array in DISK instead of RAM\n",
        "    # num_features = X.shape[-1]\n",
        "    # X_filename = \"X_data.npy\"\n",
        "    # Y_filename = \"Y_data.npy\"\n",
        "    # print(coordinates.shape[0])\n",
        "    # fpX = np.memmap(X_filename, dtype='float32', mode='w+', shape=(len(X), seq_len, num_features))\n",
        "    # fpY = np.memmap(Y_filename, dtype='float32', mode='w+', shape=(len(Y), len(classes)))\n",
        "    # fpX[:] = X\n",
        "    # fpY[:] = Y\n",
        "\n",
        "    # return fpX, fpY\n",
        "    return X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "QMIvflUaxumd"
      },
      "outputs": [],
      "source": [
        "# # define the expected input shape for the model\n",
        "# vid_height , vid_width = 416, 416\n",
        "# seq_len = 50\n",
        "# classes = [\"negative\", \"positive\"]\n",
        "\n",
        "# #Need to thread this or use multiprocessing to make this faster\n",
        "# import time\n",
        "# start = time.perf_counter()\n",
        "# X_train, y_train = create_data(train_dir, seq_len, classes)\n",
        "# X_test, y_test =  create_data(test_dir, seq_len, classes)\n",
        "# finish = time.perf_counter()\n",
        "# print(f\"Finished in {round(finish-start,2)} seconds.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Data Generator"
      ],
      "metadata": {
        "id": "1whfTjI-Ianp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import Sequence, to_categorical\n",
        "\n",
        "class CustomDataGenerator(Sequence):\n",
        "    def __init__(self, input_dir, classes, seq_len, batch_size, vid_height, vid_width):\n",
        "        self.input_dir = input_dir\n",
        "        self.classes = classes\n",
        "        self.seq_len = seq_len\n",
        "        self.batch_size = batch_size\n",
        "        self.vid_height = vid_height\n",
        "        self.vid_width = vid_width\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(os.listdir(self.input_dir)) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        batch_files = self.files[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "\n",
        "        X = []\n",
        "        y = []\n",
        "\n",
        "        print(batch_files)\n",
        "        for f in batch_files:\n",
        "            coordinates = coordinates_extraction(os.path.join(self.input_dir, f))\n",
        "            print(coordinates)\n",
        "            X.append(coordinates)\n",
        "            y.append(self.classes.index(f.split('_')[0]))\n",
        "\n",
        "        X = np.asarray(X)\n",
        "        y = np.asarray(y)\n",
        "        y = to_categorical(y, num_classes=len(self.classes))\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.files = os.listdir(self.input_dir)\n",
        "\n"
      ],
      "metadata": {
        "id": "Sb-e_0kcHbAB"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"/content/videos/training\"\n",
        "test_dir = \"/content/videos/testing\"\n",
        "batch_size = 32\n",
        "seq_len = 50\n",
        "vid_height , vid_width = 416, 416\n",
        "classes = [\"negative\", \"positive\"]\n",
        "\n",
        "# Create instances of the custom data generator for training and testing\n",
        "train_generator = CustomDataGenerator(train_dir, classes, seq_len, batch_size, vid_height, vid_width)\n",
        "test_generator = CustomDataGenerator(test_dir, classes, seq_len, batch_size, vid_height, vid_width)\n"
      ],
      "metadata": {
        "id": "tL7W2HFaIS3E"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator.__getitem__(1)\n",
        "train_generator.__len__()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0ereWHsmsJI",
        "outputId": "25a0a9f9-a0f6-4976-c695-7af029493bda"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sandbox"
      ],
      "metadata": {
        "id": "todlFyC3Ihyo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "uLMYf3TO71vk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb89c543-b5a9-448d-a868-d9e916f681c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘test’: File exists\n"
          ]
        }
      ],
      "source": [
        "!mkdir test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "LN2AvDJq8DjI"
      },
      "outputs": [],
      "source": [
        "!mkdir negative\n",
        "!mkdir positive\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "5O_nnlt49AHM"
      },
      "outputs": [],
      "source": [
        "!mv positive/ test/positive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "CvFe4Tpm9TOP"
      },
      "outputs": [],
      "source": [
        "!mv negative test/negative"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "YXaIDsEX9LqM"
      },
      "outputs": [],
      "source": [
        "#We keep running out of RAM while trying to create the data so we'll use 4 videos to tinker\n",
        "!cp \"/content/videos/testing/negative/000830.mp4\" test/negative/000830.mp4\n",
        "!cp \"/content/videos/testing/negative/000831.mp4\" test/negative/000831.mp4\n",
        "\n",
        "!cp \"/content/videos/testing/positive/000456.mp4\" test/positive/000456.mp4\n",
        "!cp \"/content/videos/testing/positive/000457.mp4\" test/positive/000457.mp4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3UlwHoJ-SZ2"
      },
      "outputs": [],
      "source": [
        "tinker_dir = \"test\"\n",
        "X, Y = create_data(tinker_dir, seq_len, classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "wuTarx5eL1ND",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66ba5b34-ffdd-4677-94c6-fecf10daaa55"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 50, 43095)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyEbUQTfB7Q7"
      },
      "outputs": [],
      "source": [
        "X.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOXwN4esFpJU"
      },
      "source": [
        "# Make LSTM model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTKjhqIdKrwb"
      },
      "source": [
        "## Define model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "K5korYWNN-LD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "294294ec-1348-43ad-f9ad-d25be49cc89a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 50, 100)           17278400  \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 50)                30200     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 102       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,308,702\n",
            "Trainable params: 17,308,702\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "#num_samples = X.shape[0]\n",
        "sequence_length = 50\n",
        "nb_features = 43095 #X.shape[2]\n",
        "nb_out = 2\n",
        "#print(input_shape.shape)\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM, Activation\n",
        "from sklearn.metrics import fbeta_score\n",
        "# build the LSTM network\n",
        "# Feature weights\n",
        "# LSTM model\n",
        "LSTM_model = Sequential()\n",
        "\n",
        "# The first layer\n",
        "LSTM_model.add(LSTM(\n",
        "         input_shape=(sequence_length, nb_features),\n",
        "         units=100,\n",
        "         return_sequences=True))\n",
        "\n",
        "# Plus a 20% dropout rate\n",
        "#LSTM_model.add(Dropout(0.2))\n",
        "\n",
        "# The second layer\n",
        "LSTM_model.add(LSTM(\n",
        "          units=50,\n",
        "          return_sequences=False))\n",
        "\n",
        "# Plus a 20% dropout rate\n",
        "#LSTM_model.add(Dropout(0.2))\n",
        "\n",
        "# # Dense sigmoid layer\n",
        "LSTM_model.add(Dense(units=nb_out, activation='sigmoid'))\n",
        "# Dense softmax layer\n",
        "#LSTM_model.add(Dense(units=nb_out, activation='softmax'))\n",
        "\n",
        "# # With adam optimizer and a binary crossentropy loss. We will opimize for model accuracy.\n",
        "LSTM_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "\n",
        "\n",
        "\n",
        "#LSTM_model.compile(optimizer=keras.optimizers.Adam(0.001), loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "# Verify the architecture\n",
        "print(LSTM_model.summary())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##Note: I seem to be getting better results with activation set to 'sigmoid' as opposed to 'softmax' and loss set to 'binary_crossentropy' as opposed to 'categorical_crossentropy'\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQZBrJMqF-FT"
      },
      "source": [
        "## Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "g97yHQMfR6tH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 818
        },
        "outputId": "f9ded4cc-398d-434d-8400-07466ec40d04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defected frame\n",
            "Defected frame\n",
            "Epoch 1/1000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-1ba468badddc>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# fit the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m LSTM_history = LSTM_model.fit(train_generator, # Training features and label combined\n\u001b[0m\u001b[1;32m     30\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/input_spec.py\", line 235, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Exception encountered when calling layer 'sequential' (type Sequential).\n    \n    Input 0 of layer \"lstm\" is incompatible with the layer: expected ndim=3, found ndim=1. Full shape received: (None,)\n    \n    Call arguments received by layer 'sequential' (type Sequential):\n      • inputs=tf.Tensor(shape=(None,), dtype=float32)\n      • training=True\n      • mask=None\n"
          ]
        }
      ],
      "source": [
        "# #### Using Sandbox data\n",
        "\n",
        "# import keras\n",
        "# import time\n",
        "\n",
        "\n",
        "# t0 = time.time()\n",
        "# # fit the network\n",
        "# LSTM_history = LSTM_model.fit(X, # Training features\n",
        "#           Y, # Training labels\n",
        "#           epochs=1000,   # We'll stop after 10 epochs\n",
        "#           batch_size=200, #\n",
        "#           validation_split=0.10, # Use 10% of data to evaluate the loss. (val_loss)\n",
        "#           verbose=1, #\n",
        "#           )\n",
        "\n",
        "# print(\"Training took \"+str(time.time() - t0)+\" seconds\")\n",
        "\n",
        "\n",
        "\n",
        "#### Using DataGenerator\n",
        "\n",
        "import keras\n",
        "import time\n",
        "\n",
        "\n",
        "t0 = time.time()\n",
        "# fit the network\n",
        "LSTM_history = LSTM_model.fit(train_generator, # Training features and label combined\n",
        "          epochs=1000,\n",
        "          validation_data=test_generator\n",
        "          )\n",
        "\n",
        "print(\"Training took \"+str(time.time() - t0)+\" seconds\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_generator.__getitem__(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kap_Ow3xlXRX",
        "outputId": "e32d9049-8291-456e-83b9-89a5606c53ff"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([], dtype=float64), array([], shape=(0, 2), dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P02uLEMGGC_M"
      },
      "source": [
        "## Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ls2mBL2DfwU"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "###Evaluate accuracy and loss of model\n",
        "###Sets for each training epoch\n",
        "acc = LSTM_history.history['acc']\n",
        "val_acc = LSTM_history.history['val_acc']\n",
        "\n",
        "loss = LSTM_history.history['loss']\n",
        "val_loss = LSTM_history.history['val_loss']\n",
        "\n",
        "###Get number of epochs\n",
        "epochs = range(len(acc))\n",
        "\n",
        "###Plot training and validation accuracy per epoch\n",
        "plt.plot(epochs, acc)\n",
        "plt.plot(epochs, val_acc)\n",
        "plt.title('Training and validation accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "###Plot training and Validation loss per epoch\n",
        "plt.plot(epochs, loss)\n",
        "plt.plot(epochs, val_loss)\n",
        "plt.title('Training and validation loss')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Akbab63eYeA8",
        "ajVNaOVXeC61"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyOCuqMN2sjW6Xg4wn6MWPD6",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}