{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "Akbab63eYeA8",
        "NDWtEPtgYi73",
        "ajVNaOVXeC61"
      ],
      "authorship_tag": "ABX9TyOCJJaWyP1zYdS3kJNQvKnw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/youngsiiimba/dashcam-accident-prediction/blob/main/YOLOv3_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "dGgCMuwhQIck"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "from keras.layers import Conv2D, Input, BatchNormalization, LeakyReLU, ZeroPadding2D, UpSampling2D\n",
        "from keras.layers import add, concatenate\n",
        "from keras.models import Model\n",
        "import struct\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -P weights https://pjreddie.com/media/files/yolov3.weights"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9u8aDhZBab3z",
        "outputId": "06d80017-8727-4c31-ef34-9bcdceeabcb0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-12 18:45:28--  https://pjreddie.com/media/files/yolov3.weights\n",
            "Resolving pjreddie.com (pjreddie.com)... 128.208.4.108\n",
            "Connecting to pjreddie.com (pjreddie.com)|128.208.4.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 248007048 (237M) [application/octet-stream]\n",
            "Saving to: ‘weights/yolov3.weights.1’\n",
            "\n",
            "yolov3.weights.1    100%[===================>] 236.52M  18.7MB/s    in 14s     \n",
            "\n",
            "2023-06-12 18:45:43 (17.1 MB/s) - ‘weights/yolov3.weights.1’ saved [248007048/248007048]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define model"
      ],
      "metadata": {
        "id": "Akbab63eYeA8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _conv_block(inp, convs, skip=True):\n",
        "    x = inp\n",
        "    count = 0\n",
        "    \n",
        "    for conv in convs:\n",
        "        if count == (len(convs) - 2) and skip:\n",
        "            skip_connection = x\n",
        "        count += 1\n",
        "        \n",
        "        if conv['stride'] > 1: x = ZeroPadding2D(((1,0),(1,0)))(x) # peculiar padding as darknet prefer left and top\n",
        "        x = Conv2D(conv['filter'], \n",
        "                   conv['kernel'], \n",
        "                   strides=conv['stride'], \n",
        "                   padding='valid' if conv['stride'] > 1 else 'same', # peculiar padding as darknet prefer left and top\n",
        "                   name='conv_' + str(conv['layer_idx']), \n",
        "                   use_bias=False if conv['bnorm'] else True)(x)\n",
        "        if conv['bnorm']: x = BatchNormalization(epsilon=0.001, name='bnorm_' + str(conv['layer_idx']))(x)\n",
        "        if conv['leaky']: x = LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(x)\n",
        "\n",
        "    return add([skip_connection, x]) if skip else x"
      ],
      "metadata": {
        "id": "i0i9v_hdZPca"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_yolov3_model():\n",
        "    input_image = Input(shape=(None, None, 3))\n",
        "\n",
        "    # Layer  0 => 4\n",
        "    x = _conv_block(input_image, [{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 0},\n",
        "                                  {'filter': 64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 1},\n",
        "                                  {'filter': 32, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 2},\n",
        "                                  {'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 3}])\n",
        "\n",
        "    # Layer  5 => 8\n",
        "    x = _conv_block(x, [{'filter': 128, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 5},\n",
        "                        {'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 6},\n",
        "                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 7}])\n",
        "\n",
        "    # Layer  9 => 11\n",
        "    x = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 9},\n",
        "                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 10}])\n",
        "\n",
        "    # Layer 12 => 15\n",
        "    x = _conv_block(x, [{'filter': 256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 12},\n",
        "                        {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 13},\n",
        "                        {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 14}])\n",
        "\n",
        "    # Layer 16 => 36\n",
        "    for i in range(7):\n",
        "        x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 16+i*3},\n",
        "                            {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 17+i*3}])\n",
        "        \n",
        "    skip_36 = x\n",
        "        \n",
        "    # Layer 37 => 40\n",
        "    x = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 37},\n",
        "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 38},\n",
        "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 39}])\n",
        "\n",
        "    # Layer 41 => 61\n",
        "    for i in range(7):\n",
        "        x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 41+i*3},\n",
        "                            {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 42+i*3}])\n",
        "        \n",
        "    skip_61 = x\n",
        "        \n",
        "    # Layer 62 => 65\n",
        "    x = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 62},\n",
        "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 63},\n",
        "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 64}])\n",
        "\n",
        "    # Layer 66 => 74\n",
        "    for i in range(3):\n",
        "        x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 66+i*3},\n",
        "                            {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 67+i*3}])\n",
        "        \n",
        "    # Layer 75 => 79\n",
        "    x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 75},\n",
        "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 76},\n",
        "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 77},\n",
        "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 78},\n",
        "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 79}], skip=False)\n",
        "\n",
        "    # Layer 80 => 82\n",
        "    yolo_82 = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 80},\n",
        "                              {'filter':  255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 81}], skip=False)\n",
        "\n",
        "    # Layer 83 => 86\n",
        "    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 84}], skip=False)\n",
        "    x = UpSampling2D(2)(x)\n",
        "    x = concatenate([x, skip_61])\n",
        "\n",
        "    # Layer 87 => 91\n",
        "    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 87},\n",
        "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 88},\n",
        "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 89},\n",
        "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 90},\n",
        "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 91}], skip=False)\n",
        "\n",
        "    # Layer 92 => 94\n",
        "    yolo_94 = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 92},\n",
        "                              {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 93}], skip=False)\n",
        "\n",
        "    # Layer 95 => 98\n",
        "    x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True,   'layer_idx': 96}], skip=False)\n",
        "    x = UpSampling2D(2)(x)\n",
        "    x = concatenate([x, skip_36])\n",
        "\n",
        "    # Layer 99 => 106\n",
        "    yolo_106 = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 99},\n",
        "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 100},\n",
        "                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 101},\n",
        "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 102},\n",
        "                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 103},\n",
        "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 104},\n",
        "                               {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 105}], skip=False)\n",
        "\n",
        "    model = Model(input_image, [yolo_82, yolo_94, yolo_106])    \n",
        "    return model"
      ],
      "metadata": {
        "id": "CFZOODN3WwWE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Weight reader"
      ],
      "metadata": {
        "id": "-iw2ouI5bW3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class WeightReader:\n",
        "    def __init__(self, weight_file):\n",
        "        with open(weight_file, 'rb') as w_f:\n",
        "            major,    = struct.unpack('i', w_f.read(4))\n",
        "            minor,    = struct.unpack('i', w_f.read(4))\n",
        "            revision, = struct.unpack('i', w_f.read(4))\n",
        "\n",
        "            if (major*10 + minor) >= 2 and major < 1000 and minor < 1000:\n",
        "                w_f.read(8)\n",
        "            else:\n",
        "                w_f.read(4)\n",
        "\n",
        "            transpose = (major > 1000) or (minor > 1000)\n",
        "            \n",
        "            binary = w_f.read()\n",
        "\n",
        "        self.offset = 0\n",
        "        self.all_weights = np.frombuffer(binary, dtype='float32')\n",
        "        \n",
        "    def read_bytes(self, size):\n",
        "        self.offset = self.offset + size\n",
        "        return self.all_weights[self.offset-size:self.offset]\n",
        "\n",
        "    def load_weights(self, model):\n",
        "        for i in range(106):\n",
        "            try:\n",
        "                conv_layer = model.get_layer('conv_' + str(i))\n",
        "                print(\"loading weights of convolution #\" + str(i))\n",
        "\n",
        "                if i not in [81, 93, 105]:\n",
        "                    norm_layer = model.get_layer('bnorm_' + str(i))\n",
        "\n",
        "                    size = np.prod(norm_layer.get_weights()[0].shape)\n",
        "\n",
        "                    beta  = self.read_bytes(size) # bias\n",
        "                    gamma = self.read_bytes(size) # scale\n",
        "                    mean  = self.read_bytes(size) # mean\n",
        "                    var   = self.read_bytes(size) # variance            \n",
        "\n",
        "                    weights = norm_layer.set_weights([gamma, beta, mean, var])  \n",
        "\n",
        "                if len(conv_layer.get_weights()) > 1:\n",
        "                    bias   = self.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n",
        "                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
        "                    \n",
        "                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
        "                    kernel = kernel.transpose([2,3,1,0])\n",
        "                    conv_layer.set_weights([kernel, bias])\n",
        "                else:\n",
        "                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
        "                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
        "                    kernel = kernel.transpose([2,3,1,0])\n",
        "                    conv_layer.set_weights([kernel])\n",
        "            except ValueError:\n",
        "                print(\"no convolution #\" + str(i))  "
      ],
      "metadata": {
        "id": "1LDZUY8qbadB"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make model"
      ],
      "metadata": {
        "id": "NDWtEPtgYi73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "yolov3_model = make_yolov3_model()"
      ],
      "metadata": {
        "id": "w18RumlGWv9h"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the model weights\n",
        "weight_reader = WeightReader('weights/yolov3.weights')"
      ],
      "metadata": {
        "id": "jirTkKQCbD4O"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set the model weights into the model\n",
        "weight_reader.load_weights(yolov3_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CN_2r74ib2tx",
        "outputId": "067748d9-e745-47bc-c4cd-07055767d053"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading weights of convolution #0\n",
            "loading weights of convolution #1\n",
            "loading weights of convolution #2\n",
            "loading weights of convolution #3\n",
            "no convolution #4\n",
            "loading weights of convolution #5\n",
            "loading weights of convolution #6\n",
            "loading weights of convolution #7\n",
            "no convolution #8\n",
            "loading weights of convolution #9\n",
            "loading weights of convolution #10\n",
            "no convolution #11\n",
            "loading weights of convolution #12\n",
            "loading weights of convolution #13\n",
            "loading weights of convolution #14\n",
            "no convolution #15\n",
            "loading weights of convolution #16\n",
            "loading weights of convolution #17\n",
            "no convolution #18\n",
            "loading weights of convolution #19\n",
            "loading weights of convolution #20\n",
            "no convolution #21\n",
            "loading weights of convolution #22\n",
            "loading weights of convolution #23\n",
            "no convolution #24\n",
            "loading weights of convolution #25\n",
            "loading weights of convolution #26\n",
            "no convolution #27\n",
            "loading weights of convolution #28\n",
            "loading weights of convolution #29\n",
            "no convolution #30\n",
            "loading weights of convolution #31\n",
            "loading weights of convolution #32\n",
            "no convolution #33\n",
            "loading weights of convolution #34\n",
            "loading weights of convolution #35\n",
            "no convolution #36\n",
            "loading weights of convolution #37\n",
            "loading weights of convolution #38\n",
            "loading weights of convolution #39\n",
            "no convolution #40\n",
            "loading weights of convolution #41\n",
            "loading weights of convolution #42\n",
            "no convolution #43\n",
            "loading weights of convolution #44\n",
            "loading weights of convolution #45\n",
            "no convolution #46\n",
            "loading weights of convolution #47\n",
            "loading weights of convolution #48\n",
            "no convolution #49\n",
            "loading weights of convolution #50\n",
            "loading weights of convolution #51\n",
            "no convolution #52\n",
            "loading weights of convolution #53\n",
            "loading weights of convolution #54\n",
            "no convolution #55\n",
            "loading weights of convolution #56\n",
            "loading weights of convolution #57\n",
            "no convolution #58\n",
            "loading weights of convolution #59\n",
            "loading weights of convolution #60\n",
            "no convolution #61\n",
            "loading weights of convolution #62\n",
            "loading weights of convolution #63\n",
            "loading weights of convolution #64\n",
            "no convolution #65\n",
            "loading weights of convolution #66\n",
            "loading weights of convolution #67\n",
            "no convolution #68\n",
            "loading weights of convolution #69\n",
            "loading weights of convolution #70\n",
            "no convolution #71\n",
            "loading weights of convolution #72\n",
            "loading weights of convolution #73\n",
            "no convolution #74\n",
            "loading weights of convolution #75\n",
            "loading weights of convolution #76\n",
            "loading weights of convolution #77\n",
            "loading weights of convolution #78\n",
            "loading weights of convolution #79\n",
            "loading weights of convolution #80\n",
            "loading weights of convolution #81\n",
            "no convolution #82\n",
            "no convolution #83\n",
            "loading weights of convolution #84\n",
            "no convolution #85\n",
            "no convolution #86\n",
            "loading weights of convolution #87\n",
            "loading weights of convolution #88\n",
            "loading weights of convolution #89\n",
            "loading weights of convolution #90\n",
            "loading weights of convolution #91\n",
            "loading weights of convolution #92\n",
            "loading weights of convolution #93\n",
            "no convolution #94\n",
            "no convolution #95\n",
            "loading weights of convolution #96\n",
            "no convolution #97\n",
            "no convolution #98\n",
            "loading weights of convolution #99\n",
            "loading weights of convolution #100\n",
            "loading weights of convolution #101\n",
            "loading weights of convolution #102\n",
            "loading weights of convolution #103\n",
            "loading weights of convolution #104\n",
            "loading weights of convolution #105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save the model to a Keras compatible .h5 model file ready for later use.\n",
        "yolov3_model.save('yolov3-model.h5')\n",
        "\n",
        "\n",
        "\n",
        "# load yolov3 model\n",
        "#model = load_model('model.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iw_fYGLUcGqz",
        "outputId": "3c438b47-368a-4963-dbe4-fcd676d61ed7"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper functions for making predictions"
      ],
      "metadata": {
        "id": "ajVNaOVXeC61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# based on https://github.com/experiencor/keras-yolo3\n",
        "import numpy as np\n",
        "from numpy import expand_dims\n",
        "from keras.models import load_model\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "from matplotlib import pyplot\n",
        "from matplotlib.patches import Rectangle"
      ],
      "metadata": {
        "id": "nk5UlcI0euzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BoundBox:\n",
        "    def __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
        "        self.xmin = xmin\n",
        "        self.ymin = ymin\n",
        "        self.xmax = xmax\n",
        "        self.ymax = ymax\n",
        "        \n",
        "        self.objness = objness\n",
        "        self.classes = classes\n",
        "\n",
        "        self.label = -1\n",
        "        self.score = -1\n",
        "\n",
        "    def get_label(self):\n",
        "        if self.label == -1:\n",
        "            self.label = np.argmax(self.classes)\n",
        "        \n",
        "        return self.label\n",
        "    \n",
        "    def get_score(self):\n",
        "        if self.score == -1:\n",
        "            self.score = self.classes[self.get_label()]\n",
        "            \n",
        "        return self.score"
      ],
      "metadata": {
        "id": "ccMWXODRfPIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _sigmoid(x):\n",
        "    return 1. / (1. + np.exp(-x))"
      ],
      "metadata": {
        "id": "r-CJuRMvgP9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_netout(netout, anchors, obj_thresh, nms_thresh, net_h, net_w):\n",
        "    grid_h, grid_w = netout.shape[:2]\n",
        "    nb_box = 3\n",
        "    netout = netout.reshape((grid_h, grid_w, nb_box, -1))\n",
        "    nb_class = netout.shape[-1] - 5\n",
        "\n",
        "    boxes = []\n",
        "\n",
        "    netout[..., :2]  = _sigmoid(netout[..., :2])\n",
        "    netout[..., 4:]  = _sigmoid(netout[..., 4:])\n",
        "    netout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
        "    netout[..., 5:] *= netout[..., 5:] > obj_thresh\n",
        "\n",
        "    for i in range(grid_h*grid_w):\n",
        "        row = i / grid_w\n",
        "        col = i % grid_w\n",
        "        \n",
        "        for b in range(nb_box):\n",
        "            # 4th element is objectness score\n",
        "            objectness = netout[int(row)][int(col)][b][4]\n",
        "            #objectness = netout[..., :4]\n",
        "            \n",
        "            if(objectness.all() <= obj_thresh): continue\n",
        "            \n",
        "            # first 4 elements are x, y, w, and h\n",
        "            x, y, w, h = netout[int(row)][int(col)][b][:4]\n",
        "\n",
        "            x = (col + x) / grid_w # center position, unit: image width\n",
        "            y = (row + y) / grid_h # center position, unit: image height\n",
        "            w = anchors[2 * b + 0] * np.exp(w) / net_w # unit: image width\n",
        "            h = anchors[2 * b + 1] * np.exp(h) / net_h # unit: image height  \n",
        "            \n",
        "            # last elements are class probabilities\n",
        "            classes = netout[int(row)][col][b][5:]\n",
        "            \n",
        "            box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
        "            #box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, None, classes)\n",
        "\n",
        "            boxes.append(box)\n",
        "\n",
        "    return boxes"
      ],
      "metadata": {
        "id": "wzPGED7ZhLM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n",
        "    if (float(net_w)/image_w) < (float(net_h)/image_h):\n",
        "        new_w = net_w\n",
        "        new_h = (image_h*net_w)/image_w\n",
        "    else:\n",
        "        new_h = net_w\n",
        "        new_w = (image_w*net_h)/image_h\n",
        "        \n",
        "    for i in range(len(boxes)):\n",
        "        x_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
        "        y_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
        "        \n",
        "        boxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
        "        boxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
        "        boxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
        "        boxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\n",
        " "
      ],
      "metadata": {
        "id": "1m51HYCxhhkx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _interval_overlap(interval_a, interval_b):\n",
        "    x1, x2 = interval_a\n",
        "    x3, x4 = interval_b\n",
        "\n",
        "    if x3 < x1:\n",
        "        if x4 < x1:\n",
        "            return 0\n",
        "        else:\n",
        "            return min(x2,x4) - x1\n",
        "    else:\n",
        "        if x2 < x3:\n",
        "             return 0\n",
        "        else:\n",
        "            return min(x2,x4) - x3 "
      ],
      "metadata": {
        "id": "6v6rz4a_h0MF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bbox_iou(box1, box2):\n",
        "    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
        "    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
        "    \n",
        "    intersect = intersect_w * intersect_h\n",
        "\n",
        "    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
        "    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
        "    \n",
        "    union = w1*h1 + w2*h2 - intersect\n",
        "    \n",
        "    return float(intersect) / union"
      ],
      "metadata": {
        "id": "Q3DYJW9gh-fY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def do_nms(boxes, nms_thresh):\n",
        "    if len(boxes) > 0:\n",
        "        nb_class = len(boxes[0].classes)\n",
        "    else:\n",
        "        return\n",
        "        \n",
        "    for c in range(nb_class):\n",
        "        sorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
        "\n",
        "        for i in range(len(sorted_indices)):\n",
        "            index_i = sorted_indices[i]\n",
        "\n",
        "            if boxes[index_i].classes[c] == 0: continue\n",
        "\n",
        "            for j in range(i+1, len(sorted_indices)):\n",
        "                index_j = sorted_indices[j]\n",
        "\n",
        "                if bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
        "                    boxes[index_j].classes[c] = 0"
      ],
      "metadata": {
        "id": "OpeHoB5DiGxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load and prepare an image\n",
        "def load_image_pixels(filename, shape):\n",
        "    # load the image to get its shape\n",
        "    image = load_img(filename)\n",
        "    width, height = image.size\n",
        "    # load the image with the required size\n",
        "    image = load_img(filename, target_size=shape)\n",
        "    # convert to numpy array\n",
        "    image = img_to_array(image)\n",
        "    # scale pixel values to [0, 1]\n",
        "    image = image.astype('float32')\n",
        "    image /= 255.0\n",
        "    # add a dimension so that we have one sample\n",
        "    image = expand_dims(image, 0)\n",
        "    return image, width, height"
      ],
      "metadata": {
        "id": "Ou81IYbZiccG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get all of the results above a threshold\n",
        "def get_boxes(boxes, labels, thresh):\n",
        "    v_boxes, v_labels, v_scores = list(), list(), list()\n",
        "    # enumerate all boxes\n",
        "    for box in boxes:\n",
        "      # enumerate all possible labels\n",
        "      for i in range(len(labels)):\n",
        "        # check if the threshold for this label is high enough\n",
        "        if box.classes[i] > thresh:\n",
        "          v_boxes.append(box)\n",
        "          v_labels.append(labels[i])\n",
        "          v_scores.append(box.classes[i]*100)\n",
        "          # don't break, many labels may trigger for one box\n",
        "    return v_boxes, v_labels, v_scores"
      ],
      "metadata": {
        "id": "gUKjhooVi5Ee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# draw all results\n",
        "def draw_boxes(filename, v_boxes, v_labels, v_scores):\n",
        "    # load the image\n",
        "    data = pyplot.imread(filename)\n",
        "    # plot the image\n",
        "    pyplot.imshow(data)\n",
        "    # get the context for drawing boxes\n",
        "    ax = pyplot.gca()\n",
        "    # plot each box\n",
        "    for i in range(len(v_boxes)):\n",
        "        box = v_boxes[i]\n",
        "        # get coordinates\n",
        "        y1, x1, y2, x2 = box.ymin, box.xmin, box.ymax, box.xmax\n",
        "        # calculate width and height of the box\n",
        "        width, height = x2 - x1, y2 - y1\n",
        "        # create the shape\n",
        "        rect = Rectangle((x1, y1), width, height, fill=False, color='white')\n",
        "        # draw the box\n",
        "        ax.add_patch(rect)\n",
        "        # draw text and score in top left corner\n",
        "        label = \"%s (%.3f)\" % (v_labels[i], v_scores[i])\n",
        "        pyplot.text(x1, y1, label, color='white')\n",
        "      # show the plot\n",
        "    pyplot.show()\n"
      ],
      "metadata": {
        "id": "UtPx02_DjMrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make predictions"
      ],
      "metadata": {
        "id": "BLZFpXzUmZAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/heartkilla/yolo-v3.git"
      ],
      "metadata": {
        "id": "aP6VgLJhkTC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image1 = '/content/yolo-v3/data/images/dog.jpg'\n",
        "image2 = '/content/yolo-v3/data/images/office.jpg'"
      ],
      "metadata": {
        "id": "K6T_ROipmRwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the expected input shape for the model\n",
        "input_w, input_h = 416, 416\n",
        "# define our new photo\n",
        "photo_filename = '/content/yolo-v3/data/images/dog.jpg'\n",
        "# load and prepare image\n",
        "image, image_w, image_h = load_image_pixels(photo_filename, (input_w, input_h))"
      ],
      "metadata": {
        "id": "OERx567fmcPn"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image.size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8G4dNTg0pFd",
        "outputId": "10046046-e8db-4db2-9dcf-25843fb952c2"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "519168"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output of the model is, in fact, encoded candidate bounding boxes from three different grid sizes, and the boxes are defined the context of anchor boxes, carefully chosen based on an analysis of the size of objects in the MSCOCO dataset."
      ],
      "metadata": {
        "id": "yti-2Ozqugnk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "# make prediction\n",
        "yhat = yolov3_model.predict(image)\n",
        "print(len(yhat))\n",
        "#arr_yhat = np.array(yhat.copy)\n",
        "# summarize the shape of the list of arrays\n",
        "print([a.shape for a in yhat])"
      ],
      "metadata": {
        "id": "_KaVHxXNm73A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make data for YOLO-LSTM"
      ],
      "metadata": {
        "id": "kZhvgm_lvM3n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###access google drive folder\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYOGEfOGwqbG",
        "outputId": "cef6ad02-12d4-46e8-840f-55fc506c4cd9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -u -q /content/drive/MyDrive/Dachcam_dataset.zip"
      ],
      "metadata": {
        "id": "UQ094hWzxUWZ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"/content/videos/training\"\n",
        "test_dir = \"/content/videos/testing\""
      ],
      "metadata": {
        "id": "DqLCIWrDxXXF"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import expand_dims\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "# load and prepare an image\n",
        "def load_image_pixels(filename, shape):\n",
        "    # load the image to get its shape\n",
        "    image = load_img(filename)\n",
        "    width, height = image.size\n",
        "    # load the image with the required size\n",
        "    image = load_img(filename, target_size=shape)\n",
        "    # convert to numpy array\n",
        "    image = img_to_array(image)\n",
        "    # scale pixel values to [0, 1]\n",
        "    image = image.astype('float32')\n",
        "    image /= 255.0\n",
        "    # add a dimension so that we have one sample\n",
        "    image = expand_dims(image, 0)\n",
        "    return image, width, height"
      ],
      "metadata": {
        "id": "EqS25xmY1FZJ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from numpy import expand_dims\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "def coordinates_extraction(video_path):\n",
        "    coordinates_list = []\n",
        "    vidObj = cv2.VideoCapture(video_path)\n",
        "    # Used as counter variable \n",
        "    count = 1\n",
        "    while count <= seq_len:   \n",
        "        success, image = vidObj.read() \n",
        "        if success:\n",
        "            # #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            #image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "            image = cv2.resize(image, (vid_height, vid_width))\n",
        "            # convert to numpy array\n",
        "            image = img_to_array(image)\n",
        "            # scale pixel values to [0, 1]\n",
        "            image = image.astype('float32')\n",
        "            image /= 255.0\n",
        "            # add a dimension so that we have one sample\n",
        "            image = expand_dims(image, 0)\n",
        "            yolov3_model.predict(image)\n",
        "            coordinates_list.append(image)\n",
        "            count += 1\n",
        "        else:\n",
        "            print(\"Defected frame\")\n",
        "            break\n",
        "    #return only the first 50 frames, so model makes predict for the next 50 frames\n",
        "    return coordinates_list"
      ],
      "metadata": {
        "id": "ulpYxLR1xj4O"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "def create_data(input_dir, seq_len, classes):\n",
        "    X = []\n",
        "    Y = []\n",
        "     \n",
        "    classes_list = os.listdir(input_dir)\n",
        "     \n",
        "    for c in classes_list:\n",
        "        print(c)\n",
        "        files_list = os.listdir(os.path.join(input_dir, c))\n",
        "        for f in files_list:\n",
        "          coordinates = coordinates_extraction(os.path.join(os.path.join(input_dir, c), f))\n",
        "          if len(coordinates) == seq_len:\n",
        "                X.append(coordinates)\n",
        "                y = [0]*len(classes)\n",
        "                y[classes.index(c)] = 1\n",
        "                Y.append(y)\n",
        "          else:\n",
        "            print(\"len(coordinates) != seq_len\")\n",
        "            break\n",
        "     \n",
        "    X = np.asarray(X)\n",
        "    Y = np.asarray(Y)\n",
        "    return X, Y"
      ],
      "metadata": {
        "id": "2HoaHMUZxneT"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the expected input shape for the model\n",
        "vid_height , vid_width = 416, 416\n",
        "seq_len = 100\n",
        "classes = [\"negative\", \"positive\"]\n",
        "\n",
        "#Need to thread this or use multiprocessing to make this faster\n",
        "import time\n",
        "start = time.perf_counter()\n",
        "X_train, y_train = create_data(train_dir, seq_len, classes) \n",
        "X_test, y_test =  create_data(test_dir, seq_len, classes)\n",
        "finish = time.perf_counter()\n",
        "print(f\"Finished in {round(finish-start,2)} seconds.\")"
      ],
      "metadata": {
        "id": "QMIvflUaxumd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir test"
      ],
      "metadata": {
        "id": "uLMYf3TO71vk"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir negative\n",
        "!mkdir positive\n"
      ],
      "metadata": {
        "id": "LN2AvDJq8DjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv positive/ test/positive"
      ],
      "metadata": {
        "id": "5O_nnlt49AHM"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv negative test/negative"
      ],
      "metadata": {
        "id": "CvFe4Tpm9TOP"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We keep running out run while trying to create the data so we'll use 4 videos to tinker\n",
        "!cp \"/content/videos/testing/negative/000830.mp4\" test/negative/000830.mp4\n",
        "!cp \"/content/videos/testing/negative/000831.mp4\" test/negative/000831.mp4\n",
        "\n",
        "!cp \"/content/videos/testing/positive/000456.mp4\" test/positive/000456.mp4\n",
        "!cp \"/content/videos/testing/positive/000457.mp4\" test/positive/000457.mp4"
      ],
      "metadata": {
        "id": "YXaIDsEX9LqM"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tinker_dir = \"test\"\n",
        "X, Y = create_data(tinker_dir, seq_len, classes) "
      ],
      "metadata": {
        "id": "g3UlwHoJ-SZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuTarx5eL1ND",
        "outputId": "b4ff3bfa-4fc6-453a-9d19-12f2771324d1"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 100, 1, 416, 416, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = 4\n",
        "sequence_length = 100\n",
        "input_shape = np.reshape(X, (num_samples, sequence_length, -1))\n",
        "#print(input_shape.shape)\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM, Activation\n",
        "from sklearn.metrics import fbeta_score\n",
        "# build the LSTM network\n",
        "# Feature weights\n",
        "nb_features = input_shape[2]\n",
        "sequence_length = input_shape[1]\n",
        "nb_out = 1\n",
        "\n",
        "# LSTM model\n",
        "LSTM_model = Sequential()\n",
        "\n",
        "# The first layer\n",
        "LSTM_model.add(LSTM(\n",
        "         input_shape=(sequence_length, nb_features),\n",
        "         units=100,\n",
        "         return_sequences=True))\n",
        "\n",
        "# Plus a 20% dropout rate\n",
        "#LSTM_model.add(Dropout(0.2))\n",
        "\n",
        "# The second layer\n",
        "LSTM_model.add(LSTM(\n",
        "          units=50,\n",
        "          return_sequences=False))\n",
        "\n",
        "# Plus a 20% dropout rate\n",
        "#LSTM_model.add(Dropout(0.2))\n",
        "\n",
        "# Dense sigmoid layer\n",
        "LSTM_model.add(Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# With adam optimizer and a binary crossentropy loss. We will opimize for model accuracy.\n",
        "LSTM_model.compile(loss='binary_crossentropy', optimizer='adam')\n",
        "\n",
        "# Verify the architecture \n",
        "print(LSTM_model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5korYWNN-LD",
        "outputId": "09c8a29a-b96f-46a0-ab8a-ec3daa3f59ea"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_8 (LSTM)               (None, 100, 100)          207707600 \n",
            "                                                                 \n",
            " lstm_9 (LSTM)               (None, 50)                30200     \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 207,737,851\n",
            "Trainable params: 207,737,851\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = np.reshape(X, (num_samples, sequence_length, -1))\n",
        "train_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WbjyHsjSa-w",
        "outputId": "9d277c94-6fe9-4bed-e14f-a3ade4eaa9cc"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 100, 519168)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import time\n",
        "\n",
        "\n",
        "t0 = time.time()\n",
        "# fit the network\n",
        "LSTM_history = LSTM_model.fit(train_data, # Training features\n",
        "          Y, # Training labels\n",
        "          epochs=1000,   # We'll stop after 10 epochs\n",
        "          batch_size=200, # \n",
        "          validation_split=0.10, # Use 10% of data to evaluate the loss. (val_loss)\n",
        "          verbose=1, #\n",
        "          )\n",
        "\n",
        "print(\"Training took \"+str(time.time() - t0)+\" seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 801
        },
        "id": "g97yHQMfR6tH",
        "outputId": "0a3cf499-4267-4218-f848-613fb2a7bbc8"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-998371d5a418>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# fit the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m LSTM_history = LSTM_model.fit(train_data, # Training features\n\u001b[0m\u001b[1;32m      8\u001b[0m           \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Training labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0;31m# We'll stop after 10 epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1051, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1109, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/losses.py\", line 2156, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"/usr/local/lib/python3.10/dist-packages/keras/backend.py\", line 5707, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 1) vs (None, 2)).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijQ2zb4GS4KS",
        "outputId": "087aead2-f85c-4b4d-fc5c-c63385b31559"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 0]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]]\n"
          ]
        }
      ]
    }
  ]
}